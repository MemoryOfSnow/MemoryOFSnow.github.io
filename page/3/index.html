<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueinyou.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Paul C&#39;s Blog">
<meta property="og:url" content="https://blueinyou.com/page/3/index.html">
<meta property="og:site_name" content="Paul C&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Paul C">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueinyou.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Paul C's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Paul C's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">To be funny,to grow up!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Kaggle2019/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Kaggle2019/" class="post-title-link" itemprop="url">CustomerLoyalty</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-05-06 14:12:58" itemprop="dateCreated datePublished" datetime="2022-05-06T14:12:58+08:00">2022-05-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-04 03:03:56" itemprop="dateModified" datetime="2022-06-04T03:03:56+08:00">2022-06-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/CTF/%E8%B5%B0%E4%BB%A3%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/CTF/%E8%B5%B0%E4%BB%A3%E7%90%86/" class="post-title-link" itemprop="url">走代理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-26 14:19:49" itemprop="dateCreated datePublished" datetime="2022-04-26T14:19:49+08:00">2022-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-18 17:14:36" itemprop="dateModified" datetime="2022-10-18T17:14:36+08:00">2022-10-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CTF/" itemprop="url" rel="index"><span itemprop="name">CTF</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>这部分内容常用，所以做了一个系统整理；之后会陆续增加点其他内容</p>
<p>查看左边栏的目录进行快速跳转。</p>
<p>防火墙ban了大部分国外服务器的IP，可以轻易检测出没有伪装过的vmess流量，考虑效益，我购买了某机场的会员，价格为30元一个季度，每个月200GB流量。</p>
<p><img src="/categories/CTF/%E8%B5%B0%E4%BB%A3%E7%90%86/image-20220426160329651.png" alt="image-20220426160329651"></p>
<p>我的真机系统为Win11，使用v2rayN管理连接的服务器和代理端口。</p>
<p>如图所示，我的socks代理端口为10808，http端口为10809。这两种端口，http端口使用的最为频繁。</p>
<ul>
<li>设置v2rayNG-&gt;系统代理-&gt;清除系统代理；</li>
<li>设置v2rayNG-&gt;路由-&gt;PAC分流模式。</li>
</ul>
<h2 id="虚拟机走代理"><a href="#虚拟机走代理" class="headerlink" title="虚拟机走代理"></a>虚拟机走代理</h2><p>百度都是直接关闭防火墙，这样不安全，所以写下这一部分内容记录一下步骤。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/categories/CTF/%E8%B5%B0%E4%BB%A3%E7%90%86/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">爬虫4</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-26 14:19:49" itemprop="dateCreated datePublished" datetime="2022-04-26T14:19:49+08:00">2022-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-29 21:50:01" itemprop="dateModified" datetime="2022-10-29T21:50:01+08:00">2022-10-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CTF/" itemprop="url" rel="index"><span itemprop="name">CTF</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>使用 Pyppeteer 针对之前的 Selenium 案例做一次改写，来体会一下二者的不同之处，同时也加强一下对 Pyppeteer 的理解和掌握情况。</p>
<p>还是 Selenium 的那个案例，地址为：<a target="_blank" rel="noopener" href="https://dynamic2.scrape.cuiqingcai.com/">https://dynamic2.scrape.cuiqingcai.com/</a></p>
<p>爬取目标和那一节也是一样的：</p>
<ul>
<li>遍历每一页列表页，然后获取每部电影详情页的 URL。</li>
<li>爬取每部电影的详情页，然后提取其名称、评分、类别、封面、简介等信息。</li>
<li>爬取到的数据存为 JSON 文件。</li>
</ul>
<p>要求和之前也是一样的，只不过我们这里的实现就全用 Pyppeteer 来做了。</p>
<ul>
<li>安装好 Python （最低为 Python 3.6）版本，并能成功运行 Python 程序。</li>
<li>安装好 Pyppeteer 并能成功运行示例。</li>
</ul>
<p>其他的浏览器、驱动配置就不需要了，这也是相比 Selenium 更加方便的地方。</p>
<p>页面分析在这里就不多介绍了，还是列表页 + 详情页的结构，具体可以参考 Selenium 那一课时的内容。</p>
<h2 id="爬取列表页"><a href="#爬取列表页" class="headerlink" title="爬取列表页"></a>爬取列表页</h2><p>首先我们先做一些准备工作，定义一些基础的配置，包括日志定义、变量等等并引入一些必要的包，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIMEOUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line">WINDOW_WIDTH, WINDOW_HEIGHT = <span class="number">1366</span>, <span class="number">768</span></span><br><span class="line">HEADLESS = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>这里大多数的配置和之前是一样的，不过这里我们额外定义了窗口的宽高信息，这里定义为 1366 x 768，你也可以随意指定适合自己屏幕的宽高信息。另外这里定义了一个变量 HEADLESS，用来指定是否启用 Pyppeteer 的无头模式，如果为 False，那么启动 Pyppeteer 的时候就会弹出一个 Chromium 浏览器窗口。</p>
<p>接着我们再定义一个初始化 Pyppeteer 的方法，包括启动 Pyppeteer，新建一个页面选项卡，设置窗口大小等操作，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line">browser, tab = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">   <span class="keyword">global</span> browser, tab</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=HEADLESS,</span><br><span class="line">                          args=[<span class="string">&#x27;--disable-infobars&#x27;</span>,</span><br><span class="line">                                <span class="string">f&#x27;--window-size=<span class="subst">&#123;WINDOW_WIDTH&#125;</span>,<span class="subst">&#123;WINDOW_HEIGHT&#125;</span>&#x27;</span>])</span><br><span class="line">   tab = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> tab.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: WINDOW_WIDTH, <span class="string">&#x27;height&#x27;</span>: WINDOW_HEIGHT&#125;)</span><br></pre></td></tr></table></figure>
<p>在这里我们先声明了一个 browser 对象，代表 Pyppeteer 所用的浏览器对象，tab 代表新建的页面选项卡，这里把两项设置为全局变量，方便其他的方法调用。</p>
<p>另外定义了一个 init 方法，调用了 Pyppeteer 的 launch 方法，传入了 headless 为 HEADLESS，将其设置为非无头模式，另外还通过 args 指定了隐藏提示条并设定了窗口的宽高。</p>
<p>接下来我们像之前一样，定义一个通用的爬取方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer.errors <span class="keyword">import</span> TimeoutError</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_page</span>(<span class="params">url, selector</span>):</span><br><span class="line">   logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">await</span> tab.goto(url)</span><br><span class="line">       <span class="keyword">await</span> tab.waitForSelector(selector, options=&#123;</span><br><span class="line">           <span class="string">&#x27;timeout&#x27;</span>: TIMEOUT * <span class="number">1000</span></span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">except</span> TimeoutError:</span><br><span class="line">       logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 scrape_page 方法，它接收两个参数，一个是 url，代表要爬取的链接，使用 goto 方法调用即可；另外一个是 selector，即要等待渲染出的节点对应的 CSS 选择器，这里我们使用 waitForSelector 方法并传入了 selector，并通过 options 指定了最长等待时间。</p>
<p>这样的话在运行时页面会首先访问这个 URL，然后等待某个符合 selector 的节点加载出来，最长等待 10 秒，如果 10 秒内加载出来了，那就接着往下执行，否则抛出异常，捕获 TimeoutError 并输出错误日志。</p>
<p>接下来，我们就实现一下爬取列表页的方法，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">   url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;.item .name&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了 scrape_index 方法来爬取页面，其接受一个参数 page，代表要爬取的页码，这里我们首先通过 INDEX_URL 构造了列表页的 URL，然后调用 scrape_page 方法传入了 url 和要等待加载的选择器。</p>
<p>好，接下来我们可以再定义一个解析列表页的方法，提取出每部电影的详情页 URL，定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_index</span>():</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.item .name&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们调用了 querySelectorAllEval 方法，它接收两个参数，第一个参数是 selector，代表要选择的节点对应的 CSS 选择器；第二个参数是 pageFunction，代表的是要执行的 JavaScript 方法，这里需要传入的是一段 JavaScript 字符串，整个方法的作用是选择 selector 对应的节点，然后对这些节点通过 pageFunction 定义的逻辑抽取出对应的结果并返回。</p>
<p>所以这里第一个参数 selector 就传入电影名称对应的节点，其实是超链接 a 节点。由于提取结果有多个，所以这里 JavaScript 对应的 pageFunction 输入参数就是 nodes，输出结果是调用了 map 方法得到每个 node，然后调用 node 的 href 属性即可。这样返回结果就是当前列表页的所有电影的详情页 URL 组成的列表了。</p>
<p>好，接下来我们来串联调用一下看看，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           logging.info(<span class="string">&#x27;detail_urls %s&#x27;</span>, detail_urls)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h2 id="爬取详情页"><a href="#爬取详情页" class="headerlink" title="爬取详情页"></a>爬取详情页</h2><p>拿到详情页的 URL 之后，下一步就是爬取每一个详情页然后提取信息了，首先我们定义一个爬取详情页的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;h2&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>如果顺利运行，那么当前 Pyppeteer 就已经成功加载出详情页了，下一步就是提取里面的信息了。</p>
<p>接下来我们再定义一个提取详情信息的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_detail</span>():</span><br><span class="line">   url = tab.url</span><br><span class="line">   name = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;h2&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   categories = <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.categories button span&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;</span>)</span><br><span class="line">   cover = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.cover&#x27;</span>, <span class="string">&#x27;node =&gt; node.src&#x27;</span>)</span><br><span class="line">   score = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.score&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   drama = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.drama p&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   <span class="keyword">return</span> &#123;</span><br><span class="line">       <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">       <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">       <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">       <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">       <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">       <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 parse_detail 方法，提取了 URL、名称、类别、封面、分数、简介等内容，提取方式如下：</p>
<ul>
<li>URL：直接调用 tab 对象的 url 属性即可获取当前页面的 URL。</li>
<li>名称：由于名称只有一个节点，所以这里我们调用了 querySelectorEval 方法来提取，而不是querySelectorAllEval，第一个参数传入 h2，提取到了名称对应的节点，然后第二个参数传入提取的 pageFunction，调用了 node 的 innerText 属性提取了文本值，即电影名称。</li>
<li>类别：类别有多个，所以我们这里调用了 querySelectorAllEval 方法来提取，其对应的 CSS 选择器为 .categories button span，可以选中多个类别节点。接下来还是像之前提取详情页 URL 一样，pageFunction 使用 nodes 参数，然后调用 map 方法提取 node 的 innerText 就得到所有类别结果了。</li>
<li>封面：同样地，可以使用 CSS 选择器 .cover 直接获取封面对应的节点，但是由于其封面的 URL 对应的是 src 这个属性，所以这里提取的是 src 属性。</li>
<li>分数：分数对应的 CSS 选择器为 .score ，类似的原理，提取 node 的 innerText 即可。</li>
<li>简介：同样可以使用 CSS 选择器 .drama p 直接获取简介对应的节点，然后调用 innerText 属性提取文本即可。</li>
</ul>
<p>最后我们将提取结果汇总成一个字典然后返回即可。</p>
<p>接下来 main 方法里面，我们增加 scrape_detail 和 parse_detail 方法的调用，main 方法改写如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">               <span class="keyword">await</span> scrape_detail(detail_url)</span><br><span class="line">               detail_data = <span class="keyword">await</span> parse_detail()</span><br><span class="line">               logging.info(<span class="string">&#x27;data %s&#x27;</span>, detail_data)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br></pre></td></tr></table></figure>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>最后，我们再像之前一样添加一个数据存储的方法，为了方便，这里还是保存为 JSON 文本文件，实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">   name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">   data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">   json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>在运行过程中，由于 Pyppeteer 本身实现的原因，可能连续运行 20 秒之后控制台就会出现如下错误：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyppeteer.errors.NetworkError: Protocol Error (Runtime.evaluate): Session closed. Most likely the page has been closed.</span><br></pre></td></tr></table></figure>
<h2 id="无头模式"><a href="#无头模式" class="headerlink" title="无头模式"></a>无头模式</h2><p>最后如果代码能稳定运行了，我们可以将其改为无头模式，将 HEADLESS 修改为 True 即可，这样在运行的时候就不会弹出浏览器窗口了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/4%E7%88%AC%E8%99%AB%E9%9D%99%E6%80%81%E6%8F%90%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/4%E7%88%AC%E8%99%AB%E9%9D%99%E6%80%81%E6%8F%90%E5%8F%96/" class="post-title-link" itemprop="url">爬虫1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-26 14:19:49" itemprop="dateCreated datePublished" datetime="2022-04-26T14:19:49+08:00">2022-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-29 21:49:32" itemprop="dateModified" datetime="2022-10-29T21:49:32+08:00">2022-10-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CTF/" itemprop="url" rel="index"><span itemprop="name">CTF</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="页面解析之数据提取"><a href="#页面解析之数据提取" class="headerlink" title="页面解析之数据提取"></a>页面解析之数据提取</h1><p>一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值，内容一般分为两部分，非结构化的文本，或结构化的文本。</p>
<h3 id="关于结构化的数据"><a href="#关于结构化的数据" class="headerlink" title="关于结构化的数据"></a>关于结构化的数据</h3><p>JSON、XML</p>
<h3 id="关于非结构化的数据"><a href="#关于非结构化的数据" class="headerlink" title="关于非结构化的数据"></a>关于非结构化的数据</h3><h4 id="关于HTML文本（包含JavaScript代码）"><a href="#关于HTML文本（包含JavaScript代码）" class="headerlink" title="关于HTML文本（包含JavaScript代码）"></a>关于HTML文本（包含JavaScript代码）</h4><p>HTML文本（包含JavaScript代码）是最常见的数据格式，理应属于结构化的文本组织，但因为一般我们需要的关键信息并非直接可以得到，需要进行对HTML的解析查找，甚至一些字符串操作才能得到，所以还是归类于非结构化的数据处理中。</p>
<p>把网页比作一个人，那么HTML便是他的骨架，JS便是他的肌肉，CSS便是它的衣服。</p>
<p>常见解析方式如下： XPath、CSS选择器、正则表达式</p>
<h4 id="一段文本"><a href="#一段文本" class="headerlink" title="一段文本"></a>一段文本</h4><p>例如一篇文章，或者一句话，我们的初衷是提取有效信息，所以如果是滞后处理，可以直接存储，如果是需要实时提取有用信息，常见的处理方式如下：</p>
<ul>
<li>分词 根据抓取的网站类型，使用不同词库，进行基本的分词，然后变成词频统计，类似于向量的表示，词为方向，词频为长度。</li>
<li>NLP 自然语言处理，进行语义分析，用结果表示，例如正负面等。</li>
</ul>
<h1 id="XPath-语言"><a href="#XPath-语言" class="headerlink" title="XPath 语言"></a>XPath 语言</h1><p>XPath（XML Path Language）是XML路径语言,它是一种用来定位XML文档中某部分位置的语言。</p>
<h3 id="学习目的"><a href="#学习目的" class="headerlink" title="学习目的"></a>学习目的</h3><p>将HTML转换成XML文档之后，用XPath查找HTML节点或元素</p>
<p>比如用“/”来作为上下层级间的分隔，第一个“/”表示文档的根节点（注意，不是指文档最外层的tag节点，而是指文档本身）。</p>
<p>比如对于一个HTML文件来说，最外层的节点应该是”/html”。</p>
<h3 id="XPath开发工具"><a href="#XPath开发工具" class="headerlink" title="XPath开发工具"></a>XPath开发工具</h3><ol>
<li><p>开源的XPath表达式编辑工具:XMLQuire(XML格式文件可用)</p>
</li>
<li><p>chrome插件 XPath Helper</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-Xpath_Helper.bmp" alt="img"></p>
</li>
<li><p>firefox插件 XPath Checker</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/01-checker.png" alt="img"></p>
</li>
</ol>
<p>XPath语法参考文档：</p>
<p><a target="_blank" rel="noopener" href="http://www.w3school.com.cn/xpath/index.asp">http://www.w3school.com.cn/xpath/index.asp</a></p>
<h3 id="XPath语法"><a href="#XPath语法" class="headerlink" title="XPath语法"></a>XPath语法</h3><p>XPath 是一门在 XML 文档中查找信息的语言。</p>
<p>XPath 可用来在 XML 文档中对元素和属性进行遍历。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bookstore</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">book</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span> <span class="attr">lang</span>=<span class="string">&quot;eng&quot;</span>&gt;</span>Harry Potter<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">price</span>&gt;</span>29.99<span class="tag">&lt;/<span class="name">price</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">book</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">book</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span> <span class="attr">lang</span>=<span class="string">&quot;eng&quot;</span>&gt;</span>Learning XML<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">price</span>&gt;</span>39.95<span class="tag">&lt;/<span class="name">price</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">book</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">bookstore</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。</p>
<p>下面列出了最有用的路径表达式：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>/</td>
<td>从根节点选取。</td>
</tr>
<tr>
<td>nodename</td>
<td>选取此节点的<strong>所有子节点</strong>。</td>
</tr>
<tr>
<td>//</td>
<td>从当前节点 选择 <strong>所有匹配</strong>文档中的节点</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点。</td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点。</td>
</tr>
<tr>
<td>@</td>
<td>选取属性。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们已列出了一些路径表达式以及表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore</td>
<td>选取根元素 bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！</td>
</tr>
<tr>
<td>bookstore</td>
<td>选取 bookstore 元素的所有子节点。默认从根节点选取</td>
</tr>
<tr>
<td>bookstore/book</td>
<td>选取属于 bookstore 的子元素的所有 book 元素。</td>
</tr>
<tr>
<td>//book</td>
<td>选取所有 book 子元素，而不管它们在文档中的位置。</td>
</tr>
<tr>
<td>//book/./title</td>
<td>选取所有 book 子元素，从当前节点查找title节点</td>
</tr>
<tr>
<td>//price/..</td>
<td>选取所有 book 子元素，从当前节点查找父节点</td>
</tr>
<tr>
<td>bookstore//book</td>
<td>选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。</td>
</tr>
<tr>
<td>//@lang</td>
<td>选取名为 lang 的所有属性。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>谓语条件（Predicates）<ol>
<li>谓语用来查找<strong>某个特定的信息</strong>或者<strong>包含某个指定的值</strong>的节点。</li>
<li>所谓”谓语条件”，就是对路径表达式的附加条件</li>
<li>谓语是<strong>被嵌在方括号</strong>中，都写在方括号”[]”中，表示对节点进行进一步的筛选。</li>
</ol>
</li>
</ul>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/book[1]</td>
<td>选取属于 bookstore 子元素的第一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取属于 bookstore 子元素的最后一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()-1]</td>
<td>选取属于 bookstore 子元素的倒数第二个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[position()&lt;3]</td>
<td>选取最前面的两个属于 bookstore 元素的子元素的 book 元素。</td>
</tr>
<tr>
<td>//title[@lang]</td>
<td>选取所有拥有名为 lang 的属性的 title 元素。</td>
</tr>
<tr>
<td>//title[@lang=’eng’]</td>
<td>选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。</td>
</tr>
<tr>
<td>//book[price]</td>
<td>选取所有 book 元素，且被选中的book元素必须带有price子元素</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]</td>
<td>选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]/title</td>
<td>选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>选取未知节点</li>
</ul>
<p>XPath 通配符可用来选取未知的 XML 元素。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>通配符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>匹配任何元素节点。</td>
</tr>
<tr>
<td>@*</td>
<td>匹配任何属性节点。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/*</td>
<td>选取 bookstore 元素的所有子元素。</td>
</tr>
<tr>
<td>//*</td>
<td>选取文档中的所有元素。</td>
</tr>
<tr>
<td>//title[@*]</td>
<td>选取所有带有属性的 title 元素。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>选取若干路径</li>
</ul>
<p>通过在路径表达式中使用“|”运算符，您可以选取若干个路径。</p>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>//book/title \</td>
<td>//book/price</td>
<td>选取 book 元素的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>//title \</td>
<td>//price</td>
<td>选取文档中的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>/bookstore/book/title \</td>
<td>//price</td>
<td>选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="XPath-高级用法"><a href="#XPath-高级用法" class="headerlink" title="XPath 高级用法"></a>XPath 高级用法</h3><ul>
<li>模糊查询 contains</li>
</ul>
<p>目前许多web框架，都是动态生成界面的元素id，因此在每次操作相同界面时，ID都是变化的，这样为自动化测试造成了一定的影响。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;eleWrapper&quot;</span> <span class="attr">title</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">class</span>=<span class="string">&quot;textfield&quot;</span> <span class="attr">name</span>=<span class="string">&quot;ID9sLJQnkQyLGLhYShhlJ6gPzHLgvhpKpLzp2Tyh4hyb1b4pnvzxFR!-166749344!1357374592067&quot;</span> <span class="attr">id</span>=<span class="string">&quot;nt1357374592068&quot;</span>  /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>解决方法 使用xpath的匹配功能，<code>//input[contains(@id,&#39;nt&#39;)]</code></p>
<ul>
<li>测试使用的XML</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Root</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Person</span> <span class="attr">ID</span>=<span class="string">&quot;1001&quot;</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Name</span> <span class="attr">lang</span>=<span class="string">&quot;zh-cn&quot;</span> &gt;</span>张城斌<span class="tag">&lt;/<span class="name">Name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Email</span> <span class="attr">xmlns</span>=<span class="string">&quot;www.quicklearn.cn&quot;</span> &gt;</span> cbcye@live.com <span class="tag">&lt;/<span class="name">Email</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Blog</span>&gt;</span>http://cbcye.cnblogs.com<span class="tag">&lt;/<span class="name">Blog</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Person</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Person</span> <span class="attr">ID</span>=<span class="string">&quot;1002&quot;</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Name</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span> &gt;</span>Gary Zhang<span class="tag">&lt;/<span class="name">Name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Email</span> <span class="attr">xmlns</span>=<span class="string">&quot;www.quicklearn.cn&quot;</span> &gt;</span> GaryZhang@cbcye.com<span class="tag">&lt;/<span class="name">Email</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Blog</span>&gt;</span>http://www.quicklearn.cn<span class="tag">&lt;/<span class="name">Blog</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Person</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>查询所有Blog节点值中带有 cn 字符串的Person节点</li>
</ol>
<p>Xpath表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Root//Person[contains(Blog,&#x27;cn&#x27;)]</span><br></pre></td></tr></table></figure>
<p>2.查询所有Blog节点值中带有 cn 字符串并且属性ID值中有01的Person节点</p>
<p>Xpath表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Root//Person[contains(Blog,&#x27;cn&#x27;) and contains(@ID,&#x27;01&#x27;)]</span><br></pre></td></tr></table></figure>
<h1 id="学习笔记"><a href="#学习笔记" class="headerlink" title="学习笔记"></a>学习笔记</h1><p>1.依靠自己的属性，文本定位</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//td[text()=<span class="string">&#x27;Data Import&#x27;</span>]</span><br><span class="line"></span><br><span class="line">//div[contains(@<span class="keyword">class</span>,<span class="string">&#x27;cux-rightArrowIcon-on&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">//a[text()=<span class="string">&#x27;马上注册&#x27;</span>]</span><br><span class="line"></span><br><span class="line">//<span class="built_in">input</span>[@<span class="built_in">type</span>=<span class="string">&#x27;radio&#x27;</span> <span class="keyword">and</span> @value=<span class="string">&#x27;1&#x27;</span>]     多条件</span><br><span class="line"></span><br><span class="line">//span[@name=<span class="string">&#x27;bruce&#x27;</span>][text()=<span class="string">&#x27;bruce1&#x27;</span>][<span class="number">1</span>]   多条件</span><br><span class="line"></span><br><span class="line"> //span[@<span class="built_in">id</span>=<span class="string">&#x27;bruce1&#x27;</span> <span class="keyword">or</span> text()=<span class="string">&#x27;bruce2&#x27;</span>]  找出多个</span><br><span class="line"></span><br><span class="line"> //span[text()=<span class="string">&#x27;bruce1&#x27;</span> <span class="keyword">and</span> text()=<span class="string">&#x27;bruce2&#x27;</span>]  找出多个</span><br></pre></td></tr></table></figure>
<p>2.依靠父节点定位</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//div[@class=&#x27;x-grid-col-name x-grid-cell-inner&#x27;]/div</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;dynamicGridTestInstanceformclearuxformdiv&#x27;]/div</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;test&#x27;]/input</span><br></pre></td></tr></table></figure>
<p>3.依靠子节点定位</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//div[div[@id=&#x27;navigation&#x27;]]</span><br><span class="line"></span><br><span class="line">//div[div[@name=&#x27;listType&#x27;]]</span><br><span class="line"></span><br><span class="line">//div[p[@name=&#x27;testname&#x27;]]</span><br></pre></td></tr></table></figure>
<p>4.混合型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[div[@name=&#x27;listType&#x27;]]//img</span><br><span class="line"></span><br><span class="line">//td[a//font[contains(text(),&#x27;seleleium2从零开始 视屏&#x27;)]]//input[@type=&#x27;checkbox&#x27;]</span><br></pre></td></tr></table></figure>
<p>5.进阶部分</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//input[@id=&#x27;123&#x27;]/following-sibling::input   找下一个兄弟节点</span><br><span class="line"></span><br><span class="line">//input[@id=&#x27;123&#x27;]/preceding-sibling::span    上一个兄弟节点</span><br><span class="line"></span><br><span class="line">//input[starts-with(@id,&#x27;123&#x27;)]               以什么开头</span><br><span class="line"></span><br><span class="line">//span[not(contains(text(),&#x27;xpath&#x27;)）]        不包含xpath字段的span</span><br></pre></td></tr></table></figure>
<p>6.索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//div/input[2]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()=3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()&gt;3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()&lt;3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[last()]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[last()-1]</span><br></pre></td></tr></table></figure>
<p>7.substring 截取判断</p>
<p><div data-for="result" id="swfEveryCookieWrap"></div><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//*[substring(@id,4,5)=&#x27;Every&#x27;]/@id  截取该属性 定位3,取长度5的字符 </span><br><span class="line"></span><br><span class="line">//*[substring(@id,4)=&#x27;EveryCookieWrap&#x27;]  截取该属性从定位3 到最后的字符 </span><br><span class="line"></span><br><span class="line">//*[substring-before(@id,&#x27;C&#x27;)=&#x27;swfEvery&#x27;]/@id   属性 &#x27;C&#x27;之前的字符匹配</span><br><span class="line"></span><br><span class="line">//*[substring-after(@id,&#x27;C&#x27;)=&#x27;ookieWrap&#x27;]/@id   属性&#x27;C之后的字符匹配</span><br></pre></td></tr></table></figure></p>
<p>8.通配符*</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//span[@*=&#x27;bruce&#x27;]</span><br><span class="line"></span><br><span class="line">//*[@name=&#x27;bruce&#x27;]</span><br></pre></td></tr></table></figure>
<p>9.轴</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[span[text()=&#x27;+++current node&#x27;]]/parent::div    找父节点</span><br><span class="line"></span><br><span class="line">//div[span[text()=&#x27;+++current node&#x27;]]/ancestor::div    找祖先节点</span><br></pre></td></tr></table></figure>
<p>10.孙子节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[span[text()=&#x27;current note&#x27;]]/descendant::div/span[text()=&#x27;123&#x27;]</span><br><span class="line"></span><br><span class="line">//div[span[text()=&#x27;current note&#x27;]]//div/span[text()=&#x27;123&#x27;]          两个表达的意思一样</span><br></pre></td></tr></table></figure>
<h3 id="xpath提取多个标签下的text"><a href="#xpath提取多个标签下的text" class="headerlink" title="xpath提取多个标签下的text"></a>xpath提取多个标签下的text</h3><p>在写爬虫的时候，经常会使用xpath进行数据的提取，对于如下的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test1&quot;&gt;大家好！&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>使用xpath提取是非常方便的。假设网页的源代码在selector中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test1&quot;]/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>就可以把“大家好！”提取到data变量中去。</p>
<p>然而如果遇到下面这段代码呢？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test2&quot;&gt;美女，&lt;font color=red&gt;你的微信是多少？&lt;/font&gt;&lt;div&gt;</span><br></pre></td></tr></table></figure>
<p>如果使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test2&quot;]/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>只能提取到“美女，”；</p>
<p>如果使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test2&quot;]/font/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>又只能提取到“你的微信是多少？”</p>
<p><strong>可是我本意是想把“美女，你的微信是多少？”这一整个句子提取出来。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test3&quot;&gt;我左青龙，&lt;span id=&quot;tiger&quot;&gt;右白虎，&lt;ul&gt;上朱雀，&lt;li&gt;下玄武。&lt;/li&gt;&lt;/ul&gt;老牛在当中，&lt;/span&gt;龙头在胸口。&lt;div&gt;</span><br></pre></td></tr></table></figure>
<p>而且内部的标签还不固定，如果我有一百段这样类似的html代码，又如何使用xpath表达式，以最快最方便的方式提取出来？</p>
<p><strong>使用xpath的string(.)</strong></p>
<p>以第三段代码为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test3&quot;]&#x27;)</span><br><span class="line">info = data.xpath(&#x27;string(.)&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>这样，就可以把“我左青龙，右白虎，上朱雀，下玄武。老牛在当中，龙头在胸口”整个句子提取出来，赋值给info变量。</p>
<h1 id="非结构化数据之lxml库"><a href="#非结构化数据之lxml库" class="headerlink" title="非结构化数据之lxml库"></a>非结构化数据之lxml库</h1><p>lxml 是一种使用 Python 编写的库,可以迅速、灵活地处理 XML ，支持 XPath (XML Path Language)</p>
<p>lxml python 官方文档</p>
<p><a target="_blank" rel="noopener" href="http://lxml.de/index.html">http://lxml.de/index.html</a></p>
<h4 id="学习目的-1"><a href="#学习目的-1" class="headerlink" title="学习目的"></a>学习目的</h4><p>利用上节课学习的XPath语法，来快速的定位 <strong>特定元素以及节点信息</strong>，目的是 提取出 HTML、XML 目标数据</p>
<h4 id="如何安装"><a href="#如何安装" class="headerlink" title="如何安装"></a>如何安装</h4><ul>
<li>Ubuntu :</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxml2-dev libxslt1-dev python-dev</span><br><span class="line">sudo apt-get install zlib1g-dev</span><br><span class="line">sudo apt-get install libevent-dev</span><br><span class="line">sudo pip install lxml</span><br></pre></td></tr></table></figure>
<p>利用 pip 安装即可</p>
<ul>
<li><p>Windows:</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/g1apassz/article/details/46574963">http://blog.csdn.net/g1apassz/article/details/46574963</a></p>
<p><a target="_blank" rel="noopener" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml">http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</a></p>
</li>
</ul>
<h4 id="初步使用"><a href="#初步使用" class="headerlink" title="初步使用"></a>初步使用</h4><p>首先我们利用lxml来解析 HTML 代码，先来一个小例子来感受一下它的基本用法。</p>
<p>使用 lxml 的 etree 库，然后利用 etree.HTML 初始化，然后我们将其打印出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">  &lt;ul&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;</span></span><br><span class="line"><span class="string">   &lt;/ul&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#Parses an HTML document from a string</span></span><br><span class="line">html = etree.HTML(text)   </span><br><span class="line"><span class="comment">#Serialize an element to an encoded string representation of its XML tree</span></span><br><span class="line">result = etree.tostring(html)</span><br><span class="line"><span class="built_in">print</span> result</span><br></pre></td></tr></table></figure>
<p>所以输出结果是这样的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;&lt;body&gt;&lt;div&gt;</span><br><span class="line">  &lt;ul&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;&lt;a href=<span class="string">&quot;link1.html&quot;</span>&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;&lt;a href=<span class="string">&quot;link2.html&quot;</span>&gt;second item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-inactive&quot;</span>&gt;&lt;a href=<span class="string">&quot;link3.html&quot;</span>&gt;&lt;span <span class="keyword">class</span>=<span class="string">&quot;bold&quot;</span>&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;&lt;a href=<span class="string">&quot;link4.html&quot;</span>&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;&lt;a href=<span class="string">&quot;link5.html&quot;</span>&gt;fifth item&lt;/a&gt;</span><br><span class="line">   &lt;/li&gt;&lt;/ul&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<p>不仅补全了 li 标签，还添加了 body，html 标签。</p>
<h3 id="XPath实例测试"><a href="#XPath实例测试" class="headerlink" title="XPath实例测试"></a>XPath实例测试</h3><ul>
<li>（1）获取所有的 <code>&lt;li&gt;</code> 标签</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(html)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> result</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(result)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(result)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(result[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;lxml.etree._ElementTree&#x27;</span>&gt;</span><br><span class="line">[&lt;Element li at <span class="number">0x1014e0e18</span>&gt;, &lt;Element li at <span class="number">0x1014e0ef0</span>&gt;, &lt;Element li at <span class="number">0x1014e0f38</span>&gt;, &lt;Element li at <span class="number">0x1014e0f80</span>&gt;, &lt;Element li at <span class="number">0x1014e0fc8</span>&gt;]</span><br><span class="line"><span class="number">5</span></span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;lxml.etree._Element&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p>可见，每个元素都是 Element 类型;是一个个的标签元素，类似现在的实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;Element li at 0x1014e0e18&gt; Element类型代表的就是</span><br><span class="line">&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>［注意］</p>
<p>Element类型是一种灵活的容器对象，用于在内存中存储结构化数据。</p>
<p>每个element对象都具有以下属性：</p>
</li>
</ul>
<p>　　1. tag：string对象，标签，用于标识该元素表示哪种数据（即元素类型）。</p>
<p>　　2. attrib：dictionary对象，表示附有的属性。</p>
<p>　　3. text：string对象，表示element的内容。</p>
<p>　　4. tail：string对象，表示element闭合之后的尾迹。</p>
<ul>
<li><p>实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;tag attrib1=1&gt;text&lt;/tag&gt;tail</span><br><span class="line">1     2        3         4</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result[0].tag</span><br><span class="line">result[0].text</span><br><span class="line">result[0].tail</span><br><span class="line">result[0].attrib</span><br></pre></td></tr></table></figure>
</li>
<li><p>（2）获取 <code>&lt;li&gt;</code> 标签的所有 class</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/@class&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;item-0&#x27;, &#x27;item-1&#x27;, &#x27;item-inactive&#x27;, &#x27;item-1&#x27;, &#x27;item-0&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（3）获取 <code>&lt;li&gt;</code> 标签下属性 href 为 link1.html 的 <code>&lt;a&gt;</code> 标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(<span class="string">&#x27;//li/a[@href=&quot;link1.html&quot;]&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element a at 0x10ffaae18&gt;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（4）获取 <code>&lt;li&gt;</code> 标签下的所有 <code>&lt;span&gt;</code> 标签</p>
<p>注意这么写是不对的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/span&#x27;)</span><br></pre></td></tr></table></figure>
<p>因为 / 是用来获取子元素的，而 <code>&lt;span&gt;</code> 并不是 <code>&lt;li&gt;</code> 的子元素，所以，要用双斜杠</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li//span&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element span at 0x10d698e18&gt;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（5）获取 <code>&lt;li&gt;</code> 标签下的所有 class，不包括 <code>&lt;li&gt;</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/a//@class&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;blod&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（6）获取最后一个 <code>&lt;li&gt;</code> 的<code>&lt;a&gt;</code> 的 href</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li[last()]/a/@href&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;link5.html&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（7）获取 class 为 bold 的标签名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = html.xpath(&#x27;//*[@class=&quot;bold&quot;]&#x27;)</span><br><span class="line">print result[0].tag</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">span</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="开始练习"><a href="#开始练习" class="headerlink" title="开始练习"></a>开始练习</h3><p>通过以上实例的练习，相信大家对 XPath 的基本用法有了基本的了解</p>
<h4 id="实战项目"><a href="#实战项目" class="headerlink" title="实战项目"></a>实战项目</h4><p>以腾讯招聘网站为例</p>
<p><a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&amp;start=10">http://hr.tencent.com/position.php?&amp;start=10</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">&#x27;http://hr.tencent.com/position.php?&amp;start=10#a&#x27;</span>)</span><br><span class="line">response =urllib2.urlopen(request)</span><br><span class="line">resHtml = response.read()</span><br><span class="line">output =<span class="built_in">open</span>(<span class="string">&#x27;tencent.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">html = etree.HTML(resHtml)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//tr[@class=&quot;odd&quot;] | //tr[@class=&quot;even&quot;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">    item=&#123;&#125;</span><br><span class="line"></span><br><span class="line">    name = site.xpath(<span class="string">&#x27;./td[1]/a&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    detailLink = site.xpath(<span class="string">&#x27;./td[1]/a&#x27;</span>)[<span class="number">0</span>].attrib[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    catalog = site.xpath(<span class="string">&#x27;./td[2]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    recruitNumber = site.xpath(<span class="string">&#x27;./td[3]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    workLocation = site.xpath(<span class="string">&#x27;./td[4]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    publishTime = site.xpath(<span class="string">&#x27;./td[5]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="built_in">type</span>(name)</span><br><span class="line">    <span class="built_in">print</span> name,detailLink,catalog,recruitNumber,workLocation,publishTime</span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>]=name</span><br><span class="line">    item[<span class="string">&#x27;detailLink&#x27;</span>]=detailLink</span><br><span class="line">    item[<span class="string">&#x27;catalog&#x27;</span>]=catalog</span><br><span class="line">    item[<span class="string">&#x27;recruitNumber&#x27;</span>]=recruitNumber</span><br><span class="line">    item[<span class="string">&#x27;publishTime&#x27;</span>]=publishTime</span><br><span class="line"></span><br><span class="line">    line = json.dumps(item,ensure_ascii=<span class="literal">False</span>) + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> line</span><br><span class="line">    output.write(line.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>
<h1 id="CSS-Selector"><a href="#CSS-Selector" class="headerlink" title="CSS Selector"></a>CSS Selector</h1><p>CSS(即层叠样式表Cascading Stylesheet),Selector来定位（locate）页面上的元素（Elements）。Selenium官网的Document里极力推荐使用CSS locator，而不是XPath来定位元素，原因是CSS locator比XPath locator速度快.</p>
<h3 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a>Beautiful Soup</h3><ul>
<li>支持从HTML或XML文件中提取数据的Python库</li>
<li>支持Python标准库中的HTML解析器</li>
<li>还支持一些第三方的解析器lxml, 使用的是 Xpath 语法，推荐安装。</li>
</ul>
<p>Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了</p>
<ul>
<li><p>Beautiful Soup4 安装</p>
<p>官方文档链接:</p>
<p><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></p>
<p>可以利用 pip来安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装解析器(上节课已经安装过)</p>
<p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器,其中一个是 lxml .根据操作系统不同,可以选择下列方法来安装lxml:</p>
<p>另一个可供选择的解析器是纯Python实现的 html5lib , html5lib的解析方式与浏览器相同,可以选择下列方法来安装html5lib:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install html5lib</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>下表列出了主要的解析器：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python标准库</td>
<td>BeautifulSoup(markup, “html.parser”)</td>
<td>Python的内置标准库;执行速度适中;文档容错能力强</td>
<td>Python 2.7.3 or 3.2.2前 的版本中文档容错能力差</td>
</tr>
<tr>
<td>lxml HTML 解析器</td>
<td>BeautifulSoup(markup, “lxml”)</td>
<td>速度快;文档容错能力强 ;</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>lxml XML 解析器</td>
<td>BeautifulSoup(markup, [“lxml-xml”]) BeautifulSoup(markup, “xml”)</td>
<td>速度快;唯一支持XML的解析器</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>html5lib</td>
<td>BeautifulSoup(markup, “html5lib”)</td>
<td>最好的容错性;以浏览器的方式解析文档;生成HTML5格式的文档</td>
<td>速度慢;不依赖外部扩展</td>
</tr>
</tbody>
</table>
</div>
<p>推荐使用lxml作为解析器,因为效率更高. 在Python2.7.3之前的版本和Python3中3.2.2之前的版本,必须安装lxml或html5lib, 因为那些Python版本的标准库中内置的HTML解析方法不够稳定.</p>
<ul>
<li>快速开始</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(html_doc,<span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>下面我们来打印一下 soup 对象的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print soup</span><br></pre></td></tr></table></figure>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-bs4_01.png" alt="img"></p>
<p>格式化输出soup 对象</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-bs4_02.png" alt="img"></p>
<h3 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h3><p>在写 CSS 时：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">标签名不加任何修饰</span><br><span class="line"></span><br><span class="line">类名前加点</span><br><span class="line"></span><br><span class="line">id名前加 #</span><br></pre></td></tr></table></figure>
<p>利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list</p>
<ul>
<li><p>通过标签名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;title&#x27;</span>) </span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过类名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;.sister&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过 id 名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;#link1&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>直接子标签查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&quot;head &gt; title&quot;</span>)</span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>组合查找</p>
<p>组合查找即标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，</p>
<p><strong>属性和标签不属于同一节点 二者需要用空格分开</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;p #link1&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>属性查找</p>
<p>查找时还可以加入属性元素，属性需要用中括号括起来</p>
<p><strong>注意属性和标签属于同一节点，所以中间不能加空格</strong>，否则会无法匹配到</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a[class=&quot;sister&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a[href=&quot;http://example.com/elsie&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
<p>同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;p a[href=&quot;http://example.com/elsie&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
<p>以上的 select 方法返回的结果都是列表形式，可以遍历形式输出</p>
<p>用 <strong>get_text()</strong> 方法来获取它的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;title&#x27;</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> soup.select(<span class="string">&#x27;title&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span> title.get_text()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><p>Tag 是什么？通俗点讲就是 HTML 中的一个个标签，例如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</span><br><span class="line">print type(soup.select(&#x27;a&#x27;)[0])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bs4.element.Tag</span><br></pre></td></tr></table></figure>
<p>对于 Tag，它有两个重要的属性，是 name 和 attrs，下面我们分别来感受一下</p>
<ol>
<li><p>name</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.name</span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].name</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[document]</span><br><span class="line"><span class="string">&#x27;a&#x27;</span></span><br></pre></td></tr></table></figure>
<p>soup 对象本身比较特殊，它的 name 即为 [document]，对于其他内部标签，输出的值便为标签本身的名称。</p>
</li>
<li><p>attrs</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].attrs</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://example.com/elsie&#x27;</span>, <span class="string">&#x27;class&#x27;</span>: [<span class="string">&#x27;sister&#x27;</span>], <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;link1&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，我们把 soup.select(‘a’)[0] 标签的所有属性打印输出了出来，得到的类型是一个字典。</p>
<p>如果我们想要单独获取某个属性，可以这样，例如我们获取它的 class 叫什么</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;class&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;sister&#x27;]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="实战案例"><a href="#实战案例" class="headerlink" title="实战案例"></a>实战案例</h3><p>我们还是以 腾讯招聘网站</p>
<p><a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&amp;start=10#a">http://hr.tencent.com/position.php?&amp;start=10#a</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">&#x27;http://hr.tencent.com/position.php?&amp;start=10#a&#x27;</span>)</span><br><span class="line">response =urllib2.urlopen(request)</span><br><span class="line">resHtml = response.read()</span><br><span class="line">output =<span class="built_in">open</span>(<span class="string">&#x27;tencent.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">html = BeautifulSoup(resHtml,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">result = html.select(<span class="string">&#x27;tr[class=&quot;even&quot;]&#x27;</span>)</span><br><span class="line">result2 = html.select(<span class="string">&#x27;tr[class=&quot;odd&quot;]&#x27;</span>)</span><br><span class="line">result+=result2</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">    item=&#123;&#125;</span><br><span class="line"></span><br><span class="line">    name = site.select(<span class="string">&#x27;td a&#x27;</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">    detailLink = site.select(<span class="string">&#x27;td a&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    catalog = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].get_text()</span><br><span class="line">    recruitNumber = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">2</span>].get_text()</span><br><span class="line">    workLocation = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].get_text()</span><br><span class="line">    publishTime = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">4</span>].get_text()</span><br><span class="line"></span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>]=name</span><br><span class="line">    item[<span class="string">&#x27;detailLink&#x27;</span>]=detailLink</span><br><span class="line">    item[<span class="string">&#x27;catalog&#x27;</span>]=catalog</span><br><span class="line">    item[<span class="string">&#x27;recruitNumber&#x27;</span>]=recruitNumber</span><br><span class="line">    item[<span class="string">&#x27;publishTime&#x27;</span>]=publishTime</span><br><span class="line"></span><br><span class="line">    line = json.dumps(item,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span> line</span><br><span class="line"></span><br><span class="line">    output.write(line.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><p><strong>掌握了XPath、CSS选择器，为什么还要学习正则？</strong></p>
<p>正则表达式，用标准正则解析，一般会把HTML当做普通文本，用指定格式匹配当相关文本，适合小片段文本，或者某一串字符(比如电话号码、邮箱账户)，或者HTML包含javascript的代码，无法用CSS选择器或者XPath</p>
<p><a target="_blank" rel="noopener" href="http://tool.oschina.net/regex/">在线正则表达式测试网站</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.python.org/2/library/re.html#regular-expression-objects">官方文档</a></p>
<p><strong>了解正则表达式</strong></p>
<p>正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个”规则字符串”，这个”规则字符串”用来表达对字符串的一种过滤逻辑。</p>
<h3 id="正则表达式常见概念"><a href="#正则表达式常见概念" class="headerlink" title="正则表达式常见概念"></a>正则表达式常见概念</h3><ul>
<li><p>边界匹配</p>
<p>^ — 与字符串开始的地方匹配，不匹配任何字符；</p>
<p>$ — 与字符串结束的地方匹配，不匹配任何字符；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str = &quot;cat abdcatdetf ios&quot;</span><br><span class="line">^cat : 验证该行以c开头紧接着是a，然后是t</span><br><span class="line">ios$ : 验证该行以t结尾倒数第二个字符为a倒数第三个字符为c</span><br><span class="line">^cat$: 以c开头接着是a-&gt;t然后是行结束：只有cat三个字母的数据行</span><br><span class="line">^$   : 开头之后马上结束：空白行，不包括任何字符</span><br><span class="line">^    : 行的开头，可以匹配任何行，因为每个行都有行开头</span><br></pre></td></tr></table></figure>
<p>\b — 匹配一个单词边界，也就是单词和空格之间的位置，不匹配任何字符；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;er\b&quot;可以匹配&quot;never&quot;中的&quot;er&quot;，但不能匹配&quot;verb&quot;中的&quot;er&quot;。</span><br></pre></td></tr></table></figure>
<p>\B — \b取非，即匹配一个非单词边界；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;er\B&quot;能匹配&quot;verb&quot;中的&quot;er&quot;，但不能匹配&quot;never&quot;中的&quot;er&quot;。</span><br></pre></td></tr></table></figure>
</li>
<li><p>数量词的贪婪模式与非贪婪模式</p>
<p>正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">正则表达式&quot;ab*&quot;如果用于查找&quot;abbbc&quot;，将找到&quot;abbb&quot;。而如果使用非贪婪的数量词&quot;ab*?&quot;，将找到&quot;a&quot;。</span><br></pre></td></tr></table></figure>
</li>
<li><p>反斜杠问题</p>
<p>与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。</p>
<p>假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。</p>
<p>Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\“表示。</p>
</li>
</ul>
<p>  同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">a=re.search(<span class="string">r&quot;\\&quot;</span>,<span class="string">&quot;ab123bb\c&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> a.group()</span><br><span class="line">\</span><br><span class="line">a=re.search(<span class="string">r&quot;\d&quot;</span>,<span class="string">&quot;ab123bb\c&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> a.group()</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="Python-Re模块"><a href="#Python-Re模块" class="headerlink" title="Python Re模块"></a>Python Re模块</h3><p>Python 自带了re模块，它提供了对正则表达式的支持。</p>
<h3 id="match函数"><a href="#match函数" class="headerlink" title="match函数"></a>match函数</h3><p>re.match 尝试从字符串的<strong>起始位置</strong>匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。</p>
<p>下面是此函数的语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=0)</span><br></pre></td></tr></table></figure>
<p>这里的参数的说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>pattern</td>
<td>这是正则表达式来进行匹配。</td>
</tr>
<tr>
<td>string</td>
<td>这是字符串，这将被搜索匹配的模式，在字符串的开头。</td>
</tr>
<tr>
<td>flags</td>
<td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td>
</tr>
</tbody>
</table>
</div>
<p>匹配成功re.match方法返回一个匹配的对象，否则返回None。</p>
<p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>匹配对象的方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>group(num=0)</td>
<td>此方法返回整个匹配（或指定分组num）</td>
</tr>
<tr>
<td>groups()</td>
<td>此方法返回所有元组匹配的子组（空，如果没有）</td>
</tr>
</tbody>
</table>
</div>
<h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span></span><br><span class="line"></span><br><span class="line">matchObj = re.match( <span class="string">r&#x27;(.*) are (.*?) .*&#x27;</span>, line, re.M|re.I)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> matchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group() : &quot;</span>, matchObj.group()</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group(1) : &quot;</span>, matchObj.group(<span class="number">1</span>)</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group(2) : &quot;</span>, matchObj.group(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;No match!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，它产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matchObj.group() :  Cats are smarter than dogs</span><br><span class="line">matchObj.group(1) :  Cats</span><br><span class="line">matchObj.group(2) :  smarter</span><br></pre></td></tr></table></figure>
<h4 id="正则表达式修饰符-选项标志"><a href="#正则表达式修饰符-选项标志" class="headerlink" title="正则表达式修饰符 - 选项标志"></a>正则表达式修饰符 - 选项标志</h4><p>正则表达式字面可以包含一个可选的修饰符来控制匹配的各个方面。修饰符被指定为一个可选的标志。可以使用异或提供多个修饰符（|），如先前所示，并且可以由这些中的一个来表示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>修饰符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.I(re.IGNORECASE)</td>
<td>使匹配对大小写不敏感</td>
</tr>
<tr>
<td>re.M(MULTILINE)</td>
<td>多行匹配，影响 ^ 和 $</td>
</tr>
<tr>
<td>re.S(DOTALL)</td>
<td>使 . 匹配包括换行在内的所有字符</td>
</tr>
<tr>
<td>re.X(VERBOSE)</td>
<td>正则表达式可以是多行，忽略空白字符，并可以加入注释</td>
</tr>
</tbody>
</table>
</div>
<h3 id="findall-函数"><a href="#findall-函数" class="headerlink" title="findall()函数"></a>findall()函数</h3><p>re.findall(pattern, string, flags=0)</p>
<p>返回字符串中所有模式的非重叠的匹配，作为字符串列表。该字符串扫描左到右，并匹配返回的顺序发现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">默认：</span><br><span class="line">        pattren = &quot;\w+&quot;</span><br><span class="line">        target = &quot;hello world\nWORLD HELLO&quot;</span><br><span class="line">        re.findall(pattren,target)</span><br><span class="line">        [&#x27;hello&#x27;, &#x27;world&#x27;, &#x27;WORLD&#x27;, &#x27;HELLO&#x27;]</span><br><span class="line"></span><br><span class="line">re.I:   </span><br><span class="line">        re.findall(&quot;world&quot;, target,re.I)</span><br><span class="line">        [&#x27;world&#x27;, &#x27;WORLD&#x27;]</span><br><span class="line"></span><br><span class="line">re.S:   </span><br><span class="line">        re.findall(&quot;world.WORLD&quot;, target,re.S)</span><br><span class="line">        [&quot;world\nworld&quot;]</span><br><span class="line">        re.findall(&quot;hello.*WORLD&quot;, target,re.S)</span><br><span class="line">        [&#x27;hello world\nWORLD&#x27;]</span><br><span class="line"></span><br><span class="line">re.M:</span><br><span class="line">        re.findall(&quot;^WORLD&quot;,target,re.M)</span><br><span class="line">        [&quot;WORLD&quot;]</span><br><span class="line"></span><br><span class="line">re.X:</span><br><span class="line">        reStr = &#x27;&#x27;&#x27;\d&#123;3&#125;  #区号</span><br><span class="line">                -\d&#123;8&#125;&#x27;&#x27;&#x27; #号码</span><br><span class="line">        re.findall(reStr,&quot;010-12345678&quot;,re.X) </span><br><span class="line">        [&quot;010-12345678&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="search函数"><a href="#search函数" class="headerlink" title="search函数"></a>search函数</h3><p>re.search 扫描整个字符串并返回第一个成功的匹配。</p>
<p>下面是此函数语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=0)</span><br></pre></td></tr></table></figure>
<p>这里的参数说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>pattern</td>
<td>这是正则表达式来进行匹配。</td>
</tr>
<tr>
<td>string</td>
<td>这是字符串，这将被搜索到的字符串中的任何位置匹配的模式。</td>
</tr>
<tr>
<td>flags</td>
<td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td>
</tr>
</tbody>
</table>
</div>
<p>匹配成功re.search方法返回一个匹配的对象，否则返回None。</p>
<p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>匹配对象的方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>group(num=0)</td>
<td>此方法返回整个匹配（或指定分组num）</td>
</tr>
<tr>
<td>groups()</td>
<td>此方法返回所有元组匹配的子组（空，如果没有）</td>
</tr>
</tbody>
</table>
</div>
<h4 id="例子：-1"><a href="#例子：-1" class="headerlink" title="例子："></a>例子：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span>;</span><br><span class="line"></span><br><span class="line">searchObj = re.search( <span class="string">r&#x27;(.*) are (.*?) .*&#x27;</span>, line, re.M|re.I)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> searchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group() : &quot;</span>, searchObj.group()</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group(1) : &quot;</span>, searchObj.group(<span class="number">1</span>)</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group(2) : &quot;</span>, searchObj.group(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;Nothing found!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，它产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matchObj.group() :  Cats are smarter than dogs</span><br><span class="line">matchObj.group(1) :  Cats</span><br><span class="line">matchObj.group(2) :  smarter</span><br></pre></td></tr></table></figure>
<h4 id="re-match与re-search的区别"><a href="#re-match与re-search的区别" class="headerlink" title="re.match与re.search的区别"></a>re.match与re.search的区别</h4><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p>
<h4 id="例子：-2"><a href="#例子：-2" class="headerlink" title="例子："></a>例子：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span>;</span><br><span class="line"></span><br><span class="line">matchObj = re.match( <span class="string">r&#x27;dogs&#x27;</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> matchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;match --&gt; matchObj.group() : &quot;</span>, matchObj.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;No match!!&quot;</span></span><br><span class="line"></span><br><span class="line">searchObj = re.search( <span class="string">r&#x27;dogs&#x27;</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> searchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;search --&gt; searchObj.group() : &quot;</span>, searchObj.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;Nothing found!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">No match!!</span><br><span class="line">search --&gt; matchObj.group() :  dogs</span><br></pre></td></tr></table></figure>
<h3 id="搜索和替换"><a href="#搜索和替换" class="headerlink" title="搜索和替换"></a>搜索和替换</h3><p>Python 的re模块提供了re.sub用于替换字符串中的匹配项。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, max=0)</span><br></pre></td></tr></table></figure>
<p>返回的字符串是在字符串中用 RE 最左边不重复的匹配来替换。如果模式没有发现，字符将被没有改变地返回。 可选参数 count 是模式匹配后替换的最大次数；count 必须是非负整数。缺省值是 0 表示替换所有的匹配。 实例：</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p>下面是一个爬虫做翻页面例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://hr.tencent.com/position.php?&amp;start=10&quot;</span></span><br><span class="line">page = re.search(<span class="string">&#x27;start=(\d+)&#x27;</span>,url).group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">nexturl = re.sub(<span class="string">r&#x27;start=(\d+)&#x27;</span>, <span class="string">&#x27;start=&#x27;</span>+<span class="built_in">str</span>(<span class="built_in">int</span>(page)+<span class="number">10</span>), url)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Next Url : &quot;</span>, nexturl</span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Next Url :  http://hr.tencent.com/position.php?&amp;start=20</span><br></pre></td></tr></table></figure>
<h1 id="页面解析之结构化数据"><a href="#页面解析之结构化数据" class="headerlink" title="页面解析之结构化数据"></a>页面解析之结构化数据</h1><p>结构化的数据是最好处理，一般都是类似JSON格式的字符串，直接解析JSON数据，提取JSON的关键字段即可。</p>
<h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式；适用于进行数据交互的场景，比如网站前台与后台之间的数据交互</p>
<p>Python 2.7中自带了JSON模块，直接import json就可以使用了。</p>
<p>Json模块提供了四个功能：dumps、dump、loads、load,用于字符串 和 python数据类型间进行转换</p>
<p><a target="_blank" rel="noopener" href="http://docs.python.org/library/json.html">Python操作json的标准api库参考</a></p>
<p><a target="_blank" rel="noopener" href="http://tool.oschina.net/codeformat/json">在线JSON格式化代码</a></p>
<h3 id="1-json-loads"><a href="#1-json-loads" class="headerlink" title="1. json.loads()"></a>1. json.loads()</h3><p>实现：json字符串 转化 python的类型，返回一个python的类型</p>
<p>从json到python的类型转化对照如下：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/json2.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">a=<span class="string">&quot;[1,2,3,4]&quot;</span></span><br><span class="line">b=<span class="string">&#x27;&#123;&quot;k1&quot;:1,&quot;k2&quot;:2&#125;&#x27;</span><span class="comment">#当字符串为字典时&#123;&#125;外面必须是&#x27;&#x27;单引号&#123;&#125;里面必须是&quot;&quot;双引号</span></span><br><span class="line"><span class="built_in">print</span> json.loads(a) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.loads(b) </span><br><span class="line">&#123;<span class="string">&#x27;k2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;k1&#x27;</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(<span class="string">r&#x27;http://api.douban.com/v2/book/isbn/9787218087351&#x27;</span>)</span><br><span class="line"></span><br><span class="line">hjson = json.loads(response.read())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> hjson.keys()</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;rating&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;images&#x27;</span>][<span class="string">&#x27;large&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;summary&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h3 id="2-json-dumps"><a href="#2-json-dumps" class="headerlink" title="2. json.dumps()"></a>2. json.dumps()</h3><p>实现python类型转化为json字符串，返回一个str对象</p>
<p>从python原始类型向json类型的转化对照如下：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/json.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">b =&#123;<span class="string">&quot;k1&quot;</span>:<span class="number">1</span>,<span class="string">&quot;k2&quot;</span>:<span class="number">2</span>&#125;</span><br><span class="line">c = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">json.dumps(a)</span><br><span class="line"><span class="string">&#x27;[1, 2, 3, 4]&#x27;</span></span><br><span class="line"></span><br><span class="line">json.dumps(b)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;k2&quot;: 2, &quot;k1&quot;: 1&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">json.dumps(c)</span><br><span class="line"><span class="string">&#x27;[1, 2, 3, 4]&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="json-dumps-中的ensure-ascii-参数引起的中文编码问题"><a href="#json-dumps-中的ensure-ascii-参数引起的中文编码问题" class="headerlink" title="json.dumps 中的ensure_ascii 参数引起的中文编码问题"></a>json.dumps 中的ensure_ascii 参数引起的中文编码问题</h4><p>如果Python Dict字典含有中文，json.dumps 序列化时对中文默认使用的ascii编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">b = &#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;中国&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">json.dumps(b)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;name&quot;: &quot;\\u4e2d\\u56fd&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.dumps(b)</span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;\u4e2d\u56fd&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(b))</span><br><span class="line">&#123;<span class="string">&#x27;confidence&#x27;</span>: <span class="number">1.0</span>, <span class="string">&#x27;encoding&#x27;</span>: <span class="string">&#x27;ascii&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>‘中国’ 中的ascii 字符码，而不是真正的中文。</p>
<p>想输出真正的中文需要指定<strong>ensure_ascii=False</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">json.dumps(b,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;name&quot;: &quot;\xe6\x88\x91&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.dumps(b,ensure_ascii=<span class="literal">False</span>) </span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;我&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(b,ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">&#123;<span class="string">&#x27;confidence&#x27;</span>: <span class="number">0.7525</span>, <span class="string">&#x27;encoding&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-json-dump"><a href="#3-json-dump" class="headerlink" title="3. json.dump()"></a>3. json.dump()</h3><p>把Python类型 以 字符串的形式 写到文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">json.dump(a,<span class="built_in">open</span>(<span class="string">&quot;digital.json&quot;</span>,<span class="string">&quot;w&quot;</span>))</span><br><span class="line">b = &#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;我&quot;</span>&#125;</span><br><span class="line">json.dump(b,<span class="built_in">open</span>(<span class="string">&quot;name.json&quot;</span>,<span class="string">&quot;w&quot;</span>),ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">json.dump(b,<span class="built_in">open</span>(<span class="string">&quot;name2.json&quot;</span>,<span class="string">&quot;w&quot;</span>),ensure_ascii=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-json-load"><a href="#4-json-load" class="headerlink" title="4. json.load()"></a>4. json.load()</h3><p>读取 文件中json形式的字符串元素 转化成python类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">number = json.load(<span class="built_in">open</span>(<span class="string">&quot;digital.json&quot;</span>))</span><br><span class="line"><span class="built_in">print</span> number</span><br><span class="line">b = json.load(<span class="built_in">open</span>(<span class="string">&quot;name.json&quot;</span>))</span><br><span class="line"><span class="built_in">print</span> b</span><br><span class="line">b.keys()</span><br><span class="line"><span class="built_in">print</span> b[<span class="string">&#x27;name&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h4 id="实战项目-1"><a href="#实战项目-1" class="headerlink" title="实战项目"></a>实战项目</h4><p>获取 lagou 城市表信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"></span><br><span class="line">url =<span class="string">&#x27;http://www.lagou.com/lbs/getAllCitySearchLabels.json?&#x27;</span></span><br><span class="line">request =urllib2.Request(url)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="built_in">print</span> response.code</span><br><span class="line">resHtml = response.read()</span><br><span class="line">jsonobj = json.loads(resHtml)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(jsonobj)</span><br><span class="line"><span class="built_in">print</span> jsonobj</span><br><span class="line"></span><br><span class="line">citylist =[]</span><br><span class="line"></span><br><span class="line">allcitys = jsonobj[<span class="string">&#x27;content&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;allCitySearchLabels&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> allcitys.keys()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> allcitys:</span><br><span class="line">    <span class="built_in">print</span> <span class="built_in">type</span>(allcitys[key])</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> allcitys[key]:</span><br><span class="line">        name =item[<span class="string">&#x27;name&#x27;</span>].encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span> name,<span class="built_in">type</span>(name)</span><br><span class="line">        citylist.append(name)</span><br><span class="line"></span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;city.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">content = json.dumps(citylist,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> content</span><br><span class="line"></span><br><span class="line">fp.write(content)</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02_json.png" alt="img"></p>
<h3 id="JSONPath"><a href="#JSONPath" class="headerlink" title="JSONPath"></a>JSONPath</h3><p>JSON 信息抽取类库，从JSON文档中抽取指定信息的工具</p>
<h4 id="JSONPath与Xpath区别"><a href="#JSONPath与Xpath区别" class="headerlink" title="JSONPath与Xpath区别"></a>JSONPath与Xpath区别</h4><p>JsonPath 对于 JSON 来说，相当于 XPATH 对于XML。</p>
<p>下载地址：</p>
<p><a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/jsonpath/">https://pypi.python.org/pypi/jsonpath/</a></p>
<p>安装方法：</p>
<p>下载jsonpath，解压之后执行’python setup.py install’</p>
<p><a target="_blank" rel="noopener" href="http://goessner.net/articles/JsonPath/">参考文档</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>XPath</strong></th>
<th><strong>JSONPath</strong></th>
<th><strong>Result</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/store/book/author</code></td>
<td><code>$.store.book[*].author</code></td>
<td>the authors of all books in the store</td>
</tr>
<tr>
<td><code>//author</code></td>
<td><code>$..author</code></td>
<td>all authors</td>
</tr>
<tr>
<td><code>/store/*</code></td>
<td><code>$.store.*</code></td>
<td>all things in store, which are some books and a red bicycle.</td>
</tr>
<tr>
<td><code>/store//price</code></td>
<td><code>$.store..price</code></td>
<td>the price of everything in the store.</td>
</tr>
<tr>
<td><code>//book[3]</code></td>
<td><code>$..book[2]</code></td>
<td>the third book</td>
</tr>
<tr>
<td><code>//book[last()]</code></td>
<td><code>$..book[(@.length-1)]</code> <code>$..book[-1:]</code></td>
<td>the last book in order.</td>
</tr>
<tr>
<td><code>//book[position()&lt;3]</code></td>
<td><code>$..book[0,1]</code> <code>$..book[:2]</code></td>
<td>the first two books</td>
</tr>
<tr>
<td><code>//book[isbn]</code></td>
<td><code>$..book[?(@.isbn)]</code></td>
<td>filter all books with isbn number</td>
</tr>
<tr>
<td><code>//book[price&lt;10]</code></td>
<td><code>$..book[?(@.price&lt;10)]</code></td>
<td>filter all books cheapier than 10</td>
</tr>
<tr>
<td><code>//*</code></td>
<td><code>$..*</code></td>
<td>all Elements in XML document. All members of JSON structure.</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h4><p>还是以 <a target="_blank" rel="noopener" href="http://www.lagou.com/lbs/getAllCitySearchLabels.json">http://www.lagou.com/lbs/getAllCitySearchLabels.json</a> 为例，获取所有城市</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line">url =<span class="string">&#x27;http://www.lagou.com/lbs/getAllCitySearchLabels.json&#x27;</span></span><br><span class="line">request =urllib2.Request(url)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="built_in">print</span> response.code</span><br><span class="line">resHtml = response.read()</span><br><span class="line"></span><br><span class="line"><span class="comment">##detect charset</span></span><br><span class="line"><span class="built_in">print</span> chardet.detect(resHtml)</span><br><span class="line"></span><br><span class="line">jsonobj = json.loads(resHtml)</span><br><span class="line">citylist = jsonpath.jsonpath(jsonobj,<span class="string">&#x27;$..name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> citylist</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(citylist)</span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;city.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">content = json.dumps(citylist,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> content</span><br><span class="line"></span><br><span class="line">fp.write(content.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<h3 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h3><p>xmltodict模块让使用XML感觉跟操作JSON一样</p>
<p>Python操作XML的第三方库参考：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/martinblech/xmltodict">https://github.com/martinblech/xmltodict</a></p>
<p>模块安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">pip install xmltodict</span><br><span class="line"><span class="keyword">import</span> xmltodict</span><br><span class="line"></span><br><span class="line">bookdict = xmltodict.parse(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        &lt;bookstore&gt;</span></span><br><span class="line"><span class="string">            &lt;book&gt;</span></span><br><span class="line"><span class="string">                  &lt;title lang=&quot;eng&quot;&gt;Harry Potter&lt;/title&gt;</span></span><br><span class="line"><span class="string">                  &lt;price&gt;29.99&lt;/price&gt;</span></span><br><span class="line"><span class="string">            &lt;/book&gt;</span></span><br><span class="line"><span class="string">            &lt;book&gt;</span></span><br><span class="line"><span class="string">                  &lt;title lang=&quot;eng&quot;&gt;Learning XML&lt;/title&gt;</span></span><br><span class="line"><span class="string">                  &lt;price&gt;39.95&lt;/price&gt;</span></span><br><span class="line"><span class="string">            &lt;/book&gt;</span></span><br><span class="line"><span class="string">    &lt;/bookstore&gt;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> bookdict.keys()</span><br><span class="line">[<span class="string">u&#x27;bookstore&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> json.dumps(bookdict,indent=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;bookstore&quot;: &#123;</span><br><span class="line">        &quot;book&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;title&quot;: &#123;</span><br><span class="line">                    &quot;@lang&quot;: &quot;eng&quot;, </span><br><span class="line">                    &quot;#text&quot;: &quot;Harry Potter&quot;</span><br><span class="line">                &#125;, </span><br><span class="line">                &quot;price&quot;: &quot;29.99&quot;</span><br><span class="line">            &#125;, </span><br><span class="line">            &#123;</span><br><span class="line">                &quot;title&quot;: &#123;</span><br><span class="line">                    &quot;@lang&quot;: &quot;eng&quot;, </span><br><span class="line">                    &quot;#text&quot;: &quot;Learning XML&quot;</span><br><span class="line">                &#125;, </span><br><span class="line">                &quot;price&quot;: &quot;39.95&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="数据提取总结"><a href="#数据提取总结" class="headerlink" title="数据提取总结"></a>数据提取总结</h3><ul>
<li><p>HTML、XML</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">XPath</span><br><span class="line">CSS选择器</span><br><span class="line">正则表达式</span><br></pre></td></tr></table></figure>
</li>
<li><p>JSON</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JSONPath</span><br><span class="line">转化成Python类型进行操作（json类）</span><br></pre></td></tr></table></figure>
</li>
<li><p>XML</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">转化成Python类型（xmltodict）</span><br><span class="line">XPath</span><br><span class="line">CSS选择器</span><br><span class="line">正则表达式</span><br></pre></td></tr></table></figure>
</li>
<li><p>其他（js、文本、电话号码、邮箱地址）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">正则表达式</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/" class="post-title-link" itemprop="url">爬虫3</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-26 14:19:49" itemprop="dateCreated datePublished" datetime="2022-04-26T14:19:49+08:00">2022-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-29 21:51:28" itemprop="dateModified" datetime="2022-10-29T21:51:28+08:00">2022-10-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CTF/" itemprop="url" rel="index"><span itemprop="name">CTF</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h2><p>比如在这里我们看这么一个示例网站：<a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/，">https://static4.scrape.cuiqingcai.com/，</a></p>
<p><img src="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/1.png" alt="1"></p>
<p>这个网站在内部实现返回响应的逻辑的时候特意加了 5 秒的延迟，也就是说如果我们用 requests 来爬取其中某个页面的话，至少需要 5 秒才能得到响应。</p>
<p>另外这个网站的逻辑结构在之前的案例中我们也分析过，其内容就是电影数据，一共 100 部，每个电影的详情页是一个自增 ID，从 1~100，比如 <a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/detail/43">https://static4.scrape.cuiqingcai.com/detail/43</a> 就代表第 43 部电影，如图所示。</p>
<p><img src="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/2.png" alt="2"></p>
<p>下面我们来用 requests 写一个遍历程序，直接遍历 1~100 部电影数据，代码实现如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import logging</span><br><span class="line">import time</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   format=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">TOTAL_NUMBER = <span class="number">100</span></span><br><span class="line">BASE_URL = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/detail/&#123;id&#125;&#x27;</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> id <span class="keyword">in</span> range(<span class="number">1</span>, TOTAL_NUMBER + <span class="number">1</span>):</span><br><span class="line">   url = BASE_URL.format(id=id)</span><br><span class="line">   logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">   response = requests.get(url)</span><br><span class="line">end_time = time.time()</span><br><span class="line">logging.info(<span class="string">&#x27;total time %s seconds&#x27;</span>, end_time - start_time)</span><br></pre></td></tr></table></figure>
<p>这里我们直接用循环的方式构造了 100 个详情页的爬取，使用的是 requests 单线程，在爬取之前和爬取之后记录下时间，最后输出爬取了 100 个页面消耗的时间。</p>
<p>由于每个页面都至少要等待 5 秒才能加载出来，因此 100 个页面至少要花费 500 秒的时间，总的爬取时间最终为 513.6 秒，将近 9 分钟。</p>
<p>这个在实际情况下是很常见的，有些网站本身加载速度就比较慢，稍慢的可能 1~3 秒，更慢的说不定 10 秒以上才可能加载出来。如果我们用 requests 单线程这么爬取的话，总的耗时是非常多的。此时如果我们开了多线程或多进程来爬取的话，其爬取速度确实会成倍提升，但有没有更好的解决方案呢？</p>
<p>本课时我们就来了解一下使用异步执行方式来加速的方法，此种方法对于 IO 密集型任务非常有效。如将其应用到网络爬虫中，爬取效率甚至可以成百倍地提升。</p>
<h2 id="基本了解"><a href="#基本了解" class="headerlink" title="基本了解"></a>基本了解</h2><p>在了解异步协程之前，我们首先得了解一些基础概念，如阻塞和非阻塞、同步和异步、多进程和协程。</p>
<h3 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h3><p>阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续处理其他的事情，则称该程序在该操作上是阻塞的。</p>
<p>常见的阻塞形式有：网络 I/O 阻塞、磁盘 I/O 阻塞、用户输入阻塞等。阻塞是无处不在的，包括 CPU 切换上下文时，所有的进程都无法真正处理事情，它们也会被阻塞。如果是多核 CPU 则正在执行上下文切换操作的核不可被利用。</p>
<h3 id="非阻塞"><a href="#非阻塞" class="headerlink" title="非阻塞"></a>非阻塞</h3><p>程序在等待某操作过程中，自身不被阻塞，可以继续处理其他的事情，则称该程序在该操作上是非阻塞的。</p>
<p>非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。</p>
<p>非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的。</p>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，我们称这些程序单元是同步执行的。</p>
<p>例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的。</p>
<p>简言之，同步意味着有序。</p>
<h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式，不相关的程序单元之间可以是异步的。</p>
<p>例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定。</p>
<p>简言之，异步意味着无序。</p>
<h3 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h3><p>多进程就是利用 CPU 的多核优势，在同一时间并行地执行多个任务，可以大大提高执行效率。</p>
<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>协程，英文叫作 Coroutine，又称微线程、纤程，协程是一种用户态的轻量级线程。</p>
<p>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。</p>
<p>协程本质上是个单进程，协程相对于多进程来说，无需线程上下文切换的开销，无需原子操作锁定及同步的开销，编程模型也非常简单。</p>
<p>我们可以使用协程来实现异步操作，比如在网络爬虫场景下，我们发出一个请求之后，需要等待一定的时间才能得到响应，但其实在这个等待过程中，程序可以干许多其他的事情，等到响应得到之后才切换回来继续处理，这样可以充分利用 CPU 和其他资源，这就是协程的优势。</p>
<h2 id="协程用法"><a href="#协程用法" class="headerlink" title="协程用法"></a>协程用法</h2><p>接下来，我们来了解下协程的实现，从 Python 3.4 开始，Python 中加入了协程的概念，但这个版本的协程还是以生成器对象为基础的，在 Python 3.5 则增加了 async/await，使得协程的实现更加方便。</p>
<p>Python 中使用协程最常用的库莫过于 asyncio，所以本文会以 asyncio 为基础来介绍协程的使用。</p>
<p>首先我们需要了解下面几个概念。</p>
<ul>
<li>event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，当满足条件发生的时候，就会调用对应的处理方法。</li>
<li>coroutine：中文翻译叫协程，在 Python 中常指代为协程对象类型，我们可以将协程对象注册到时间循环中，它会被事件循环调用。我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。</li>
<li>task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。</li>
<li>future：代表将来执行或没有执行的任务的结果，实际上和 task 没有本质区别。</li>
</ul>
<p>另外我们还需要了解 async/await 关键字，它是从 Python 3.5 才出现的，专门用于定义协程。其中，async 定义一个协程，await 用来挂起阻塞方法的执行。</p>
<h3 id="定义协程"><a href="#定义协程" class="headerlink" title="定义协程"></a>定义协程</h3><p>首先我们来定义一个协程，体验一下它和普通进程在实现上的不同之处，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>首先我们引入了 asyncio 这个包，这样我们才可以使用 async 和 await，然后我们使用 async 定义了一个 execute 方法，方法接收一个数字参数，方法执行之后会打印这个数字。</p>
<p>随后我们直接调用了这个方法，然而这个方法并没有执行，而是返回了一个 coroutine 协程对象。随后我们使用 get_event_loop 方法创建了一个事件循环 loop，并调用了 loop 对象的 run_until_complete 方法将协程注册到事件循环 loop 中，然后启动。最后我们才看到了 execute 方法打印了输出结果。</p>
<p>可见，async 定义的方法就会变成一个无法直接执行的 coroutine 对象，必须将其注册到事件循环中才可以执行。</p>
<p>上面我们还提到了 task，它是对 coroutine 对象的进一步封装，它里面相比 coroutine 对象多了运行状态，比如 running、finished 等，我们可以用这些状态来获取协程对象的执行情况。</p>
<p>在上面的例子中，当我们将 coroutine 对象传递给 run_until_complete 方法的时候，实际上它进行了一个操作就是将 coroutine 封装成了 task 对象，我们也可以显式地进行声明，如下所示：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">   <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了 loop 对象之后，接着调用了它的 create_task 方法将 coroutine 对象转化为了 task 对象，随后我们打印输出一下，发现它是 pending 状态。接着我们将 task 对象添加到事件循环中得到执行，随后我们再打印输出一下 task 对象，发现它的状态就变成了 finished，同时还可以看到其 result 变成了 1，也就是我们定义的 execute 方法的返回结果。</p>
<p>另外定义 task 对象还有一种方式，就是直接通过 asyncio 的 ensure_future 方法，返回结果也是 task 对象，这样的话我们就可以不借助于 loop 来定义，即使我们还没有声明 loop 也可以提前定义好 task 对象，写法如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">   <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="绑定回调"><a href="#绑定回调" class="headerlink" title="绑定回调"></a>绑定回调</h3><p>另外我们也可以为某个 task 绑定一个回调方法，比如我们来看下面的例子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">def callback(task):</span><br><span class="line">   print(<span class="string">&#x27;Status:&#x27;</span>, task.result())</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">task.add_done_callback(callback)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br></pre></td></tr></table></figure>
<p>在这里我们定义了一个 request 方法，请求了百度，获取其状态码，但是这个方法里面我们没有任何 print 语句。随后我们定义了一个 callback 方法，这个方法接收一个参数，是 task 对象，然后调用 print 方法打印了 task 对象的结果。这样我们就定义好了一个 coroutine 对象和一个回调方法，我们现在希望的效果是，当 coroutine 对象执行完毕之后，就去执行声明的 callback 方法。</p>
<p>那么它们二者怎样关联起来呢？很简单，只需要调用 add_done_callback 方法即可，我们将 callback 方法传递给了封装好的 task 对象，这样当 task 执行完毕之后就可以调用 callback 方法了，同时 task 对象还会作为参数传递给 callback 方法，调用 task 对象的 result 方法就可以获取返回结果了。</p>
<p>实际上不用回调方法，直接在 task 运行完毕之后也可以直接调用 result 方法获取结果，如下所示：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;Task Result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure>
<h3 id="多任务协程"><a href="#多任务协程" class="headerlink" title="多任务协程"></a>多任务协程</h3><p>上面的例子我们只执行了一次请求，如果我们想执行多次请求应该怎么办呢？我们可以定义一个 task 列表，然后使用 asyncio 的 wait 方法即可执行，看下面的例子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">tasks = <span class="function">[<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">5</span>)]</span></span><br><span class="line">print(<span class="string">&#x27;Tasks:&#x27;</span>, tasks)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">   print(<span class="string">&#x27;Task Result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure>
<p>这里我们使用一个 for 循环创建了五个 task，组成了一个列表，然后把这个列表首先传递给了 asyncio 的 wait() 方法，然后再将其注册到时间循环中，就可以发起五个任务了。最后我们再将任务的运行结果输出出来，</p>
<h3 id="协程实现"><a href="#协程实现" class="headerlink" title="协程实现"></a>协程实现</h3><p>前面讲了这么多，又是 async，又是 coroutine，又是 task，又是 callback，但似乎并没有看出协程的优势啊？反而写法上更加奇怪和麻烦了，别急，上面的案例只是为后面的使用作铺垫，接下来我们正式来看下协程在解决 IO 密集型任务上有怎样的优势吧！</p>
<p>上面的代码中，我们用一个网络请求作为示例，这就是一个耗时等待的操作，因为我们请求网页之后需要等待页面响应并返回结果。耗时等待的操作一般都是 IO 操作，比如文件读取、网络请求等等。协程对于处理这种操作是有很大优势的，当遇到需要等待的情况的时候，程序可以暂时挂起，转而去执行其他的操作，从而避免一直等待一个程序而耗费过多的时间，充分利用资源。</p>
<p>为了表现出协程的优势，我们还是拿本课时开始介绍的网站 <a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/">https://static4.scrape.cuiqingcai.com/</a> 为例来进行演示，因为该网站响应比较慢，所以我们可以通过爬取时间来直观地感受到爬取速度的提升。</p>
<p>为了让你更好地理解协程的正确使用方法，这里我们先来看看使用协程时常犯的错误，后面再给出正确的例子来对比一下。</p>
<p>首先，我们还是拿之前的 requests 来进行网页请求，接下来我们再重新使用上面的方法请求一遍：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = requests.get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>可以发现和正常的请求并没有什么两样，依然还是顺次执行的，耗时 51 秒，平均一个请求耗时 5 秒，说好的异步处理呢？</p>
<p>其实，要实现异步处理，我们得先要有挂起的操作，当一个任务需要等待 IO 结果的时候，可以挂起当前任务，转而去执行其他任务，这样我们才能充分利用好资源，上面方法都是一本正经的串行走下来，连个挂起都没有，怎么可能实现异步？想太多了。</p>
<p>要实现异步，接下来我们需要了解一下 await 的用法，使用 await 可以将耗时等待的操作挂起，让出控制权。当协程执行的时候遇到 await，时间循环就会将本协程挂起，转而去执行别的协程，直到其他的协程挂起或执行完毕。</p>
<p>所以，我们可能会将代码中的 request 方法改成如下的样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await requests.get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br></pre></td></tr></table></figure>
<p>仅仅是在 requests 前面加了一个 await，然而执行以下代码，会得到如下报错：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">...</span><br><span class="line">Task exception was never retrieved</span><br><span class="line">future: &lt;Task finished coro=&lt;request() done, defined at demo.py:<span class="number">8</span>&gt; exception=TypeError(<span class="string">&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;</span>)&gt;</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"> File <span class="string">&quot;demo.py&quot;</span>, line <span class="number">11</span>, <span class="keyword">in</span> request</span><br><span class="line">   response = await requests.get(url)</span><br><span class="line">TypeError: object Response can<span class="string">&#x27;t be used in &#x27;</span>await<span class="string">&#x27; expression</span></span><br></pre></td></tr></table></figure>
<p>这次它遇到 await 方法确实挂起了，也等待了，但是最后却报了这么个错，这个错误的意思是 requests 返回的 Response 对象不能和 await 一起使用，为什么呢？因为根据官方文档说明，await 后面的对象必须是如下格式之一：</p>
<ul>
<li>A native coroutine object returned from a native coroutine function，一个原生 coroutine 对象。</li>
<li>A generator-based coroutine object returned from a function decorated with types.coroutine，一个由 types.coroutine 修饰的生成器，这个生成器可以返回 coroutine 对象。</li>
<li>An object with an <strong>await</strong> method returning an iterator，一个包含 <strong>await</strong> 方法的对象返回的一个迭代器。</li>
</ul>
<p>可以参见：<a target="_blank" rel="noopener" href="https://www.python.org/dev/peps/pep-0492/#await-expression。">https://www.python.org/dev/peps/pep-0492/#await-expression。</a></p>
<p>requests 返回的 Response 不符合上面任一条件，因此就会报上面的错误了。</p>
<p>那么你可能会发现，既然 await 后面可以跟一个 coroutine 对象，那么我用 async 把请求的方法改成 coroutine 对象不就可以了吗？所以就改写成如下的样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def get(url):</span><br><span class="line">   <span class="keyword">return</span> requests.get(url)</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>还是不行，它还不是异步执行，也就是说我们仅仅将涉及 IO 操作的代码封装到 async 修饰的方法里面是不可行的！我们必须要使用支持异步操作的请求方式才可以实现真正的异步，所以这里就需要 <strong>aiohttp</strong> 派上用场了。</p>
<h2 id="使用-aiohttp"><a href="#使用-aiohttp" class="headerlink" title="使用 aiohttp"></a>使用 aiohttp</h2><p>aiohttp 是一个支持异步请求的库，利用它和 asyncio 配合我们可以非常方便地实现异步请求操作。</p>
<p>安装方式如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install aiohttp</span><br></pre></td></tr></table></figure>
<p>官方文档链接为：<a target="_blank" rel="noopener" href="https://aiohttp.readthedocs.io/，它分为两部分，一部分是">https://aiohttp.readthedocs.io/，它分为两部分，一部分是</a> Client，一部分是 Server，详细的内容可以参考官方文档。</p>
<p>下面我们将 aiohttp 用上来，将代码改成如下样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def get(url):</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   response = await session.get(url)</span><br><span class="line">   await response.text()</span><br><span class="line">   await session.close()</span><br><span class="line">   <span class="keyword">return</span> response</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>成功了！我们发现这次请求的耗时由 51 秒变直接成了 6 秒，耗费时间减少了非常非常多。</p>
<p>代码里面我们使用了 await，后面跟了 get 方法，在执行这 10 个协程的时候，如果遇到了 await，那么就会将当前协程挂起，转而去执行其他的协程，直到其他的协程也挂起或执行完毕，再进行下一个协程的执行。</p>
<p>开始运行时，时间循环会运行第一个 task，针对第一个 task 来说，当执行到第一个 await 跟着的 get 方法时，它被挂起，但这个 get 方法第一步的执行是非阻塞的，挂起之后立马被唤醒，所以立即又进入执行，创建了 ClientSession 对象，接着遇到了第二个 await，调用了 session.get 请求方法，然后就被挂起了，由于请求需要耗时很久，所以一直没有被唤醒。</p>
<p>当第一个 task 被挂起了，那接下来该怎么办呢？事件循环会寻找当前未被挂起的协程继续执行，于是就转而执行第二个 task 了，也是一样的流程操作，直到执行了第十个 task 的 session.get 方法之后，全部的 task 都被挂起了。所有 task 都已经处于挂起状态，怎么办？只好等待了。5 秒之后，几个请求几乎同时都有了响应，然后几个 task 也被唤醒接着执行，输出请求结果，最后总耗时，6 秒！</p>
<p>怎么样？这就是异步操作的便捷之处，当遇到阻塞式操作时，任务被挂起，程序接着去执行其他的任务，而不是傻傻地等待，这样可以充分利用 CPU 时间，而不必把时间浪费在等待 IO 上。</p>
<p>你可能会说，既然这样的话，在上面的例子中，在发出网络请求后，既然接下来的 5 秒都是在等待的，在 5 秒之内，CPU 可以处理的 task 数量远不止这些，那么岂不是我们放 10 个、20 个、50 个、100 个、1000 个 task 一起执行，最后得到所有结果的耗时不都是差不多的吗？因为这几个任务被挂起后都是一起等待的。</p>
<p>理论来说确实是这样的，不过有个前提，那就是服务器在同一时刻接受无限次请求都能保证正常返回结果，也就是服务器无限抗压，另外还要忽略 IO 传输时延，确实可以做到无限 task 一起执行且在预想时间内得到结果。但由于不同服务器处理的实现机制不同，可能某些服务器并不能承受这么高的并发，因此响应速度也会减慢。</p>
<p>在这里我们以百度为例，来测试下并发数量为 1、3、5、10、…、500 的情况下的耗时情况，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">def test(number):</span><br><span class="line">   <span class="built_in">start</span> = time.time()</span><br><span class="line"></span><br><span class="line">   async def get(url):</span><br><span class="line">       session = aiohttp.ClientSession()</span><br><span class="line">       response = await session.get(url)</span><br><span class="line">       await response.text()</span><br><span class="line">       await session.close()</span><br><span class="line">       <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">   async def request():</span><br><span class="line">       url = <span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">       await get(url)</span><br><span class="line"></span><br><span class="line">   tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="type">number</span>)]</span><br><span class="line">   loop = asyncio.get_event_loop()</span><br><span class="line">   loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line">   <span class="keyword">end</span> = time.time()</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, number, <span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">500</span>]:</span><br><span class="line">   test(number)</span><br></pre></td></tr></table></figure>
<h2 id="aiohttp"><a href="#aiohttp" class="headerlink" title="aiohttp"></a>aiohttp</h2><p>前面介绍的 asyncio 模块内部实现了对 TCP、UDP、SSL 协议的异步操作，但是对于 HTTP 请求的异步操作来说，我们就需要用到 aiohttp 来实现了。</p>
<p>aiohttp 是一个基于 asyncio 的异步 HTTP 网络模块，它既提供了服务端，又提供了客户端。其中我们用服务端可以搭建一个支持异步处理的服务器，用于处理请求并返回响应，类似于 Django、Flask、Tornado 等一些 Web 服务器。而客户端我们就可以用来发起请求，就类似于 requests 来发起一个 HTTP 请求然后获得响应，但 requests 发起的是同步的网络请求，而 aiohttp 则发起的是异步的。</p>
<p>本课时我们就主要来了解一下 aiohttp 客户端部分的使用。</p>
<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="基本实例"><a href="#基本实例" class="headerlink" title="基本实例"></a>基本实例</h3><p>首先我们来看一个基本的 aiohttp 请求案例，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">fetch</span>(<span class="params">session, url</span>):</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">await</span> response.text(), response.status</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       html, status = <span class="keyword">await</span> fetch(session, <span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">f&#x27;html: <span class="subst">&#123;html[:<span class="number">100</span>]&#125;</span>...&#x27;</span>)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">f&#x27;status: <span class="subst">&#123;status&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   loop = asyncio.get_event_loop()</span><br><span class="line">   loop.run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>我们可以看到其请求方法的定义和之前有了明显的区别，主要有如下几点：</p>
<ul>
<li>首先在导入库的时候，我们除了必须要引入 aiohttp 这个库之外，还必须要引入 asyncio 这个库，因为要实现异步爬取需要启动协程，而协程则需要借助于 asyncio 里面的事件循环来执行。除了事件循环，asyncio 里面也提供了很多基础的异步操作。</li>
<li>异步爬取的方法的定义和之前有所不同，在每个异步方法前面统一要加 async 来修饰。</li>
<li>with as 语句前面同样需要加 async 来修饰，在 Python 中，with as 语句用于声明一个上下文管理器，能够帮我们自动分配和释放资源，而在异步方法中，with as 前面加上 async 代表声明一个支持异步的上下文管理器。</li>
<li>对于一些返回 coroutine 的操作，前面需要加 await 来修饰，如 response 调用 text 方法，查询 API 可以发现其返回的是 coroutine 对象，那么前面就要加 await；而对于状态码来说，其返回值就是一个数值类型，那么前面就不需要加 await。所以，这里可以按照实际情况处理，参考官方文档说明，看看其对应的返回值是怎样的类型，然后决定加不加 await 就可以了。</li>
<li>最后，定义完爬取方法之后，实际上是 main 方法调用了 fetch 方法。要运行的话，必须要启用事件循环，事件循环就需要使用 asyncio 库，然后使用 run_until_complete 方法来运行。</li>
</ul>
<blockquote>
<p>注意在 Python 3.7 及以后的版本中，我们可以使用 asyncio.run(main())<br>来代替最后的启动操作，不需要显式声明事件循环，run 方法内部会自动启动一个事件循环。但这里为了兼容更多的 Python<br>版本，依然还是显式声明了事件循环。</p>
</blockquote>
<h3 id="URL-参数设置"><a href="#URL-参数设置" class="headerlink" title="URL 参数设置"></a>URL 参数设置</h3><p>对于 URL 参数的设置，我们可以借助于 params 参数，传入一个字典即可，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   params = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, params=params) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h4 id="其他请求类型"><a href="#其他请求类型" class="headerlink" title="其他请求类型"></a>其他请求类型</h4><p>另外 aiohttp 还支持其他的请求类型，如 POST、PUT、DELETE 等等，这个和 requests 的使用方式有点类似，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">session.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br><span class="line">session.put(<span class="string">&#x27;http://httpbin.org/put&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br><span class="line">session.delete(<span class="string">&#x27;http://httpbin.org/delete&#x27;</span>)</span><br><span class="line">session.head(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line">session.options(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line">session.patch(<span class="string">&#x27;http://httpbin.org/patch&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POST-数据"><a href="#POST-数据" class="headerlink" title="POST 数据"></a>POST 数据</h4><p>对于 POST 表单提交，其对应的请求头的 Content-type 为 <code>application/x-www-form-urlencoded</code>，我们可以用如下方式来实现，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>对于 POST JSON 数据提交，其对应的请求头的 Content-type 为 application/json，我们只需要将 post 方法的 data 参数改成 json 即可，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, json=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br></pre></td></tr></table></figure>
<h3 id="响应字段"><a href="#响应字段" class="headerlink" title="响应字段"></a>响应字段</h3><p>对于响应来说，我们可以用如下的方法分别获取响应的状态码、响应头、响应体、响应体二进制内容、响应体 JSON 结果，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;headers:&#x27;</span>, response.headers)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;body:&#x27;</span>, <span class="keyword">await</span> response.text())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;bytes:&#x27;</span>, <span class="keyword">await</span> response.read())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;json:&#x27;</span>, <span class="keyword">await</span> response.json())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h3 id="超时设置"><a href="#超时设置" class="headerlink" title="超时设置"></a>超时设置</h3><p>对于超时的设置，我们可以借助于 ClientTimeout 对象，比如这里我要设置 1 秒的超时，可以这么来实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   timeout = aiohttp.ClientTimeout(total=<span class="number">1</span>)</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(timeout=timeout) <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h3 id="并发限制"><a href="#并发限制" class="headerlink" title="并发限制"></a>并发限制</h3><p>由于 aiohttp 可以支持非常大的并发，比如上万、十万、百万都是能做到的，但这么大的并发量，目标网站是很可能在短时间内无法响应的，而且很可能瞬时间将目标网站爬挂掉。所以我们需要控制一下爬取的并发量。</p>
<p>在一般情况下，我们可以借助于 asyncio 的 Semaphore 来控制并发量，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line">CONCURRENCY = <span class="number">5</span></span><br><span class="line">URL = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">semaphore = asyncio.Semaphore(CONCURRENCY)</span><br><span class="line">session = <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_api</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> semaphore:</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;scraping&#x27;</span>, URL)</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(URL) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">await</span> response.text()</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">global</span> session</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   scrape_index_tasks = [asyncio.ensure_future(scrape_api()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)]</span><br><span class="line">   <span class="keyword">await</span> asyncio.gather(*scrape_index_tasks)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>在这里我们声明了 CONCURRENCY 代表爬取的最大并发量为 5，同时声明爬取的目标 URL 为百度。接着我们借助于 Semaphore 创建了一个信号量对象，赋值为 semaphore，这样我们就可以用它来控制最大并发量了。怎么使用呢？我们这里把它直接放置在对应的爬取方法里面，使用 async with 语句将 semaphore 作为上下文对象即可。这样的话，信号量可以控制进入爬取的最大协程数量，最大数量就是我们声明的 CONCURRENCY 的值。</p>
<p>在 main 方法里面，我们声明了 10000 个 task，传递给 gather 方法运行。倘若不加以限制，这 10000 个 task 会被同时执行，并发数量太大。但有了信号量的控制之后，同时运行的 task 的数量最大会被控制在 5 个，这样就能给 aiohttp 限制速度了。</p>
<p>在这里，aiohttp 的基本使用就介绍这么多，更详细的内容还是推荐你到官方文档查阅，链接：<a target="_blank" rel="noopener" href="https://docs.aiohttp.org/。">https://docs.aiohttp.org/。</a></p>
<h2 id="爬取实战"><a href="#爬取实战" class="headerlink" title="爬取实战"></a>爬取实战</h2><p>上面我们介绍了 aiohttp 的基本用法之后，下面我们来根据一个实例实现异步爬虫的实战演练吧。</p>
<p>本次我们要爬取的网站是：<a target="_blank" rel="noopener" href="https://dynamic5.scrape.cuiqingcai.com/">https://dynamic5.scrape.cuiqingcai.com/</a></p>
<p>这是一个书籍网站，整个网站包含了数千本书籍信息，网站是 JavaScript 渲染的，数据可以通过 Ajax 接口获取到，并且接口没有设置任何反爬措施和加密参数，另外由于这个网站比之前的电影案例网站数据量大一些，所以更加适合做异步爬取。</p>
<p>本课时我们要完成的目标有：</p>
<ul>
<li>使用 aiohttp 完成全站的书籍数据爬取。</li>
<li>将数据通过异步的方式保存到 MongoDB 中。</li>
</ul>
<p>在本课时开始之前，请确保你已经做好了如下准备工作：</p>
<ul>
<li>安装好了 Python（最低为 Python 3.6 版本，最好为 3.7 版本或以上），并能成功运行 Python 程序。</li>
<li>了解了 Ajax 爬取的一些基本原理和模拟方法。</li>
<li>了解了异步爬虫的基本原理和 asyncio 库的基本用法。</li>
<li>了解了 aiohttp 库的基本用法。</li>
<li>安装并成功运行了 MongoDB 数据库，并安装了异步存储库 motor。</li>
</ul>
<h3 id="页面分析"><a href="#页面分析" class="headerlink" title="页面分析"></a>页面分析</h3><p>在之前我们讲解了 Ajax 的基本分析方法，本课时的站点结构和之前 Ajax 分析的站点结构类似，都是列表页加详情页的结构，加载方式都是 Ajax，所以我们能轻松分析到如下信息：</p>
<ul>
<li>列表页的 Ajax 请求接口格式为：<code>https://dynamic5.scrape.cuiqingcai.com/api/book/?limit=18&amp;offset=&#123;offset&#125;</code>，limit 的值即为每一页的书的个数，offset 的值为每一页的偏移量，其计算公式为 offset = limit * (page - 1) ，如第 1 页 offset 的值为 0，第 2 页 offset 的值为 18，以此类推。</li>
<li>列表页 Ajax 接口返回的数据里 results 字段包含当前页 18 本书的信息，其中每本书的数据里面包含一个字段 id，这个 id 就是书本身的 ID，可以用来进一步请求详情页。</li>
<li>详情页的 Ajax 请求接口格式为：<code>https://dynamic5.scrape.cuiqingcai.com/api/book/&#123;id&#125;</code>，id 即为书的 ID，可以从列表页的返回结果中获取。</li>
</ul>
<h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>其实一个完善的异步爬虫应该能够充分利用资源进行全速爬取，其思路是维护一个动态变化的爬取队列，每产生一个新的 task 就会将其放入队列中，有专门的爬虫消费者从队列中获取 task 并执行，能做到在最大并发量的前提下充分利用等待时间进行额外的爬取处理。</p>
<p>但上面的实现思路整体较为烦琐，需要设计爬取队列、回调函数、消费者等机制，需要实现的功能较多。由于我们刚刚接触 aiohttp 的基本用法，本课时也主要是了解 aiohttp 的实战应用，所以这里我们将爬取案例的实现稍微简化一下。</p>
<p>在这里我们将爬取的逻辑拆分成两部分，第一部分为爬取列表页，第二部分为爬取详情页。由于异步爬虫的关键点在于并发执行，所以我们可以将爬取拆分为两个阶段：</p>
<ul>
<li>第一阶段为所有列表页的异步爬取，我们可以将所有的列表页的爬取任务集合起来，声明为 task 组成的列表，进行异步爬取。</li>
<li>第二阶段则是拿到上一步列表页的所有内容并解析，拿到所有书的 id 信息，组合为所有详情页的爬取任务集合，声明为 task 组成的列表，进行异步爬取，同时爬取的结果也以异步的方式存储到 MongoDB 里面。</li>
</ul>
<p>因为两个阶段的拆分之后需要串行执行，所以可能不能达到协程的最佳调度方式和资源利用情况，但也差不了很多。但这个实现思路比较简单清晰，代码实现也比较简单，能够帮我们快速了解 aiohttp 的基本使用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/5selenium%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/5selenium%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">爬虫2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-26 14:19:49" itemprop="dateCreated datePublished" datetime="2022-04-26T14:19:49+08:00">2022-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-29 21:49:42" itemprop="dateModified" datetime="2022-10-29T21:49:42+08:00">2022-10-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CTF/" itemprop="url" rel="index"><span itemprop="name">CTF</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>来源:CSDN  参考即可</p>
<p>上个课时我们讲解了 Ajax 的分析方法，利用 Ajax 接口我们可以非常方便地完成数据的爬取。只要我们能找到 Ajax 接口的规律，就可以通过某些参数构造出对应的的请求，数据自然就能被轻松爬取到。</p>
<p>但是，在很多情况下，Ajax 请求的接口通常会包含加密的参数，如 token、sign 等，如：<a target="_blank" rel="noopener" href="https://dynamic2.scrape.cuiqingcai.com/，它的">https://dynamic2.scrape.cuiqingcai.com/，它的</a> Ajax 接口是包含一个 token 参数的，如图所示。<br><img src="https://img-blog.csdnimg.cn/20200817172536726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>由于接口的请求加上了 token 参数，如果不深入分析并找到 token 的构造逻辑，我们是难以直接模拟这些 Ajax 请求的。</p>
<p>此时解决方法通常有两种，一种是深挖其中的逻辑，把其中 token 的构造逻辑完全找出来，再用 Python 复现，构造 Ajax 请求；另外一种方法就是直接通过模拟浏览器的方式，绕过这个过程。因为在浏览器里面我们是可以看到这个数据的，如果能直接把看到的数据爬取下来，当然也就能获取对应的信息了。</p>
<p>由于第 1 种方法难度较高，在这里我们就先介绍第 2 种方法，模拟浏览器爬取。</p>
<p>这里使用的工具为 Selenium，我们先来了解一下 Selenium 的基本使用方法吧。</p>
<p>Selenium 是一个自动化测试工具，利用它可以驱动浏览器执行特定的动作，如点击、下拉等操作，同时还可以获取浏览器当前呈现的页面源代码，做到可见即可爬。对于一些使用 JavaScript 动态渲染的页面来说，此种抓取方式非常有效。本课时就让我们来感受一下它的强大之处吧。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>本课时以 Chrome 为例来讲解 Selenium 的用法。在开始之前，请确保已经正确安装好了 Chrome 浏览器并配置好了 ChromeDriver。另外，还需要正确安装好 Python 的 Selenium 库。</p>
<p>安装过程可以参考：<a target="_blank" rel="noopener" href="https://cuiqingcai.com/5135.html">https://cuiqingcai.com/5135.html</a> 和 <a target="_blank" rel="noopener" href="https://cuiqingcai.com/5141.html。">https://cuiqingcai.com/5141.html。</a></p>
<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>准备工作做好之后，首先来看一下 Selenium 有一些怎样的功能。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)</span><br><span class="line"><span class="built_in">input</span>.send_keys(<span class="string">&#x27;Python&#x27;</span>)</span><br><span class="line"><span class="built_in">input</span>.send_keys(Keys.ENTER)</span><br><span class="line">wait = WebDriverWait(browser, <span class="number">10</span>)</span><br><span class="line">wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;content_left&#x27;</span>)))</span><br><span class="line"><span class="built_in">print</span>(browser.current_url)</span><br><span class="line"><span class="built_in">print</span>(browser.get_cookies())</span><br><span class="line"><span class="built_in">print</span>(browser.page_source) </span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>
<p>运行代码后会自动弹出一个 Chrome 浏览器，浏览器会跳转到百度，然后在搜索框中输入 Python，接着跳转到搜索结果页，如图所示。<br><img src="https://img-blog.csdnimg.cn/20200817173116910.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>此时在控制台的输出结果如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">https://www.baidu.com/s?ie=utf<span class="literal">-8</span>&amp;f=<span class="number">8</span>&amp;rsv_bp=<span class="number">0</span>&amp;rsv_idx=<span class="number">1</span>&amp;tn=baidu&amp;wd=Python&amp;rsv_pq= </span><br><span class="line">c94d0df9000a72d0&amp;rsv_t=<span class="number">07099</span>xvun1ZmC0bf6eQvygJ43IUTTUOl5FCJVPgwG2YREs70GplJjH2F%<span class="number">2</span>BC</span><br><span class="line">Q&amp;rqlang=cn&amp;rsv_enter=<span class="number">1</span>&amp;rsv_sug3=<span class="number">6</span>&amp;rsv_sug2=<span class="number">0</span>&amp;inputT=<span class="number">87</span>&amp;rsv_sug4=<span class="number">87</span> </span><br><span class="line">[&#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>,</span><br><span class="line"> <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;B490B5EBF6F3CD402E515D22BCDA1598&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.baidu.com&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"> <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;BDORZ&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;expiry&#x27;</span>: <span class="number">1491688071.707553</span>&#125;, </span><br><span class="line"> </span><br><span class="line"> &#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"> <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;22473_1441_21084_17001&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.baidu.com&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"> <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;H_PS_PSSID&#x27;</span>&#125;, </span><br><span class="line"></span><br><span class="line"> &#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"> <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;12883875381399993259_00_0_I_R_2_0303_C02F_N_I_I_0&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.www.baidu.com&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"> <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;__bsi&#x27;</span>, </span><br><span class="line"> <span class="string">&#x27;expiry&#x27;</span>: <span class="number">1491601676.69722</span>&#125;]</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;!<span class="literal">--STATUS</span> OK<span class="literal">--</span>&gt;...</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"><span class="number">12345678910111213141516171819202122232425262728</span></span><br></pre></td></tr></table></figure>
<p>源代码过长，在此省略。可以看到，当前我们得到的 URL、Cookies 和源代码都是浏览器中的真实内容。</p>
<p>所以说，如果用 Selenium 来驱动浏览器加载网页的话，就可以直接拿到 JavaScript 渲染的结果了，不用担心使用的是什么加密系统。</p>
<p>下面来详细了解一下 Selenium 的用法。</p>
<h2 id="声明浏览器对象"><a href="#声明浏览器对象" class="headerlink" title="声明浏览器对象"></a>声明浏览器对象</h2><p>Selenium 支持非常多的浏览器，如 Chrome、Firefox、Edge 等，还有 Android、BlackBerry 等手机端的浏览器。</p>
<p>此外，我们可以用如下方式进行初始化：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser = webdriver.Firefox() </span><br><span class="line">browser = webdriver.Edge() </span><br><span class="line">browser = webdriver.Safari()</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>这样就完成了浏览器对象的初始化并将其赋值为 browser 对象。接下来，我们要做的就是调用 browser 对象，让其执行各个动作以模拟浏览器操作。</p>
<h2 id="访问页面"><a href="#访问页面" class="headerlink" title="访问页面"></a>访问页面</h2><p>我们可以用 get 方法来请求网页，只需要把参数传入链接 URL 即可。比如，这里用 get 方法访问淘宝，然后打印出源代码，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">print(browser.page_source) </span><br><span class="line">browser.close()</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>运行后会弹出 Chrome 浏览器并且自动访问淘宝，然后控制台会输出淘宝页面的源代码，随后浏览器关闭。</p>
<p>通过这几行简单的代码，我们就可以驱动浏览器并获取网页源码，非常便捷。</p>
<h2 id="查找节点"><a href="#查找节点" class="headerlink" title="查找节点"></a>查找节点</h2><p>Selenium 可以驱动浏览器完成各种操作，比如填充表单、模拟点击等。举个例子，当我们想要完成向某个输入框输入文字的操作时，首先需要知道这个输入框在哪，而 Selenium 提供了一系列查找节点的方法，我们可以用这些方法来获取想要的节点，以便执行下一步动作或者提取信息。</p>
<h3 id="单个节点"><a href="#单个节点" class="headerlink" title="单个节点"></a>单个节点</h3><p>当我们想要从淘宝页面中提取搜索框这个节点，首先要观察它的源代码，如图所示。<br><img src="https://img-blog.csdnimg.cn/20200817173345550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>可以发现，它的 id 是 q，name 也是 q，此外还有许多其他属性。此时我们就可以用多种方式获取它了。比如，find_element_by_name 代表根据 name 值获取，find_element_by_id 则是根据 id 获取，另外，还有根据 XPath、CSS 选择器等获取的方式。</p>
<p>我们用代码实现一下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">input_first = browser.find_element_by_id(<span class="string">&#x27;q&#x27;</span>) </span><br><span class="line">input_second = browser.find_element_by_css_selector(<span class="string">&#x27;#q&#x27;</span>) </span><br><span class="line">input_third = browser.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;q&quot;]&#x27;</span>) </span><br><span class="line">print(input_first, input_second, input_third) </span><br><span class="line">browser.close()</span><br><span class="line"><span class="number">12345678</span></span><br></pre></td></tr></table></figure>
<p>这里我们使用 3 种方式获取输入框，分别是根据 id、CSS 选择器和 XPath 获取，它们返回的结果完全一致。运行结果如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=<span class="string">&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;</span>,</span><br><span class="line"> element=<span class="string">&quot;0.5649563096161541-1&quot;</span>)&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;selenium.webdriver.remote.webelement.WebElement (session</span><br><span class="line"> =<span class="string">&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;</span>, </span><br><span class="line"> element=<span class="string">&quot;0.5649563096161541-1&quot;</span>)&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;selenium.webdriver.</span><br><span class="line"> remote.webelement.WebElement (session=<span class="string">&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;</span>, </span><br><span class="line"> element=<span class="string">&quot;0.5649563096161541-1&quot;</span>)&gt;</span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<p>可以看到，这 3 个节点的类型是一致的，都是 WebElement。</p>
<p>这里列出所有获取单个节点的方法：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">find_element_by_id </span><br><span class="line">find_element_by_name </span><br><span class="line">find_element_by_xpath </span><br><span class="line">find_element_by_link_text </span><br><span class="line">find_element_by_partial_link_text </span><br><span class="line">find_element_by_tag_name </span><br><span class="line">find_element_by_class_name </span><br><span class="line">find_element_by_css_selector</span><br><span class="line"><span class="number">12345678</span></span><br></pre></td></tr></table></figure>
<p>另外，Selenium 还提供了 find_element 这个通用方法，它需要传入两个参数：查找方式 By 和值。实际上，find_element 就是 find_element_by_id 这种方法的通用函数版本，比如 find_element_by_id(id) 就等价于 find_element(By.ID, id)，二者得到的结果完全一致。我们用代码实现一下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">input_first = browser.find_element(By.ID, <span class="string">&#x27;q&#x27;</span>) </span><br><span class="line">print(input_first) </span><br><span class="line">browser.close()</span><br><span class="line"><span class="number">1234567</span></span><br></pre></td></tr></table></figure>
<p>这种查找方式的功能和上面列举的查找函数完全一致，不过参数更加灵活。</p>
<h3 id="多个节点"><a href="#多个节点" class="headerlink" title="多个节点"></a>多个节点</h3><p>如果在网页中只查找一个目标，那么完全可以用 find_element 方法。但如果有多个节点需要查找，再用 find_element 方法，就只能得到第 1 个节点了。如果要查找所有满足条件的节点，需要用 find_elements 这样的方法。<strong>注意，在这个方法的名称中，element 多了一个 s，注意区分。</strong></p>
<p>举个例子，假如你要查找淘宝左侧导航条的所有条目，就可以这样来实现：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">lis = browser.find_elements_by_css_selector(<span class="string">&#x27;.service-bd li&#x27;</span>) </span><br><span class="line">print(lis) </span><br><span class="line">browser.close()</span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[&lt;<span class="type">selenium.webdriver.remote.webelement.WebElement</span> </span><br><span class="line">(<span class="type">session</span>=<span class="string">&quot;c26290835d4457ebf7d96bfab3740d19&quot;</span>, <span class="type">element</span>=<span class="string">&quot;0.09221044033125603-1&quot;</span>)&gt;,</span><br><span class="line"> </span><br><span class="line">&lt;<span class="type">selenium.webdriver.remote.webelement.WebElement</span> </span><br><span class="line">(<span class="type">session</span>=<span class="string">&quot;c26290835d4457ebf7d96bfab3740d19&quot;</span>, <span class="type">element</span>=<span class="string">&quot;0.09221044033125603-2&quot;</span>)&gt;,</span><br><span class="line"></span><br><span class="line">&lt;<span class="type">selenium.webdriver.remote.webelement.WebElement</span> </span><br><span class="line">(<span class="type">session</span>=<span class="string">&quot;c26290835d4457ebf7d96bfab3740d19&quot;</span>, <span class="type">element</span>=<span class="string">&quot;0.09221044033125603-3&quot;</span>)&gt;<span class="type">...</span></span><br><span class="line"></span><br><span class="line">&lt;<span class="type">selenium.webdriver.remote.webelement.WebElement</span> </span><br><span class="line">(<span class="type">session</span>=<span class="string">&quot;c26290835d4457ebf7d96bfab3740d19&quot;</span>, <span class="type">element</span>=<span class="string">&quot;0.09221044033125603-16&quot;</span>)&gt;]</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>这里简化了输出结果，中间部分省略。</p>
<p>可以看到，得到的内容变成了列表类型，列表中的每个节点都是 WebElement 类型。</p>
<p>也就是说，如果我们用 find_element 方法，只能获取匹配的第一个节点，结果是 WebElement 类型。如果用 find_elements 方法，则结果是列表类型，列表中的每个节点是 WebElement 类型。</p>
<p>这里列出所有获取多个节点的方法：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">find_elements_by_id </span><br><span class="line">find_elements_by_name </span><br><span class="line">find_elements_by_xpath </span><br><span class="line">find_elements_by_link_text </span><br><span class="line">find_elements_by_partial_link_text </span><br><span class="line">find_elements_by_tag_name </span><br><span class="line">find_elements_by_class_name </span><br><span class="line">find_elements_by_css_selector</span><br><span class="line"><span class="number">12345678</span></span><br></pre></td></tr></table></figure>
<p>当然，我们也可以直接用 find_elements 方法来选择，这时可以这样写：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lis = browser.find_elements(By.CSS_SELECTOR, <span class="string">&#x27;.service-bd li&#x27;</span>)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>结果是完全一致的。</p>
<h2 id="节点交互"><a href="#节点交互" class="headerlink" title="节点交互"></a>节点交互</h2><p>Selenium 可以驱动浏览器来执行一些操作，或者说可以让浏览器模拟执行一些动作。比较常见的用法有：输入文字时用 send_keys 方法，清空文字时用 clear 方法，点击按钮时用 click 方法。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">import time </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">input = browser.find_element_by_id(<span class="string">&#x27;q&#x27;</span>) </span><br><span class="line">input.send_keys(<span class="string">&#x27;iPhone&#x27;</span>) </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line">input.clear() </span><br><span class="line">input.send_keys(<span class="string">&#x27;iPad&#x27;</span>) </span><br><span class="line">button = browser.find_element_by_class_name(<span class="string">&#x27;btn-search&#x27;</span>) </span><br><span class="line">button.click()</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>这里首先驱动浏览器打开淘宝，用 find_element_by_id 方法获取输入框，然后用 send_keys 方法输入 iPhone 文字，等待一秒后用 clear 方法清空输入框，接着再次调用 send_keys 方法输入 iPad 文字，之后再用 find_element_by_class_name 方法获取搜索按钮，最后调用 click 方法完成搜索动作。</p>
<p>通过上面的方法，我们就完成了一些常见节点的动作操作，更多的操作可以参见官方文档的交互动作介绍 ：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement。">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement。</a></p>
<h2 id="动作链"><a href="#动作链" class="headerlink" title="动作链"></a>动作链</h2><p>在上面的实例中，一些交互动作都是针对某个节点执行的。比如，对于输入框，我们调用它的输入文字和清空文字方法；对于按钮，我们调用它的点击方法。其实，还有另外一些操作，它们没有特定的执行对象，比如鼠标拖拽、键盘按键等，这些动作用另一种方式来执行，那就是动作链。</p>
<p>比如，现在我要实现一个节点的拖拽操作，将某个节点从一处拖拽到另外一处，可以这样实现：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.webdriver import ActionChains </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">url = <span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">browser.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>) </span><br><span class="line">source = browser.find_element_by_css_selector(<span class="string">&#x27;#draggable&#x27;</span>) </span><br><span class="line">target = browser.find_element_by_css_selector(<span class="string">&#x27;#droppable&#x27;</span>) </span><br><span class="line">actions = ActionChains(browser) </span><br><span class="line">actions.drag_and_drop(source, target) </span><br><span class="line">actions.perform()</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>首先，打开网页中的一个拖拽实例，依次选中要拖拽的节点和拖拽到的目标节点，接着声明 ActionChains 对象并将其赋值为 actions 变量，然后通过调用 actions 变量的 drag_and_drop 方法，再调用 perform 方法执行动作，此时就完成了拖拽操作，如图所示：<img src="https://img-blog.csdnimg.cn/20200817174903639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>拖拽前页面<img src="https://img-blog.csdnimg.cn/20200817174919366.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>拖拽后页面<br>以上两图分别为在拖拽前和拖拽后的结果。</p>
<p>更多的动作链操作可以参考官方文档的动作链介绍：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains。">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains。</a></p>
<h2 id="执行-JavaScript"><a href="#执行-JavaScript" class="headerlink" title="执行 JavaScript"></a>执行 JavaScript</h2><p>Selenium API 并没有提供实现某些操作的方法，比如，下拉进度条。但它可以直接模拟运行 JavaScript，此时使用 execute_script 方法即可实现，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.scrollTo(0, document.body.scrollHeight)&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;alert(&quot;To Bottom&quot;)&#x27;</span>)</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>这里利用 <strong>execute_script</strong> 方法将进度条下拉到最底部，然后弹出 alert 提示框。</p>
<p>有了这个方法，基本上 API 没有提供的所有功能都可以用执行 JavaScript 的方式来实现了。</p>
<h2 id="获取节点信息"><a href="#获取节点信息" class="headerlink" title="获取节点信息"></a>获取节点信息</h2><p>前面说过，通过 page_source 属性可以获取网页的源代码，接着就可以使用解析库（如正则表达式、Beautiful Soup、pyquery 等）来提取信息了。</p>
<p>不过，既然 Selenium 已经提供了选择节点的方法，并且返回的是 WebElement 类型，那么它也有相关的方法和属性来直接提取节点信息，如属性、文本等。这样的话，我们就可以不用通过解析源代码来提取信息了，非常方便。</p>
<p>接下来，我们就来看看可以通过怎样的方式来获取节点信息吧。</p>
<h3 id="获取属性"><a href="#获取属性" class="headerlink" title="获取属性"></a>获取属性</h3><p>我们可以使用 get_attribute 方法来获取节点的属性，但是前提是得先选中这个节点，示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">logo = browser.find_element_by_class_name(<span class="string">&#x27;logo-image&#x27;</span>)</span><br><span class="line">print(logo) </span><br><span class="line">print(logo.get_attribute(<span class="string">&#x27;src&#x27;</span>))</span><br><span class="line"><span class="number">1234567</span></span><br></pre></td></tr></table></figure>
<p>运行之后，程序便会驱动浏览器打开该页面，然后获取 class 为 logo-image 的节点，最后打印出它的 src 属性。</p>
<p>控制台的输出结果如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement </span><br><span class="line">(session=<span class="string">&quot;7f4745d35a104759239b53f68a6f27d0&quot;</span>, </span><br><span class="line">element=<span class="string">&quot;cd7c72b4-4920-47ed-91c5-ea06601dc509&quot;</span>)&gt; </span><br><span class="line">https://dynamic2.scrape .cuiqingcai.com/img/logo.a508a8f0.png</span><br><span class="line"><span class="number">1234</span></span><br></pre></td></tr></table></figure>
<p>通过 get_attribute 方法，我们只需要传入想要获取的属性名，就可以得到它的值了。</p>
<h3 id="获取文本值"><a href="#获取文本值" class="headerlink" title="获取文本值"></a>获取文本值</h3><p>每个 WebElement 节点都有 text 属性，直接调用这个属性就可以得到节点内部的文本信息，这相当于 pyquery 的 text 方法，示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;</span> </span><br><span class="line">browser.get(url)</span><br><span class="line">input = browser.find_element_by_class_name(<span class="string">&#x27;logo-title&#x27;</span>) </span><br><span class="line">print(input.text)</span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>
<p>这里依然先打开页面，然后获取 class 为 logo-title 这个节点，再将其文本值打印出来。</p>
<p>控制台的输出结果如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Scrape</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="获取-ID、位置、标签名、大小"><a href="#获取-ID、位置、标签名、大小" class="headerlink" title="获取 ID、位置、标签名、大小"></a>获取 ID、位置、标签名、大小</h3><p>另外，WebElement 节点还有一些其他属性，比如 id 属性可以获取节点 id，location 属性可以获取该节点在页面中的相对位置，tag_name 属性可以获取标签名称，size 属性可以获取节点的大小，也就是宽高，这些属性有时候还是很有用的。示例如下：<br>另外，WebElement 节点还有一些其他属性，比如 id 属性可以获取节点 id，location 属性可以获取该节点在页面中的相对位置，tag_name 属性可以获取标签名称，size 属性可以获取节点的大小，也就是宽高，这些属性有时候还是很有用的。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">input = browser.find_element_by_class_name(<span class="string">&#x27;logo-title&#x27;</span>) </span><br><span class="line">print(input.id) </span><br><span class="line">print(input.location) </span><br><span class="line">print(input.tag_name) </span><br><span class="line">print(input.size)</span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p>这里首先获得 class 为 logo-title 这个节点，然后调用其 id、location、tag_name、size 属性来获取对应的属性值。</p>
<h2 id="切换-Frame"><a href="#切换-Frame" class="headerlink" title="切换 Frame"></a>切换 Frame</h2><p>我们知道网页中有一种节点叫作 iframe，也就是子 Frame，相当于页面的子页面，它的结构和外部网页的结构完全一致。Selenium 打开页面后，默认是在父级 Frame 里面操作，而此时如果页面中还有子 Frame，Selenium 是不能获取到子 Frame 里面的节点的。这时就需要使用 switch_to.frame 方法来切换 Frame。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import time </span><br><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.common.exceptions import NoSuchElementException </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">browser.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    logo = browser.find_element_by_class_name(<span class="string">&#x27;logo&#x27;</span>) </span><br><span class="line">except NoSuchElementException:</span><br><span class="line">    print(<span class="string">&#x27;NO LOGO&#x27;</span>) </span><br><span class="line">browser.switch_to.parent_frame() </span><br><span class="line">logo = browser.find_element_by_class_name(<span class="string">&#x27;logo&#x27;</span>)</span><br><span class="line">print(logo) </span><br><span class="line">print(logo.text)</span><br><span class="line"><span class="number">123456789101112131415</span></span><br></pre></td></tr></table></figure>
<p>控制台输出：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NO LOGO </span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement</span><br><span class="line">(session=<span class="string">&quot;4bb8ac03ced4ecbdefef03ffdc0e4ccd&quot;</span>, </span><br><span class="line">element=<span class="string">&quot;0.13792611320464965-2&quot;</span>)&gt; </span><br><span class="line">RUNOOB.COM</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>这里还是以前面演示动作链操作的网页为例，首先通过 switch_to.frame 方法切换到子 Frame 里面，然后尝试获取子 Frame 里的 logo 节点（这是不能找到的），如果找不到的话，就会抛出 NoSuchElementException 异常，异常被捕捉之后，就会输出 NO LOGO。接下来，我们需要重新切换回父级 Frame，然后再次重新获取节点，发现此时可以成功获取了。</p>
<p>所以，当页面中包含子 Frame 时，如果想获取子 Frame 中的节点，需要先调用 switch_to.frame 方法切换到对应的 Frame，然后再进行操作。</p>
<h2 id="延时等待"><a href="#延时等待" class="headerlink" title="延时等待"></a>延时等待</h2><p>在 Selenium 中，get 方法会在网页框架加载结束后结束执行，此时如果获取 page_source，可能并不是浏览器完全加载完成的页面，如果某些页面有额外的 Ajax 请求，我们在网页源代码中也不一定能成功获取到。所以，这里需要延时等待一定时间，确保节点已经加载出来。</p>
<p>这里等待的方式有两种：一种是<strong>隐式等待</strong>，一种是<strong>显式等待</strong>。</p>
<h3 id="隐式等待"><a href="#隐式等待" class="headerlink" title="隐式等待"></a>隐式等待</h3><p>当使用隐式等待执行测试的时候，如果 Selenium 没有在 DOM 中找到节点，将继续等待，超出设定时间后，则抛出找不到节点的异常。换句话说，隐式等待可以在我们查找节点而节点并没有立即出现的时候，等待一段时间再查找 DOM，默认的时间是 0。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.implicitly_wait(<span class="number">10</span>) </span><br><span class="line">browser.get(<span class="string">&#x27;https://dynamic2. scrape.cuiqingcai.com/&#x27;</span>) </span><br><span class="line">input = browser.find_element_by_class_name(<span class="string">&#x27;logo-image&#x27;</span>) </span><br><span class="line">print(input)</span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>
<p>在这里我们用 implicitly_wait 方法实现了隐式等待。</p>
<h3 id="显式等待"><a href="#显式等待" class="headerlink" title="显式等待"></a>显式等待</h3><p>隐式等待的效果其实并没有那么好，因为我们只规定了一个固定时间，而页面的加载时间会受到网络条件的影响。</p>
<p>这里还有一种更合适的显式等待方法，它指定要查找的节点，然后指定一个最长等待时间。如果在规定时间内加载出来了这个节点，就返回查找的节点；如果到了规定时间依然没有加载出该节点，则抛出超时异常。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.webdriver.common.by import By </span><br><span class="line">from selenium.webdriver.support.ui import WebDriverWait </span><br><span class="line">from selenium.webdriver.support import expected_conditions as EC </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>) </span><br><span class="line">wait = WebDriverWait(browser, <span class="number">10</span>) </span><br><span class="line">input = wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;q&#x27;</span>))) </span><br><span class="line">button =  wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">&#x27;.btn-search&#x27;</span>))) </span><br><span class="line">print(input, button)</span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<p>这里首先引入 WebDriverWait 这个对象，指定最长等待时间，然后调用它的 until() 方法，传入要等待条件 expected_conditions。比如，这里传入了 presence_of_element_located 这个条件，代表节点出现，其参数是节点的定位元组，也就是 ID 为 q 的节点搜索框。</p>
<p>这样做的效果就是，在 10 秒内如果 ID 为 q 的节点（即搜索框）成功加载出来，就返回该节点；如果超过 10 秒还没有加载出来，就抛出异常。</p>
<p>对于按钮，我们可以更改一下等待条件，比如改为 element_to_be_clickable，也就是可点击，所以查找按钮时先查找 CSS 选择器为.btn-search 的按钮，如果 10 秒内它是可点击的，也就代表它成功加载出来了，就会返回这个按钮节点；如果超过 10 秒还不可点击，也就是没有加载出来，就抛出异常。</p>
<p>现在我们运行代码，它在网速较佳的情况下是可以成功加载出来的。</p>
<p>控制台的输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement </span><br><span class="line">(session=<span class="string">&quot;07dd2fbc2d5b1ce40e82b9754aba8fa8&quot;</span>, </span><br><span class="line">element=<span class="string">&quot;0.5642646294074107-1&quot;</span>)&gt;</span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement </span><br><span class="line">(session=<span class="string">&quot;07dd2fbc2d5b1ce40e82b9754aba8fa8&quot;</span>, </span><br><span class="line">element=<span class="string">&quot;0.5642646294074107-2&quot;</span>)&gt;</span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>
<p>可以看到，控制台成功输出了两个节点，它们都是 WebElement 类型。</p>
<p>如果网络有问题，10 秒内没有成功加载，那就抛出 TimeoutException 异常，此时控制台的输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TimeoutException Traceback (most recent call last) </span><br><span class="line">&lt;ipython<span class="literal">-input-4-f3d73973b223</span>&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">      <span class="number">7</span> browser.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>)</span><br><span class="line">      <span class="number">8</span> wait = WebDriverWait(browser, <span class="number">10</span>) </span><br><span class="line"><span class="literal">----</span>&gt; <span class="number">9</span> input = wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;q&#x27;</span>)))</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>关于等待条件，其实还有很多，比如判断标题内容，判断某个节点内是否出现了某文字等。下表我列出了所有的等待条件。<br><img src="https://img-blog.csdnimg.cn/20200818115631701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200818115638937.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>更多详细的等待条件的参数及用法介绍可以参考官方文档：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions。">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions。</a></p>
<h2 id="前进后退"><a href="#前进后退" class="headerlink" title="前进后退"></a>前进后退</h2><p>平常我们使用浏览器时都有前进和后退功能，Selenium 也可以完成这个操作，它使用 back 方法后退，使用 forward 方法前进。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import time </span><br><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>) </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>) </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.python.org/&#x27;</span>) </span><br><span class="line">browser.back() </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line">browser.forward() </span><br><span class="line">browser.close()</span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<p>这里我们连续访问 3 个页面，然后调用 back 方法回到第 2 个页面，接下来再调用 forward 方法又可以前进到第 3 个页面</p>
<h2 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h2><p>使用 Selenium，还可以方便地对 Cookies 进行操作，例如获取、添加、删除 Cookies 等。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>) </span><br><span class="line">print(browser.get_cookies()) </span><br><span class="line">browser.add_cookie(&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;www.zhihu.com&#x27;</span>, <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>&#125;) </span><br><span class="line">print(browser.get_cookies()) </span><br><span class="line">browser.delete_all_cookies() </span><br><span class="line">print(browser.get_cookies())</span><br><span class="line"><span class="number">12345678</span></span><br></pre></td></tr></table></figure>
<p>首先，我们访问知乎，加载完成后，浏览器实际上已经生成 Cookies 了。接着，调用 get_cookies 方法获取所有的 Cookies。然后，我们再添加一个 Cookie，这里传入一个字典，有 name、domain 和 value 等内容。接下来，再次获取所有的 Cookies，可以发现，结果会多出这一项新加的 Cookie。最后，调用 delete_all_cookies 方法删除所有的 Cookies。再重新获取，发现结果就为空了。</p>
<p>控制台的输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;&quot;NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY=|1491604091|236e34290a6f407bfbb517888849ea509ac366d0&quot;&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.zhihu.com&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;l_cap_id&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;expiry&#x27;</span>: <span class="number">1494196091.403418</span>&#125;,<span class="type">...</span>] </span><br><span class="line">[&#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.www.zhihu.com&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;name&#x27;</span>&#125;, </span><br><span class="line">&#123;<span class="string">&#x27;secure&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;&quot;NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY=|1491604091|236e34290a6f407bfbb517888849ea509ac366d0&quot;&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;.zhihu.com&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;path&#x27;</span>:<span class="string">&#x27;/&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;httpOnly&#x27;</span>: <span class="type">False</span>, </span><br><span class="line"><span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;l_cap_id&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;expiry&#x27;</span>: <span class="number">1494196091.403418</span>&#125;, <span class="type">...</span>] </span><br><span class="line">[]</span><br><span class="line"><span class="number">123456789101112131415161718192021</span></span><br></pre></td></tr></table></figure>
<p>通过以上方法来操作 Cookies 还是非常方便的。</p>
<h2 id="选项卡管理"><a href="#选项卡管理" class="headerlink" title="选项卡管理"></a>选项卡管理</h2><p>在访问网页的时候，我们通常会开启多个选项卡。在 Selenium 中，我们也可以对选项卡进行操作。示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import time </span><br><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.open()&#x27;</span>) </span><br><span class="line">print(browser.window_handles) </span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">1</span>])</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">0</span>]) </span><br><span class="line">browser.get(<span class="string">&#x27;https://python.org&#x27;</span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>控制台输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;CDwindow-4f58e3a7-7167-4587-bedf-9cd8c867f435&#x27;</span>, <span class="string">&#x27;CDwindow-6e05f076-6d77-453a-a36c-32baacc447df&#x27;</span>]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>首先访问百度，然后调用 execute_script 方法，这里我们传入 window.open 这个 JavaScript 语句新开启一个选项卡，然后切换到该选项卡，调用 window_handles 属性获取当前开启的所有选项卡，后面的参数代表返回选项卡的代号列表。要想切换选项卡，只需要调用 switch_to.window 方法即可，其中的参数是选项卡的代号。这里我们将第 2 个选项卡代号传入，即跳转到第 2 个选项卡，接下来在第 2 个选项卡下打开一个新页面，如果你想要切换回第 2 个选项卡，只需要重新调用 switch_to.window 方法，再执行其他操作即可。</p>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>在使用 Selenium 的过程中，难免会遇到一些异常，例如超时、节点未找到等错误，一旦出现此类错误，程序便不会继续运行了。这里我们可以使用 try except 语句来捕获各种异常。</p>
<p>首先，演示一下节点未找到的异常，示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>) </span><br><span class="line">browser.find_element_by_id(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line"><span class="number">1234</span></span><br></pre></td></tr></table></figure>
<p>这里我们首先打开百度页面，然后尝试选择一个并不存在的节点，此时就会遇到异常。</p>
<p>运行之后控制台的输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NoSuchElementException Traceback (most recent call last) </span><br><span class="line">&lt;ipython<span class="literal">-input-23-978945848a1b</span>&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">     <span class="number">3</span> browser = webdriver.Chrome()</span><br><span class="line">     <span class="number">4</span> browser.get (<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="literal">----</span>&gt; <span class="number">5</span> browser.find_element_by_id(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p>可以看到，这里抛出了 NoSuchElementException 异常，通常代表节点未找到。为了防止程序遇到异常而中断，我们需要捕获这些异常，示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.common.exceptions import TimeoutException, </span><br><span class="line">NoSuchElementException </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>) </span><br><span class="line">except TimeoutException:</span><br><span class="line">    print(<span class="string">&#x27;Time Out&#x27;</span>) </span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.find_element_by_id(<span class="string">&#x27;hello&#x27;</span>) </span><br><span class="line">except NoSuchElementException:</span><br><span class="line">    print(<span class="string">&#x27;No Element&#x27;</span>) </span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()</span><br><span class="line"><span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p>这里我们使用 try except 来捕获各类异常。比如，我们用 find_element_by_id 查找节点的方法捕获 NoSuchElementException 异常，这样一旦出现这样的错误，就进行异常处理，程序也不会中断了。</p>
<p>控制台的输出如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">No Element</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>关于更多的异常类，可以参考官方文档：：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions。">http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions。</a></p>
<h2 id="反屏蔽"><a href="#反屏蔽" class="headerlink" title="反屏蔽"></a>反屏蔽</h2><p>现在很多网站都加上了对 Selenium 的检测，来防止一些爬虫的恶意爬取。即如果检测到有人在使用 Selenium 打开浏览器，那就直接屏蔽。</p>
<p>其大多数情况下，检测基本原理是检测当前浏览器窗口下的 <strong>window.navigator</strong> 对象是否包含 webdriver 这个属性。因为在正常使用浏览器的情况下，这个属性是 undefined，然而一旦我们使用了 Selenium，Selenium 会给 window.navigator 设置 webdriver 属性。很多网站就通过 JavaScript 判断如果 webdriver 属性存在，那就直接屏蔽。</p>
<p>这边有一个典型的案例网站：<a target="_blank" rel="noopener" href="https://antispider1.scrape.cuiqingcai.com/，这个网站就是使用了上述原理实现了">https://antispider1.scrape.cuiqingcai.com/，这个网站就是使用了上述原理实现了</a> WebDriver 的检测，如果使用 Selenium 直接爬取的话，那就会返回如下页面：<br><img src="https://img-blog.csdnimg.cn/20200818134925305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这时候我们可能想到直接使用 JavaScript 直接把这个 webdriver 属性置空，比如通过调用 execute_script 方法来执行如下代码：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Object.defineProperty(navigator, <span class="string">&quot;webdriver&quot;</span>, &#123;get: () =&gt; undefined&#125;)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这行 JavaScript 的确是可以把 webdriver 属性置空，但是 execute_script 调用这行 JavaScript 语句实际上是在页面加载完毕之后才执行的，执行太晚了，网站早在最初页面渲染之前就已经对 webdriver 属性进行了检测，所以用上述方法并不能达到效果。</p>
<p>在 Selenium 中，我们可以使用 CDP（即 Chrome Devtools-Protocol，Chrome 开发工具协议）来解决这个问题，通过 CDP 我们可以实现在每个页面刚加载的时候执行 JavaScript 代码，执行的 CDP 方法叫作 <strong>Page.addScriptToEvaluateOnNewDocument</strong>，然后传入上文的 JavaScript 代码即可，这样我们就可以在每次页面加载之前将 webdriver 属性置空了。另外我们还可以加入几个选项来隐藏 WebDriver 提示条和自动化扩展信息，代码实现如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, False)</span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.execute_cdp_cmd(<span class="string">&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;</span>, &#123;</span><br><span class="line">   <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider1.scrape.cuiqingcai.com/&#x27;</span>)</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>这样整个页面就能被加载出来了：<br><img src="https://img-blog.csdnimg.cn/20200818135202355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于大多数的情况，以上的方法均可以实现 Selenium 反屏蔽。但对于一些特殊的网站，如果其有更多的 WebDriver 特征检测，可能需要具体排查。</p>
<h2 id="无头模式"><a href="#无头模式" class="headerlink" title="无头模式"></a>无头模式</h2><p>上面的案例在运行的时候，我们可以观察到其总会弹出一个浏览器窗口，虽然有助于观察页面爬取状况，但在有些时候窗口弹来弹去也会形成一些干扰。</p>
<p>Chrome 浏览器从 60 版本已经支持了无头模式，即 Headless。无头模式在运行的时候不会再弹出浏览器窗口，减少了干扰，而且它减少了一些资源的加载，如图片等资源，所以也在一定程度上节省了资源加载时间和网络带宽。</p>
<p>我们可以借助于 ChromeOptions 来开启 Chrome Headless 模式，代码实现如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.set_window_size(<span class="number">1366</span>, <span class="number">768</span>)</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">browser.get_screenshot_as_file(<span class="string">&#x27;preview.png&#x27;</span>)</span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p>这里我们通过 ChromeOptions 的 add_argument 方法添加了一个参数 —headless，开启了无头模式。在无头模式下，我们最好需要设置下窗口的大小，接着打开页面，最后我们调用 get_screenshot_as_file 方法输出了页面的截图。</p>
<p>运行代码之后，我们发现 Chrome 窗口就不会再弹出来了，代码依然正常运行，最后输出了页面截图如图所示。<br><img src="https://img-blog.csdnimg.cn/20200818135420725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODgxOTg4OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这样我们就在无头模式下完成了页面的抓取和截图操作。</p>
<p>现在，我们基本对 Selenium 的常规用法有了大体的了解。使用 Selenium，处理 JavaScript 渲染的页面不再是难事。</p>
<p>本节代码：<a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/SeleniumTest">https://github.com/Python3WebSpider/SeleniumTest</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/stacking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/stacking/" class="post-title-link" itemprop="url">模型融合</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-20 18:14:53" itemprop="dateCreated datePublished" datetime="2022-04-20T18:14:53+08:00">2022-04-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-04 03:03:56" itemprop="dateModified" datetime="2022-06-04T03:03:56+08:00">2022-06-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>stacking&amp;blending</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.6aiq.com/article/1536427413103">机器学习比赛大杀器 —— 模型融合</a>，目前只看到<strong>排名平均</strong>部分。</p>
</blockquote>
<p>1.可以集成提交文件（对预测结果的文件进行集成）</p>
<p>2.投票集成(预测结果为类别时)  少数服从多数， 概率意义上相加值大于原来的准确率。</p>
<p>3.集成低相关度的模型（即使其性能较差）也可以提升模型的性能。</p>
<h2 id="4-加权投票"><a href="#4-加权投票" class="headerlink" title="4.加权投票"></a>4.加权投票</h2><blockquote>
<p>原理理解：三个臭皮匠才可以稍微的对诸葛亮的看法做点改进。</p>
</blockquote>
<p>通常我们希望模型越好，其权重就越高。比如，我们将表现最好的模型的投票看作3票，其它的4个模型只看作1票。</p>
<p>原因是：当表现较差的模型需要否决表现最好的模型时，唯一的办法是它们集体同意另一种选择。我们期望这样的集成能够对表现最好的模型进行一些修正，带来一些小的提高。</p>
<p><img src="/categories/ML/stacking/image-20220420182603405.png" alt="image-20220420182603405"></p>
<h2 id="5-Average"><a href="#5-Average" class="headerlink" title="5.Average"></a>5.Average</h2><p>更愿意叫做”bagging Sumissions”。打包提交。</p>
<blockquote>
<p>脚本：<a target="_blank" rel="noopener" href="https://github.com/MLWave/Kaggle-Ensemble-Guide/tree/master/src">https://github.com/MLWave/Kaggle-Ensemble-Guide/tree/master/src</a></p>
</blockquote>
<p><strong>平均预测常常会降低过拟合</strong></p>
<p><img src="/categories/ML/stacking/image-20220420195230457.png" alt="image-20220420195230457"></p>
<p>图中黑线比绿线有更好的分割，绿色线已经从数据点中学习了一些噪声。</p>
<p><strong>平均多个不同的绿线， 使其更接近黑线。</strong></p>
<p>我们的目标不仅是去记住这些训练数据(这里有比在随机森林里更加有效的方法来存储数据)，而且还要去对我们没有看到的数据进行良好的泛化。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF">https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF</a></p>
</blockquote>
<h2 id="ROC空间"><a href="#ROC空间" class="headerlink" title="ROC空间"></a>ROC空间</h2><p>Receiver operating characteristic接收者操作特征</p>
<p>ROC空间将伪阳性率（FPR）定义为 <em>X</em> 轴，真阳性率（TPR）定义为 <em>Y</em> 轴。</p>
<ul>
<li>伪阳性率(FPR, false positive rate)</li>
</ul>
<p>又称：错误命中率，假警报率 (false alarm rate)</p>
<p>FPR = FP / N = FP / (FP + TN)</p>
<ul>
<li>真阳性率 (TPR, true positive rate)</li>
</ul>
<p>又称：命中率 (hit rate)、敏感度(sensitivity)</p>
<p>TPR = TP / P = TP / (TP+FN)</p>
<p><strong>则(0，1)是完美情况，FP错误的肯定为0，FN错误的否定为0.</strong></p>
<p><img src="/categories/ML/stacking/image-20220420192855473.png" alt="image-20220420192855473"></p>
<p><img src="/categories/ML/stacking/image-20220420193035472.png" alt="image-20220420193035472" style="zoom: 25%;"></p>
<p>离左上角越近，即x越小、y越大，模型预测准确度越好；</p>
<p>三种模型中，A&gt;B&gt;C但是只要把C当作一个相反结果预测机，则C’&gt;A&gt;B；</p>
<h2 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h2><p>调整二分类模型的阈值，得出不同的FPR和TPR，将这些点全部作在一个ROC空间里，就成为<strong>特定模型的ROC曲线</strong>。</p>
<ul>
<li><strong>在同一个分类器之内</strong>，<strong>当阈值设置为最高时</strong>，<strong>没有样本被预测为阳性</strong>，FPR=0,TPR=0；<strong>得出ROC坐标系左下角的点 (0, 0)。</strong></li>
<li>当阈值设置为最低时，所有样本均为阳性，FPR=FP/N=FP/(TN+FP)=1；TPR=TP/(TP+FN)=1；<strong>得出ROC坐标系右上角的点 (1, 1)。</strong></li>
<li><strong>随着阈值调低，FP、TP增大，FN、TN减小；ROC点</strong> 往右上（或右／或上）移动，或不动；但<strong>绝不会往左下(或左／或下)移动</strong>。</li>
</ul>
<h2 id="AUC曲线下面积"><a href="#AUC曲线下面积" class="headerlink" title="AUC曲线下面积"></a>AUC曲线下面积</h2><p>Area Under the Curve of ROC，作为评价模型优劣的指针；取值范围为[0,1]</p>
<p><img src="/categories/ML/stacking/image-20220420192128438.png" alt="image-20220420192128438"></p>
<p><strong>AUC值越大的分类器，正确率越高。</strong></p>
<p>从AUC判断分类器（预测模型）优劣的标准：</p>
<ul>
<li>AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。</li>
<li>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设置阈值的话，能有预测价值。</li>
<li>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</li>
<li>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Linux/perm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Linux/perm/" class="post-title-link" itemprop="url">chmod命令</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-14 19:59:30" itemprop="dateCreated datePublished" datetime="2022-04-14T19:59:30+08:00">2022-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-04 03:03:56" itemprop="dateModified" datetime="2022-06-04T03:03:56+08:00">2022-06-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>全文选摘自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u013197629/article/details/73608613#t1">林20的CSDNblog</a></p>
</blockquote>
<p>Linux下权限的粒度有 <strong>拥有者 、群组 、其它组</strong> 三种。每个文件都可以针对三个粒度，设置不同的rwx(读写执行)权限。</p>
<p>对于user、group、other分别设置三个粒度，则形成了000~777的不同授权数字，分别表示<code>---------</code>和<code>rwxrwxrwx</code>；</p>
<p>实际表示文件时，会采用10位表示法的八进制表示，最高的那一位实际上是拼接上的字母（还有12位二进制的八进制表示，此时要用四个八进制数字）。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/categories/Linux/perm/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Linux/xargs,sed,awk/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Linux/xargs,sed,awk/" class="post-title-link" itemprop="url">xargs、sed、awk</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-14 19:59:30" itemprop="dateCreated datePublished" datetime="2022-04-14T19:59:30+08:00">2022-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-04 03:03:56" itemprop="dateModified" datetime="2022-06-04T03:03:56+08:00">2022-06-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>持续更新ing</p>
<p>xargs可以解析空格分隔的命令，类似于管道符，但是支持的广泛性上强于管道符。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/SL-05/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/SL-05/" class="post-title-link" itemprop="url">梯度下降法、[拟]牛顿法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-03-30 16:14:53" itemprop="dateCreated datePublished" datetime="2022-03-30T16:14:53+08:00">2022-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-04 03:03:56" itemprop="dateModified" datetime="2022-06-04T03:03:56+08:00">2022-06-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="GD"><a href="#GD" class="headerlink" title="GD"></a>GD</h2><p>Gradient Decent/Steepest Decent，求解无约束最优化问题。</p>
<p><img src="/categories/ML/SL-05/image-20220330173751248.png" alt="image-20220330173751248" style="zoom:33%;"></p>
<p>负梯度方向是使函数值下降最快的方向。</p>
<p><img src="/categories/ML/SL-05/image-20220330181452563.png" alt="image-20220330181452563"></p>
<p>否则，不断地找f(x)的极小值点x，办法是让x=x-df(x)* λ，最关键的是找到合适的λ。</p>
<p>举例如下：</p>
<p><img src="/categories/ML/SL-05/image-20220330181942932.png" alt="image-20220330181942932"></p>
<p>梯度下降法收敛速度不一定快，而牛顿法和拟牛顿法，收敛速度更快。</p>
<h2 id="Newton-Method"><a href="#Newton-Method" class="headerlink" title="Newton Method"></a>Newton Method</h2><p>求解无约束最优化问题的迭代算法，每一步需要求解目标函数的海森矩阵的逆矩阵。</p>
<p>基本思想:在现有极小值估计值的附近对f(x)做泰勒展开，进而找到<strong>极小值的下一个估计</strong>值。</p>
<p><img src="/categories/ML/SL-05/image-20220330182720475.png" alt="image-20220330182720475"></p>
<h2 id="quasi-Newton-Method"><a href="#quasi-Newton-Method" class="headerlink" title="quasi-Newton Method"></a>quasi-Newton Method</h2><p>通过正定矩阵近似海森矩阵(的逆矩阵)。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Paul C"
      src="https://blueinyou.com/photos/avatar.jpg">
  <p class="site-author-name" itemprop="name">Paul C</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">100</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/memoryofsnow" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;memoryofsnow" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2215489940@qq.com" title="E-Mail → mailto:2215489940@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/jiyi_guoshu" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;jiyi_guoshu" rel="noopener" target="_blank"><i class="fab fa-csdn fa-fw"></i>CSDN</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Paul C</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
