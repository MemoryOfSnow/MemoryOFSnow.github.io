<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueinyou.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="使用 Pyppeteer 针对之前的 Selenium 案例做一次改写，来体会一下二者的不同之处，同时也加强一下对 Pyppeteer 的理解和掌握情况。 还是 Selenium 的那个案例，地址为：https:&#x2F;&#x2F;dynamic2.scrape.cuiqingcai.com&#x2F; 爬取目标和那一节也是一样的：  遍历每一页列表页，然后获取每部电影详情页的 URL。 爬取每部电影的详情页，然后提取其名">
<meta property="og:type" content="article">
<meta property="og:title" content="Paul C&#39;s Blog">
<meta property="og:url" content="https://blueinyou.com/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="Paul C&#39;s Blog">
<meta property="og:description" content="使用 Pyppeteer 针对之前的 Selenium 案例做一次改写，来体会一下二者的不同之处，同时也加强一下对 Pyppeteer 的理解和掌握情况。 还是 Selenium 的那个案例，地址为：https:&#x2F;&#x2F;dynamic2.scrape.cuiqingcai.com&#x2F; 爬取目标和那一节也是一样的：  遍历每一页列表页，然后获取每部电影详情页的 URL。 爬取每部电影的详情页，然后提取其名">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-10-29T13:47:51.766Z">
<meta property="article:modified_time" content="2022-10-28T08:30:11.214Z">
<meta property="article:author" content="Paul C">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueinyou.com/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | Paul C's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Paul C's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">To be funny,to grow up!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-29 21:47:51" itemprop="dateCreated datePublished" datetime="2022-10-29T21:47:51+08:00">2022-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-28 16:30:11" itemprop="dateModified" datetime="2022-10-28T16:30:11+08:00">2022-10-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>使用 Pyppeteer 针对之前的 Selenium 案例做一次改写，来体会一下二者的不同之处，同时也加强一下对 Pyppeteer 的理解和掌握情况。</p>
<p>还是 Selenium 的那个案例，地址为：<a target="_blank" rel="noopener" href="https://dynamic2.scrape.cuiqingcai.com/">https://dynamic2.scrape.cuiqingcai.com/</a></p>
<p>爬取目标和那一节也是一样的：</p>
<ul>
<li>遍历每一页列表页，然后获取每部电影详情页的 URL。</li>
<li>爬取每部电影的详情页，然后提取其名称、评分、类别、封面、简介等信息。</li>
<li>爬取到的数据存为 JSON 文件。</li>
</ul>
<p>要求和之前也是一样的，只不过我们这里的实现就全用 Pyppeteer 来做了。</p>
<ul>
<li>安装好 Python （最低为 Python 3.6）版本，并能成功运行 Python 程序。</li>
<li>安装好 Pyppeteer 并能成功运行示例。</li>
</ul>
<p>其他的浏览器、驱动配置就不需要了，这也是相比 Selenium 更加方便的地方。</p>
<p>页面分析在这里就不多介绍了，还是列表页 + 详情页的结构，具体可以参考 Selenium 那一课时的内容。</p>
<h2 id="爬取列表页"><a href="#爬取列表页" class="headerlink" title="爬取列表页"></a>爬取列表页</h2><p>首先我们先做一些准备工作，定义一些基础的配置，包括日志定义、变量等等并引入一些必要的包，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIMEOUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line">WINDOW_WIDTH, WINDOW_HEIGHT = <span class="number">1366</span>, <span class="number">768</span></span><br><span class="line">HEADLESS = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>这里大多数的配置和之前是一样的，不过这里我们额外定义了窗口的宽高信息，这里定义为 1366 x 768，你也可以随意指定适合自己屏幕的宽高信息。另外这里定义了一个变量 HEADLESS，用来指定是否启用 Pyppeteer 的无头模式，如果为 False，那么启动 Pyppeteer 的时候就会弹出一个 Chromium 浏览器窗口。</p>
<p>接着我们再定义一个初始化 Pyppeteer 的方法，包括启动 Pyppeteer，新建一个页面选项卡，设置窗口大小等操作，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line">browser, tab = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">   <span class="keyword">global</span> browser, tab</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=HEADLESS,</span><br><span class="line">                          args=[<span class="string">&#x27;--disable-infobars&#x27;</span>,</span><br><span class="line">                                <span class="string">f&#x27;--window-size=<span class="subst">&#123;WINDOW_WIDTH&#125;</span>,<span class="subst">&#123;WINDOW_HEIGHT&#125;</span>&#x27;</span>])</span><br><span class="line">   tab = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> tab.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: WINDOW_WIDTH, <span class="string">&#x27;height&#x27;</span>: WINDOW_HEIGHT&#125;)</span><br></pre></td></tr></table></figure>
<p>在这里我们先声明了一个 browser 对象，代表 Pyppeteer 所用的浏览器对象，tab 代表新建的页面选项卡，这里把两项设置为全局变量，方便其他的方法调用。</p>
<p>另外定义了一个 init 方法，调用了 Pyppeteer 的 launch 方法，传入了 headless 为 HEADLESS，将其设置为非无头模式，另外还通过 args 指定了隐藏提示条并设定了窗口的宽高。</p>
<p>接下来我们像之前一样，定义一个通用的爬取方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer.errors <span class="keyword">import</span> TimeoutError</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_page</span>(<span class="params">url, selector</span>):</span><br><span class="line">   logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">await</span> tab.goto(url)</span><br><span class="line">       <span class="keyword">await</span> tab.waitForSelector(selector, options=&#123;</span><br><span class="line">           <span class="string">&#x27;timeout&#x27;</span>: TIMEOUT * <span class="number">1000</span></span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">except</span> TimeoutError:</span><br><span class="line">       logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 scrape_page 方法，它接收两个参数，一个是 url，代表要爬取的链接，使用 goto 方法调用即可；另外一个是 selector，即要等待渲染出的节点对应的 CSS 选择器，这里我们使用 waitForSelector 方法并传入了 selector，并通过 options 指定了最长等待时间。</p>
<p>这样的话在运行时页面会首先访问这个 URL，然后等待某个符合 selector 的节点加载出来，最长等待 10 秒，如果 10 秒内加载出来了，那就接着往下执行，否则抛出异常，捕获 TimeoutError 并输出错误日志。</p>
<p>接下来，我们就实现一下爬取列表页的方法，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">   url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;.item .name&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了 scrape_index 方法来爬取页面，其接受一个参数 page，代表要爬取的页码，这里我们首先通过 INDEX_URL 构造了列表页的 URL，然后调用 scrape_page 方法传入了 url 和要等待加载的选择器。</p>
<p>好，接下来我们可以再定义一个解析列表页的方法，提取出每部电影的详情页 URL，定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_index</span>():</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.item .name&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们调用了 querySelectorAllEval 方法，它接收两个参数，第一个参数是 selector，代表要选择的节点对应的 CSS 选择器；第二个参数是 pageFunction，代表的是要执行的 JavaScript 方法，这里需要传入的是一段 JavaScript 字符串，整个方法的作用是选择 selector 对应的节点，然后对这些节点通过 pageFunction 定义的逻辑抽取出对应的结果并返回。</p>
<p>所以这里第一个参数 selector 就传入电影名称对应的节点，其实是超链接 a 节点。由于提取结果有多个，所以这里 JavaScript 对应的 pageFunction 输入参数就是 nodes，输出结果是调用了 map 方法得到每个 node，然后调用 node 的 href 属性即可。这样返回结果就是当前列表页的所有电影的详情页 URL 组成的列表了。</p>
<p>好，接下来我们来串联调用一下看看，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           logging.info(<span class="string">&#x27;detail_urls %s&#x27;</span>, detail_urls)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h2 id="爬取详情页"><a href="#爬取详情页" class="headerlink" title="爬取详情页"></a>爬取详情页</h2><p>拿到详情页的 URL 之后，下一步就是爬取每一个详情页然后提取信息了，首先我们定义一个爬取详情页的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;h2&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>如果顺利运行，那么当前 Pyppeteer 就已经成功加载出详情页了，下一步就是提取里面的信息了。</p>
<p>接下来我们再定义一个提取详情信息的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_detail</span>():</span><br><span class="line">   url = tab.url</span><br><span class="line">   name = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;h2&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   categories = <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.categories button span&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;</span>)</span><br><span class="line">   cover = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.cover&#x27;</span>, <span class="string">&#x27;node =&gt; node.src&#x27;</span>)</span><br><span class="line">   score = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.score&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   drama = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.drama p&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   <span class="keyword">return</span> &#123;</span><br><span class="line">       <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">       <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">       <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">       <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">       <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">       <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 parse_detail 方法，提取了 URL、名称、类别、封面、分数、简介等内容，提取方式如下：</p>
<ul>
<li>URL：直接调用 tab 对象的 url 属性即可获取当前页面的 URL。</li>
<li>名称：由于名称只有一个节点，所以这里我们调用了 querySelectorEval 方法来提取，而不是querySelectorAllEval，第一个参数传入 h2，提取到了名称对应的节点，然后第二个参数传入提取的 pageFunction，调用了 node 的 innerText 属性提取了文本值，即电影名称。</li>
<li>类别：类别有多个，所以我们这里调用了 querySelectorAllEval 方法来提取，其对应的 CSS 选择器为 .categories button span，可以选中多个类别节点。接下来还是像之前提取详情页 URL 一样，pageFunction 使用 nodes 参数，然后调用 map 方法提取 node 的 innerText 就得到所有类别结果了。</li>
<li>封面：同样地，可以使用 CSS 选择器 .cover 直接获取封面对应的节点，但是由于其封面的 URL 对应的是 src 这个属性，所以这里提取的是 src 属性。</li>
<li>分数：分数对应的 CSS 选择器为 .score ，类似的原理，提取 node 的 innerText 即可。</li>
<li>简介：同样可以使用 CSS 选择器 .drama p 直接获取简介对应的节点，然后调用 innerText 属性提取文本即可。</li>
</ul>
<p>最后我们将提取结果汇总成一个字典然后返回即可。</p>
<p>接下来 main 方法里面，我们增加 scrape_detail 和 parse_detail 方法的调用，main 方法改写如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">               <span class="keyword">await</span> scrape_detail(detail_url)</span><br><span class="line">               detail_data = <span class="keyword">await</span> parse_detail()</span><br><span class="line">               logging.info(<span class="string">&#x27;data %s&#x27;</span>, detail_data)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br></pre></td></tr></table></figure>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>最后，我们再像之前一样添加一个数据存储的方法，为了方便，这里还是保存为 JSON 文本文件，实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">   name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">   data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">   json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>在运行过程中，由于 Pyppeteer 本身实现的原因，可能连续运行 20 秒之后控制台就会出现如下错误：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyppeteer.errors.NetworkError: Protocol Error (Runtime.evaluate): Session closed. Most likely the page has been closed.</span><br></pre></td></tr></table></figure>
<h2 id="无头模式"><a href="#无头模式" class="headerlink" title="无头模式"></a>无头模式</h2><p>最后如果代码能稳定运行了，我们可以将其改为无头模式，将 HEADLESS 修改为 True 即可，这样在运行的时候就不会弹出浏览器窗口了。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/categories/Notes/ComplexNetWork/" rel="prev" title="Attack Robustness and Centrality of Complex Networks">
      <i class="fa fa-chevron-left"></i> Attack Robustness and Centrality of Complex Networks
    </a></div>
      <div class="post-nav-item">
    <a href="/categories/Notes/4%E7%88%AC%E8%99%AB%E9%9D%99%E6%80%81%E6%8F%90%E5%8F%96/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="nav-number">1.</span> <span class="nav-text">爬取列表页</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="nav-number">2.</span> <span class="nav-text">爬取详情页</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="nav-number">3.</span> <span class="nav-text">数据存储</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5"><span class="nav-number">4.</span> <span class="nav-text">问题排查</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E5%A4%B4%E6%A8%A1%E5%BC%8F"><span class="nav-number">5.</span> <span class="nav-text">无头模式</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Paul C"
      src="https://blueinyou.com/photos/avatar.jpg">
  <p class="site-author-name" itemprop="name">Paul C</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">99</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/memoryofsnow" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;memoryofsnow" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2215489940@qq.com" title="E-Mail → mailto:2215489940@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/jiyi_guoshu" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;jiyi_guoshu" rel="noopener" target="_blank"><i class="fab fa-csdn fa-fw"></i>CSDN</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Paul C</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
