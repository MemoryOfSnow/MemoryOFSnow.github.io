<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueinyou.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Paul C&#39;s Blog">
<meta property="og:url" content="https://blueinyou.com/index.html">
<meta property="og:site_name" content="Paul C&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Paul C">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueinyou.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Paul C's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Paul C's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">To be funny,to grow up!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-29 21:47:51" itemprop="dateCreated datePublished" datetime="2022-10-29T21:47:51+08:00">2022-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-28 16:30:12" itemprop="dateModified" datetime="2022-10-28T16:30:12+08:00">2022-10-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h2><p>比如在这里我们看这么一个示例网站：<a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/，">https://static4.scrape.cuiqingcai.com/，</a></p>
<p><img src="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/1.png" alt="1"></p>
<p>这个网站在内部实现返回响应的逻辑的时候特意加了 5 秒的延迟，也就是说如果我们用 requests 来爬取其中某个页面的话，至少需要 5 秒才能得到响应。</p>
<p>另外这个网站的逻辑结构在之前的案例中我们也分析过，其内容就是电影数据，一共 100 部，每个电影的详情页是一个自增 ID，从 1~100，比如 <a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/detail/43">https://static4.scrape.cuiqingcai.com/detail/43</a> 就代表第 43 部电影，如图所示。</p>
<p><img src="/categories/Notes/8%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/2.png" alt="2"></p>
<p>下面我们来用 requests 写一个遍历程序，直接遍历 1~100 部电影数据，代码实现如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import logging</span><br><span class="line">import time</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   format=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">TOTAL_NUMBER = <span class="number">100</span></span><br><span class="line">BASE_URL = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/detail/&#123;id&#125;&#x27;</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> id <span class="keyword">in</span> range(<span class="number">1</span>, TOTAL_NUMBER + <span class="number">1</span>):</span><br><span class="line">   url = BASE_URL.format(id=id)</span><br><span class="line">   logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">   response = requests.get(url)</span><br><span class="line">end_time = time.time()</span><br><span class="line">logging.info(<span class="string">&#x27;total time %s seconds&#x27;</span>, end_time - start_time)</span><br></pre></td></tr></table></figure>
<p>这里我们直接用循环的方式构造了 100 个详情页的爬取，使用的是 requests 单线程，在爬取之前和爬取之后记录下时间，最后输出爬取了 100 个页面消耗的时间。</p>
<p>由于每个页面都至少要等待 5 秒才能加载出来，因此 100 个页面至少要花费 500 秒的时间，总的爬取时间最终为 513.6 秒，将近 9 分钟。</p>
<p>这个在实际情况下是很常见的，有些网站本身加载速度就比较慢，稍慢的可能 1~3 秒，更慢的说不定 10 秒以上才可能加载出来。如果我们用 requests 单线程这么爬取的话，总的耗时是非常多的。此时如果我们开了多线程或多进程来爬取的话，其爬取速度确实会成倍提升，但有没有更好的解决方案呢？</p>
<p>本课时我们就来了解一下使用异步执行方式来加速的方法，此种方法对于 IO 密集型任务非常有效。如将其应用到网络爬虫中，爬取效率甚至可以成百倍地提升。</p>
<h2 id="基本了解"><a href="#基本了解" class="headerlink" title="基本了解"></a>基本了解</h2><p>在了解异步协程之前，我们首先得了解一些基础概念，如阻塞和非阻塞、同步和异步、多进程和协程。</p>
<h3 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h3><p>阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续处理其他的事情，则称该程序在该操作上是阻塞的。</p>
<p>常见的阻塞形式有：网络 I/O 阻塞、磁盘 I/O 阻塞、用户输入阻塞等。阻塞是无处不在的，包括 CPU 切换上下文时，所有的进程都无法真正处理事情，它们也会被阻塞。如果是多核 CPU 则正在执行上下文切换操作的核不可被利用。</p>
<h3 id="非阻塞"><a href="#非阻塞" class="headerlink" title="非阻塞"></a>非阻塞</h3><p>程序在等待某操作过程中，自身不被阻塞，可以继续处理其他的事情，则称该程序在该操作上是非阻塞的。</p>
<p>非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。</p>
<p>非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的。</p>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，我们称这些程序单元是同步执行的。</p>
<p>例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的。</p>
<p>简言之，同步意味着有序。</p>
<h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式，不相关的程序单元之间可以是异步的。</p>
<p>例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定。</p>
<p>简言之，异步意味着无序。</p>
<h3 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h3><p>多进程就是利用 CPU 的多核优势，在同一时间并行地执行多个任务，可以大大提高执行效率。</p>
<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>协程，英文叫作 Coroutine，又称微线程、纤程，协程是一种用户态的轻量级线程。</p>
<p>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。</p>
<p>协程本质上是个单进程，协程相对于多进程来说，无需线程上下文切换的开销，无需原子操作锁定及同步的开销，编程模型也非常简单。</p>
<p>我们可以使用协程来实现异步操作，比如在网络爬虫场景下，我们发出一个请求之后，需要等待一定的时间才能得到响应，但其实在这个等待过程中，程序可以干许多其他的事情，等到响应得到之后才切换回来继续处理，这样可以充分利用 CPU 和其他资源，这就是协程的优势。</p>
<h2 id="协程用法"><a href="#协程用法" class="headerlink" title="协程用法"></a>协程用法</h2><p>接下来，我们来了解下协程的实现，从 Python 3.4 开始，Python 中加入了协程的概念，但这个版本的协程还是以生成器对象为基础的，在 Python 3.5 则增加了 async/await，使得协程的实现更加方便。</p>
<p>Python 中使用协程最常用的库莫过于 asyncio，所以本文会以 asyncio 为基础来介绍协程的使用。</p>
<p>首先我们需要了解下面几个概念。</p>
<ul>
<li>event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，当满足条件发生的时候，就会调用对应的处理方法。</li>
<li>coroutine：中文翻译叫协程，在 Python 中常指代为协程对象类型，我们可以将协程对象注册到时间循环中，它会被事件循环调用。我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。</li>
<li>task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。</li>
<li>future：代表将来执行或没有执行的任务的结果，实际上和 task 没有本质区别。</li>
</ul>
<p>另外我们还需要了解 async/await 关键字，它是从 Python 3.5 才出现的，专门用于定义协程。其中，async 定义一个协程，await 用来挂起阻塞方法的执行。</p>
<h3 id="定义协程"><a href="#定义协程" class="headerlink" title="定义协程"></a>定义协程</h3><p>首先我们来定义一个协程，体验一下它和普通进程在实现上的不同之处，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>首先我们引入了 asyncio 这个包，这样我们才可以使用 async 和 await，然后我们使用 async 定义了一个 execute 方法，方法接收一个数字参数，方法执行之后会打印这个数字。</p>
<p>随后我们直接调用了这个方法，然而这个方法并没有执行，而是返回了一个 coroutine 协程对象。随后我们使用 get_event_loop 方法创建了一个事件循环 loop，并调用了 loop 对象的 run_until_complete 方法将协程注册到事件循环 loop 中，然后启动。最后我们才看到了 execute 方法打印了输出结果。</p>
<p>可见，async 定义的方法就会变成一个无法直接执行的 coroutine 对象，必须将其注册到事件循环中才可以执行。</p>
<p>上面我们还提到了 task，它是对 coroutine 对象的进一步封装，它里面相比 coroutine 对象多了运行状态，比如 running、finished 等，我们可以用这些状态来获取协程对象的执行情况。</p>
<p>在上面的例子中，当我们将 coroutine 对象传递给 run_until_complete 方法的时候，实际上它进行了一个操作就是将 coroutine 封装成了 task 对象，我们也可以显式地进行声明，如下所示：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">   <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了 loop 对象之后，接着调用了它的 create_task 方法将 coroutine 对象转化为了 task 对象，随后我们打印输出一下，发现它是 pending 状态。接着我们将 task 对象添加到事件循环中得到执行，随后我们再打印输出一下 task 对象，发现它的状态就变成了 finished，同时还可以看到其 result 变成了 1，也就是我们定义的 execute 方法的返回结果。</p>
<p>另外定义 task 对象还有一种方式，就是直接通过 asyncio 的 ensure_future 方法，返回结果也是 task 对象，这样的话我们就可以不借助于 loop 来定义，即使我们还没有声明 loop 也可以提前定义好 task 对象，写法如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def execute(x):</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">   <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="绑定回调"><a href="#绑定回调" class="headerlink" title="绑定回调"></a>绑定回调</h3><p>另外我们也可以为某个 task 绑定一个回调方法，比如我们来看下面的例子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">def callback(task):</span><br><span class="line">   print(<span class="string">&#x27;Status:&#x27;</span>, task.result())</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">task.add_done_callback(callback)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br></pre></td></tr></table></figure>
<p>在这里我们定义了一个 request 方法，请求了百度，获取其状态码，但是这个方法里面我们没有任何 print 语句。随后我们定义了一个 callback 方法，这个方法接收一个参数，是 task 对象，然后调用 print 方法打印了 task 对象的结果。这样我们就定义好了一个 coroutine 对象和一个回调方法，我们现在希望的效果是，当 coroutine 对象执行完毕之后，就去执行声明的 callback 方法。</p>
<p>那么它们二者怎样关联起来呢？很简单，只需要调用 add_done_callback 方法即可，我们将 callback 方法传递给了封装好的 task 对象，这样当 task 执行完毕之后就可以调用 callback 方法了，同时 task 对象还会作为参数传递给 callback 方法，调用 task 对象的 result 方法就可以获取返回结果了。</p>
<p>实际上不用回调方法，直接在 task 运行完毕之后也可以直接调用 result 方法获取结果，如下所示：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">print(<span class="string">&#x27;Task Result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure>
<h3 id="多任务协程"><a href="#多任务协程" class="headerlink" title="多任务协程"></a>多任务协程</h3><p>上面的例子我们只执行了一次请求，如果我们想执行多次请求应该怎么办呢？我们可以定义一个 task 列表，然后使用 asyncio 的 wait 方法即可执行，看下面的例子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">tasks = <span class="function">[<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">5</span>)]</span></span><br><span class="line">print(<span class="string">&#x27;Tasks:&#x27;</span>, tasks)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">   print(<span class="string">&#x27;Task Result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure>
<p>这里我们使用一个 for 循环创建了五个 task，组成了一个列表，然后把这个列表首先传递给了 asyncio 的 wait() 方法，然后再将其注册到时间循环中，就可以发起五个任务了。最后我们再将任务的运行结果输出出来，</p>
<h3 id="协程实现"><a href="#协程实现" class="headerlink" title="协程实现"></a>协程实现</h3><p>前面讲了这么多，又是 async，又是 coroutine，又是 task，又是 callback，但似乎并没有看出协程的优势啊？反而写法上更加奇怪和麻烦了，别急，上面的案例只是为后面的使用作铺垫，接下来我们正式来看下协程在解决 IO 密集型任务上有怎样的优势吧！</p>
<p>上面的代码中，我们用一个网络请求作为示例，这就是一个耗时等待的操作，因为我们请求网页之后需要等待页面响应并返回结果。耗时等待的操作一般都是 IO 操作，比如文件读取、网络请求等等。协程对于处理这种操作是有很大优势的，当遇到需要等待的情况的时候，程序可以暂时挂起，转而去执行其他的操作，从而避免一直等待一个程序而耗费过多的时间，充分利用资源。</p>
<p>为了表现出协程的优势，我们还是拿本课时开始介绍的网站 <a target="_blank" rel="noopener" href="https://static4.scrape.cuiqingcai.com/">https://static4.scrape.cuiqingcai.com/</a> 为例来进行演示，因为该网站响应比较慢，所以我们可以通过爬取时间来直观地感受到爬取速度的提升。</p>
<p>为了让你更好地理解协程的正确使用方法，这里我们先来看看使用协程时常犯的错误，后面再给出正确的例子来对比一下。</p>
<p>首先，我们还是拿之前的 requests 来进行网页请求，接下来我们再重新使用上面的方法请求一遍：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = requests.get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>可以发现和正常的请求并没有什么两样，依然还是顺次执行的，耗时 51 秒，平均一个请求耗时 5 秒，说好的异步处理呢？</p>
<p>其实，要实现异步处理，我们得先要有挂起的操作，当一个任务需要等待 IO 结果的时候，可以挂起当前任务，转而去执行其他任务，这样我们才能充分利用好资源，上面方法都是一本正经的串行走下来，连个挂起都没有，怎么可能实现异步？想太多了。</p>
<p>要实现异步，接下来我们需要了解一下 await 的用法，使用 await 可以将耗时等待的操作挂起，让出控制权。当协程执行的时候遇到 await，时间循环就会将本协程挂起，转而去执行别的协程，直到其他的协程挂起或执行完毕。</p>
<p>所以，我们可能会将代码中的 request 方法改成如下的样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await requests.get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br></pre></td></tr></table></figure>
<p>仅仅是在 requests 前面加了一个 await，然而执行以下代码，会得到如下报错：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">Waiting <span class="keyword">for</span> https://static4.scrape.cuiqingcai.com/</span><br><span class="line">...</span><br><span class="line">Task exception was never retrieved</span><br><span class="line">future: &lt;Task finished coro=&lt;request() done, defined at demo.py:<span class="number">8</span>&gt; exception=TypeError(<span class="string">&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;</span>)&gt;</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"> File <span class="string">&quot;demo.py&quot;</span>, line <span class="number">11</span>, <span class="keyword">in</span> request</span><br><span class="line">   response = await requests.get(url)</span><br><span class="line">TypeError: object Response can<span class="string">&#x27;t be used in &#x27;</span>await<span class="string">&#x27; expression</span></span><br></pre></td></tr></table></figure>
<p>这次它遇到 await 方法确实挂起了，也等待了，但是最后却报了这么个错，这个错误的意思是 requests 返回的 Response 对象不能和 await 一起使用，为什么呢？因为根据官方文档说明，await 后面的对象必须是如下格式之一：</p>
<ul>
<li>A native coroutine object returned from a native coroutine function，一个原生 coroutine 对象。</li>
<li>A generator-based coroutine object returned from a function decorated with types.coroutine，一个由 types.coroutine 修饰的生成器，这个生成器可以返回 coroutine 对象。</li>
<li>An object with an <strong>await</strong> method returning an iterator，一个包含 <strong>await</strong> 方法的对象返回的一个迭代器。</li>
</ul>
<p>可以参见：<a target="_blank" rel="noopener" href="https://www.python.org/dev/peps/pep-0492/#await-expression。">https://www.python.org/dev/peps/pep-0492/#await-expression。</a></p>
<p>requests 返回的 Response 不符合上面任一条件，因此就会报上面的错误了。</p>
<p>那么你可能会发现，既然 await 后面可以跟一个 coroutine 对象，那么我用 async 把请求的方法改成 coroutine 对象不就可以了吗？所以就改写成如下的样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def get(url):</span><br><span class="line">   <span class="keyword">return</span> requests.get(url)</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>还是不行，它还不是异步执行，也就是说我们仅仅将涉及 IO 操作的代码封装到 async 修饰的方法里面是不可行的！我们必须要使用支持异步操作的请求方式才可以实现真正的异步，所以这里就需要 <strong>aiohttp</strong> 派上用场了。</p>
<h2 id="使用-aiohttp"><a href="#使用-aiohttp" class="headerlink" title="使用 aiohttp"></a>使用 aiohttp</h2><p>aiohttp 是一个支持异步请求的库，利用它和 asyncio 配合我们可以非常方便地实现异步请求操作。</p>
<p>安装方式如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install aiohttp</span><br></pre></td></tr></table></figure>
<p>官方文档链接为：<a target="_blank" rel="noopener" href="https://aiohttp.readthedocs.io/，它分为两部分，一部分是">https://aiohttp.readthedocs.io/，它分为两部分，一部分是</a> Client，一部分是 Server，详细的内容可以参考官方文档。</p>
<p>下面我们将 aiohttp 用上来，将代码改成如下样子：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"><span class="built_in">start</span> = time.time()</span><br><span class="line"> </span><br><span class="line">async def get(url):</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   response = await session.get(url)</span><br><span class="line">   await response.text()</span><br><span class="line">   await session.close()</span><br><span class="line">   <span class="keyword">return</span> response</span><br><span class="line"> </span><br><span class="line">async def request():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.cuiqingcai.com/&#x27;</span></span><br><span class="line">   print(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = await get(url)</span><br><span class="line">   print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span> = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br></pre></td></tr></table></figure>
<p>成功了！我们发现这次请求的耗时由 51 秒变直接成了 6 秒，耗费时间减少了非常非常多。</p>
<p>代码里面我们使用了 await，后面跟了 get 方法，在执行这 10 个协程的时候，如果遇到了 await，那么就会将当前协程挂起，转而去执行其他的协程，直到其他的协程也挂起或执行完毕，再进行下一个协程的执行。</p>
<p>开始运行时，时间循环会运行第一个 task，针对第一个 task 来说，当执行到第一个 await 跟着的 get 方法时，它被挂起，但这个 get 方法第一步的执行是非阻塞的，挂起之后立马被唤醒，所以立即又进入执行，创建了 ClientSession 对象，接着遇到了第二个 await，调用了 session.get 请求方法，然后就被挂起了，由于请求需要耗时很久，所以一直没有被唤醒。</p>
<p>当第一个 task 被挂起了，那接下来该怎么办呢？事件循环会寻找当前未被挂起的协程继续执行，于是就转而执行第二个 task 了，也是一样的流程操作，直到执行了第十个 task 的 session.get 方法之后，全部的 task 都被挂起了。所有 task 都已经处于挂起状态，怎么办？只好等待了。5 秒之后，几个请求几乎同时都有了响应，然后几个 task 也被唤醒接着执行，输出请求结果，最后总耗时，6 秒！</p>
<p>怎么样？这就是异步操作的便捷之处，当遇到阻塞式操作时，任务被挂起，程序接着去执行其他的任务，而不是傻傻地等待，这样可以充分利用 CPU 时间，而不必把时间浪费在等待 IO 上。</p>
<p>你可能会说，既然这样的话，在上面的例子中，在发出网络请求后，既然接下来的 5 秒都是在等待的，在 5 秒之内，CPU 可以处理的 task 数量远不止这些，那么岂不是我们放 10 个、20 个、50 个、100 个、1000 个 task 一起执行，最后得到所有结果的耗时不都是差不多的吗？因为这几个任务被挂起后都是一起等待的。</p>
<p>理论来说确实是这样的，不过有个前提，那就是服务器在同一时刻接受无限次请求都能保证正常返回结果，也就是服务器无限抗压，另外还要忽略 IO 传输时延，确实可以做到无限 task 一起执行且在预想时间内得到结果。但由于不同服务器处理的实现机制不同，可能某些服务器并不能承受这么高的并发，因此响应速度也会减慢。</p>
<p>在这里我们以百度为例，来测试下并发数量为 1、3、5、10、…、500 的情况下的耗时情况，代码如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">def test(number):</span><br><span class="line">   <span class="built_in">start</span> = time.time()</span><br><span class="line"></span><br><span class="line">   async def get(url):</span><br><span class="line">       session = aiohttp.ClientSession()</span><br><span class="line">       response = await session.get(url)</span><br><span class="line">       await response.text()</span><br><span class="line">       await session.close()</span><br><span class="line">       <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">   async def request():</span><br><span class="line">       url = <span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">       await get(url)</span><br><span class="line"></span><br><span class="line">   tasks = [<span class="type">asyncio.ensure_future</span>(<span class="type">request</span>()) <span class="type">for</span> <span class="type">_</span> <span class="type">in</span> <span class="type">range</span>(<span class="type">number</span>)]</span><br><span class="line">   loop = asyncio.get_event_loop()</span><br><span class="line">   loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line">   <span class="keyword">end</span> = time.time()</span><br><span class="line">   print(<span class="string">&#x27;Number:&#x27;</span>, number, <span class="string">&#x27;Cost time:&#x27;</span>, <span class="keyword">end</span> - <span class="built_in">start</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">500</span>]:</span><br><span class="line">   test(number)</span><br></pre></td></tr></table></figure>
<h2 id="aiohttp"><a href="#aiohttp" class="headerlink" title="aiohttp"></a>aiohttp</h2><p>前面介绍的 asyncio 模块内部实现了对 TCP、UDP、SSL 协议的异步操作，但是对于 HTTP 请求的异步操作来说，我们就需要用到 aiohttp 来实现了。</p>
<p>aiohttp 是一个基于 asyncio 的异步 HTTP 网络模块，它既提供了服务端，又提供了客户端。其中我们用服务端可以搭建一个支持异步处理的服务器，用于处理请求并返回响应，类似于 Django、Flask、Tornado 等一些 Web 服务器。而客户端我们就可以用来发起请求，就类似于 requests 来发起一个 HTTP 请求然后获得响应，但 requests 发起的是同步的网络请求，而 aiohttp 则发起的是异步的。</p>
<p>本课时我们就主要来了解一下 aiohttp 客户端部分的使用。</p>
<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="基本实例"><a href="#基本实例" class="headerlink" title="基本实例"></a>基本实例</h3><p>首先我们来看一个基本的 aiohttp 请求案例，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">fetch</span>(<span class="params">session, url</span>):</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">await</span> response.text(), response.status</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       html, status = <span class="keyword">await</span> fetch(session, <span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">f&#x27;html: <span class="subst">&#123;html[:<span class="number">100</span>]&#125;</span>...&#x27;</span>)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">f&#x27;status: <span class="subst">&#123;status&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   loop = asyncio.get_event_loop()</span><br><span class="line">   loop.run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>我们可以看到其请求方法的定义和之前有了明显的区别，主要有如下几点：</p>
<ul>
<li>首先在导入库的时候，我们除了必须要引入 aiohttp 这个库之外，还必须要引入 asyncio 这个库，因为要实现异步爬取需要启动协程，而协程则需要借助于 asyncio 里面的事件循环来执行。除了事件循环，asyncio 里面也提供了很多基础的异步操作。</li>
<li>异步爬取的方法的定义和之前有所不同，在每个异步方法前面统一要加 async 来修饰。</li>
<li>with as 语句前面同样需要加 async 来修饰，在 Python 中，with as 语句用于声明一个上下文管理器，能够帮我们自动分配和释放资源，而在异步方法中，with as 前面加上 async 代表声明一个支持异步的上下文管理器。</li>
<li>对于一些返回 coroutine 的操作，前面需要加 await 来修饰，如 response 调用 text 方法，查询 API 可以发现其返回的是 coroutine 对象，那么前面就要加 await；而对于状态码来说，其返回值就是一个数值类型，那么前面就不需要加 await。所以，这里可以按照实际情况处理，参考官方文档说明，看看其对应的返回值是怎样的类型，然后决定加不加 await 就可以了。</li>
<li>最后，定义完爬取方法之后，实际上是 main 方法调用了 fetch 方法。要运行的话，必须要启用事件循环，事件循环就需要使用 asyncio 库，然后使用 run_until_complete 方法来运行。</li>
</ul>
<blockquote>
<p>注意在 Python 3.7 及以后的版本中，我们可以使用 asyncio.run(main())<br>来代替最后的启动操作，不需要显式声明事件循环，run 方法内部会自动启动一个事件循环。但这里为了兼容更多的 Python<br>版本，依然还是显式声明了事件循环。</p>
</blockquote>
<h3 id="URL-参数设置"><a href="#URL-参数设置" class="headerlink" title="URL 参数设置"></a>URL 参数设置</h3><p>对于 URL 参数的设置，我们可以借助于 params 参数，传入一个字典即可，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   params = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, params=params) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h4 id="其他请求类型"><a href="#其他请求类型" class="headerlink" title="其他请求类型"></a>其他请求类型</h4><p>另外 aiohttp 还支持其他的请求类型，如 POST、PUT、DELETE 等等，这个和 requests 的使用方式有点类似，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">session.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br><span class="line">session.put(<span class="string">&#x27;http://httpbin.org/put&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br><span class="line">session.delete(<span class="string">&#x27;http://httpbin.org/delete&#x27;</span>)</span><br><span class="line">session.head(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line">session.options(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line">session.patch(<span class="string">&#x27;http://httpbin.org/patch&#x27;</span>, data=<span class="string">b&#x27;data&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POST-数据"><a href="#POST-数据" class="headerlink" title="POST 数据"></a>POST 数据</h4><p>对于 POST 表单提交，其对应的请求头的 Content-type 为 <code>application/x-www-form-urlencoded</code>，我们可以用如下方式来实现，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>对于 POST JSON 数据提交，其对应的请求头的 Content-type 为 application/json，我们只需要将 post 方法的 data 参数改成 json 即可，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, json=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br></pre></td></tr></table></figure>
<h3 id="响应字段"><a href="#响应字段" class="headerlink" title="响应字段"></a>响应字段</h3><p>对于响应来说，我们可以用如下的方法分别获取响应的状态码、响应头、响应体、响应体二进制内容、响应体 JSON 结果，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;headers:&#x27;</span>, response.headers)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;body:&#x27;</span>, <span class="keyword">await</span> response.text())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;bytes:&#x27;</span>, <span class="keyword">await</span> response.read())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;json:&#x27;</span>, <span class="keyword">await</span> response.json())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h3 id="超时设置"><a href="#超时设置" class="headerlink" title="超时设置"></a>超时设置</h3><p>对于超时的设置，我们可以借助于 ClientTimeout 对象，比如这里我要设置 1 秒的超时，可以这么来实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   timeout = aiohttp.ClientTimeout(total=<span class="number">1</span>)</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(timeout=timeout) <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h3 id="并发限制"><a href="#并发限制" class="headerlink" title="并发限制"></a>并发限制</h3><p>由于 aiohttp 可以支持非常大的并发，比如上万、十万、百万都是能做到的，但这么大的并发量，目标网站是很可能在短时间内无法响应的，而且很可能瞬时间将目标网站爬挂掉。所以我们需要控制一下爬取的并发量。</p>
<p>在一般情况下，我们可以借助于 asyncio 的 Semaphore 来控制并发量，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line">CONCURRENCY = <span class="number">5</span></span><br><span class="line">URL = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">semaphore = asyncio.Semaphore(CONCURRENCY)</span><br><span class="line">session = <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_api</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> semaphore:</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;scraping&#x27;</span>, URL)</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(URL) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">await</span> response.text()</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">global</span> session</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   scrape_index_tasks = [asyncio.ensure_future(scrape_api()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)]</span><br><span class="line">   <span class="keyword">await</span> asyncio.gather(*scrape_index_tasks)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p>在这里我们声明了 CONCURRENCY 代表爬取的最大并发量为 5，同时声明爬取的目标 URL 为百度。接着我们借助于 Semaphore 创建了一个信号量对象，赋值为 semaphore，这样我们就可以用它来控制最大并发量了。怎么使用呢？我们这里把它直接放置在对应的爬取方法里面，使用 async with 语句将 semaphore 作为上下文对象即可。这样的话，信号量可以控制进入爬取的最大协程数量，最大数量就是我们声明的 CONCURRENCY 的值。</p>
<p>在 main 方法里面，我们声明了 10000 个 task，传递给 gather 方法运行。倘若不加以限制，这 10000 个 task 会被同时执行，并发数量太大。但有了信号量的控制之后，同时运行的 task 的数量最大会被控制在 5 个，这样就能给 aiohttp 限制速度了。</p>
<p>在这里，aiohttp 的基本使用就介绍这么多，更详细的内容还是推荐你到官方文档查阅，链接：<a target="_blank" rel="noopener" href="https://docs.aiohttp.org/。">https://docs.aiohttp.org/。</a></p>
<h2 id="爬取实战"><a href="#爬取实战" class="headerlink" title="爬取实战"></a>爬取实战</h2><p>上面我们介绍了 aiohttp 的基本用法之后，下面我们来根据一个实例实现异步爬虫的实战演练吧。</p>
<p>本次我们要爬取的网站是：<a target="_blank" rel="noopener" href="https://dynamic5.scrape.cuiqingcai.com/">https://dynamic5.scrape.cuiqingcai.com/</a></p>
<p>这是一个书籍网站，整个网站包含了数千本书籍信息，网站是 JavaScript 渲染的，数据可以通过 Ajax 接口获取到，并且接口没有设置任何反爬措施和加密参数，另外由于这个网站比之前的电影案例网站数据量大一些，所以更加适合做异步爬取。</p>
<p>本课时我们要完成的目标有：</p>
<ul>
<li>使用 aiohttp 完成全站的书籍数据爬取。</li>
<li>将数据通过异步的方式保存到 MongoDB 中。</li>
</ul>
<p>在本课时开始之前，请确保你已经做好了如下准备工作：</p>
<ul>
<li>安装好了 Python（最低为 Python 3.6 版本，最好为 3.7 版本或以上），并能成功运行 Python 程序。</li>
<li>了解了 Ajax 爬取的一些基本原理和模拟方法。</li>
<li>了解了异步爬虫的基本原理和 asyncio 库的基本用法。</li>
<li>了解了 aiohttp 库的基本用法。</li>
<li>安装并成功运行了 MongoDB 数据库，并安装了异步存储库 motor。</li>
</ul>
<h3 id="页面分析"><a href="#页面分析" class="headerlink" title="页面分析"></a>页面分析</h3><p>在之前我们讲解了 Ajax 的基本分析方法，本课时的站点结构和之前 Ajax 分析的站点结构类似，都是列表页加详情页的结构，加载方式都是 Ajax，所以我们能轻松分析到如下信息：</p>
<ul>
<li>列表页的 Ajax 请求接口格式为：<code>https://dynamic5.scrape.cuiqingcai.com/api/book/?limit=18&amp;offset=&#123;offset&#125;</code>，limit 的值即为每一页的书的个数，offset 的值为每一页的偏移量，其计算公式为 offset = limit * (page - 1) ，如第 1 页 offset 的值为 0，第 2 页 offset 的值为 18，以此类推。</li>
<li>列表页 Ajax 接口返回的数据里 results 字段包含当前页 18 本书的信息，其中每本书的数据里面包含一个字段 id，这个 id 就是书本身的 ID，可以用来进一步请求详情页。</li>
<li>详情页的 Ajax 请求接口格式为：<code>https://dynamic5.scrape.cuiqingcai.com/api/book/&#123;id&#125;</code>，id 即为书的 ID，可以从列表页的返回结果中获取。</li>
</ul>
<h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>其实一个完善的异步爬虫应该能够充分利用资源进行全速爬取，其思路是维护一个动态变化的爬取队列，每产生一个新的 task 就会将其放入队列中，有专门的爬虫消费者从队列中获取 task 并执行，能做到在最大并发量的前提下充分利用等待时间进行额外的爬取处理。</p>
<p>但上面的实现思路整体较为烦琐，需要设计爬取队列、回调函数、消费者等机制，需要实现的功能较多。由于我们刚刚接触 aiohttp 的基本用法，本课时也主要是了解 aiohttp 的实战应用，所以这里我们将爬取案例的实现稍微简化一下。</p>
<p>在这里我们将爬取的逻辑拆分成两部分，第一部分为爬取列表页，第二部分为爬取详情页。由于异步爬虫的关键点在于并发执行，所以我们可以将爬取拆分为两个阶段：</p>
<ul>
<li>第一阶段为所有列表页的异步爬取，我们可以将所有的列表页的爬取任务集合起来，声明为 task 组成的列表，进行异步爬取。</li>
<li>第二阶段则是拿到上一步列表页的所有内容并解析，拿到所有书的 id 信息，组合为所有详情页的爬取任务集合，声明为 task 组成的列表，进行异步爬取，同时爬取的结果也以异步的方式存储到 MongoDB 里面。</li>
</ul>
<p>因为两个阶段的拆分之后需要串行执行，所以可能不能达到协程的最佳调度方式和资源利用情况，但也差不了很多。但这个实现思路比较简单清晰，代码实现也比较简单，能够帮我们快速了解 aiohttp 的基本使用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/4%E7%88%AC%E8%99%AB%E9%9D%99%E6%80%81%E6%8F%90%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/4%E7%88%AC%E8%99%AB%E9%9D%99%E6%80%81%E6%8F%90%E5%8F%96/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-29 21:47:51" itemprop="dateCreated datePublished" datetime="2022-10-29T21:47:51+08:00">2022-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-28 16:32:24" itemprop="dateModified" datetime="2022-10-28T16:32:24+08:00">2022-10-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="页面解析之数据提取"><a href="#页面解析之数据提取" class="headerlink" title="页面解析之数据提取"></a>页面解析之数据提取</h1><p>一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值，内容一般分为两部分，非结构化的文本，或结构化的文本。</p>
<h3 id="关于结构化的数据"><a href="#关于结构化的数据" class="headerlink" title="关于结构化的数据"></a>关于结构化的数据</h3><p>JSON、XML</p>
<h3 id="关于非结构化的数据"><a href="#关于非结构化的数据" class="headerlink" title="关于非结构化的数据"></a>关于非结构化的数据</h3><h4 id="关于HTML文本（包含JavaScript代码）"><a href="#关于HTML文本（包含JavaScript代码）" class="headerlink" title="关于HTML文本（包含JavaScript代码）"></a>关于HTML文本（包含JavaScript代码）</h4><p>HTML文本（包含JavaScript代码）是最常见的数据格式，理应属于结构化的文本组织，但因为一般我们需要的关键信息并非直接可以得到，需要进行对HTML的解析查找，甚至一些字符串操作才能得到，所以还是归类于非结构化的数据处理中。</p>
<p>把网页比作一个人，那么HTML便是他的骨架，JS便是他的肌肉，CSS便是它的衣服。</p>
<p>常见解析方式如下： XPath、CSS选择器、正则表达式</p>
<h4 id="一段文本"><a href="#一段文本" class="headerlink" title="一段文本"></a>一段文本</h4><p>例如一篇文章，或者一句话，我们的初衷是提取有效信息，所以如果是滞后处理，可以直接存储，如果是需要实时提取有用信息，常见的处理方式如下：</p>
<ul>
<li>分词 根据抓取的网站类型，使用不同词库，进行基本的分词，然后变成词频统计，类似于向量的表示，词为方向，词频为长度。</li>
<li>NLP 自然语言处理，进行语义分析，用结果表示，例如正负面等。</li>
</ul>
<h1 id="XPath-语言"><a href="#XPath-语言" class="headerlink" title="XPath 语言"></a>XPath 语言</h1><p>XPath（XML Path Language）是XML路径语言,它是一种用来定位XML文档中某部分位置的语言。</p>
<h3 id="学习目的"><a href="#学习目的" class="headerlink" title="学习目的"></a>学习目的</h3><p>将HTML转换成XML文档之后，用XPath查找HTML节点或元素</p>
<p>比如用“/”来作为上下层级间的分隔，第一个“/”表示文档的根节点（注意，不是指文档最外层的tag节点，而是指文档本身）。</p>
<p>比如对于一个HTML文件来说，最外层的节点应该是”/html”。</p>
<h3 id="XPath开发工具"><a href="#XPath开发工具" class="headerlink" title="XPath开发工具"></a>XPath开发工具</h3><ol>
<li><p>开源的XPath表达式编辑工具:XMLQuire(XML格式文件可用)</p>
</li>
<li><p>chrome插件 XPath Helper</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-Xpath_Helper.bmp" alt="img"></p>
</li>
<li><p>firefox插件 XPath Checker</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/01-checker.png" alt="img"></p>
</li>
</ol>
<p>XPath语法参考文档：</p>
<p><a target="_blank" rel="noopener" href="http://www.w3school.com.cn/xpath/index.asp">http://www.w3school.com.cn/xpath/index.asp</a></p>
<h3 id="XPath语法"><a href="#XPath语法" class="headerlink" title="XPath语法"></a>XPath语法</h3><p>XPath 是一门在 XML 文档中查找信息的语言。</p>
<p>XPath 可用来在 XML 文档中对元素和属性进行遍历。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bookstore</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">book</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span> <span class="attr">lang</span>=<span class="string">&quot;eng&quot;</span>&gt;</span>Harry Potter<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">price</span>&gt;</span>29.99<span class="tag">&lt;/<span class="name">price</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">book</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">book</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span> <span class="attr">lang</span>=<span class="string">&quot;eng&quot;</span>&gt;</span>Learning XML<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">price</span>&gt;</span>39.95<span class="tag">&lt;/<span class="name">price</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">book</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">bookstore</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。</p>
<p>下面列出了最有用的路径表达式：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>/</td>
<td>从根节点选取。</td>
</tr>
<tr>
<td>nodename</td>
<td>选取此节点的<strong>所有子节点</strong>。</td>
</tr>
<tr>
<td>//</td>
<td>从当前节点 选择 <strong>所有匹配</strong>文档中的节点</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点。</td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点。</td>
</tr>
<tr>
<td>@</td>
<td>选取属性。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们已列出了一些路径表达式以及表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore</td>
<td>选取根元素 bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！</td>
</tr>
<tr>
<td>bookstore</td>
<td>选取 bookstore 元素的所有子节点。默认从根节点选取</td>
</tr>
<tr>
<td>bookstore/book</td>
<td>选取属于 bookstore 的子元素的所有 book 元素。</td>
</tr>
<tr>
<td>//book</td>
<td>选取所有 book 子元素，而不管它们在文档中的位置。</td>
</tr>
<tr>
<td>//book/./title</td>
<td>选取所有 book 子元素，从当前节点查找title节点</td>
</tr>
<tr>
<td>//price/..</td>
<td>选取所有 book 子元素，从当前节点查找父节点</td>
</tr>
<tr>
<td>bookstore//book</td>
<td>选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。</td>
</tr>
<tr>
<td>//@lang</td>
<td>选取名为 lang 的所有属性。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>谓语条件（Predicates）<ol>
<li>谓语用来查找<strong>某个特定的信息</strong>或者<strong>包含某个指定的值</strong>的节点。</li>
<li>所谓”谓语条件”，就是对路径表达式的附加条件</li>
<li>谓语是<strong>被嵌在方括号</strong>中，都写在方括号”[]”中，表示对节点进行进一步的筛选。</li>
</ol>
</li>
</ul>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/book[1]</td>
<td>选取属于 bookstore 子元素的第一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取属于 bookstore 子元素的最后一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()-1]</td>
<td>选取属于 bookstore 子元素的倒数第二个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[position()&lt;3]</td>
<td>选取最前面的两个属于 bookstore 元素的子元素的 book 元素。</td>
</tr>
<tr>
<td>//title[@lang]</td>
<td>选取所有拥有名为 lang 的属性的 title 元素。</td>
</tr>
<tr>
<td>//title[@lang=’eng’]</td>
<td>选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。</td>
</tr>
<tr>
<td>//book[price]</td>
<td>选取所有 book 元素，且被选中的book元素必须带有price子元素</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]</td>
<td>选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]/title</td>
<td>选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>选取未知节点</li>
</ul>
<p>XPath 通配符可用来选取未知的 XML 元素。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>通配符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>匹配任何元素节点。</td>
</tr>
<tr>
<td>@*</td>
<td>匹配任何属性节点。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/*</td>
<td>选取 bookstore 元素的所有子元素。</td>
</tr>
<tr>
<td>//*</td>
<td>选取文档中的所有元素。</td>
</tr>
<tr>
<td>//title[@*]</td>
<td>选取所有带有属性的 title 元素。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>选取若干路径</li>
</ul>
<p>通过在路径表达式中使用“|”运算符，您可以选取若干个路径。</p>
<blockquote>
<p>实例</p>
</blockquote>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>//book/title \</td>
<td>//book/price</td>
<td>选取 book 元素的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>//title \</td>
<td>//price</td>
<td>选取文档中的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>/bookstore/book/title \</td>
<td>//price</td>
<td>选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="XPath-高级用法"><a href="#XPath-高级用法" class="headerlink" title="XPath 高级用法"></a>XPath 高级用法</h3><ul>
<li>模糊查询 contains</li>
</ul>
<p>目前许多web框架，都是动态生成界面的元素id，因此在每次操作相同界面时，ID都是变化的，这样为自动化测试造成了一定的影响。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;eleWrapper&quot;</span> <span class="attr">title</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">class</span>=<span class="string">&quot;textfield&quot;</span> <span class="attr">name</span>=<span class="string">&quot;ID9sLJQnkQyLGLhYShhlJ6gPzHLgvhpKpLzp2Tyh4hyb1b4pnvzxFR!-166749344!1357374592067&quot;</span> <span class="attr">id</span>=<span class="string">&quot;nt1357374592068&quot;</span>  /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>解决方法 使用xpath的匹配功能，<code>//input[contains(@id,&#39;nt&#39;)]</code></p>
<ul>
<li>测试使用的XML</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Root</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Person</span> <span class="attr">ID</span>=<span class="string">&quot;1001&quot;</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Name</span> <span class="attr">lang</span>=<span class="string">&quot;zh-cn&quot;</span> &gt;</span>张城斌<span class="tag">&lt;/<span class="name">Name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Email</span> <span class="attr">xmlns</span>=<span class="string">&quot;www.quicklearn.cn&quot;</span> &gt;</span> cbcye@live.com <span class="tag">&lt;/<span class="name">Email</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Blog</span>&gt;</span>http://cbcye.cnblogs.com<span class="tag">&lt;/<span class="name">Blog</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Person</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Person</span> <span class="attr">ID</span>=<span class="string">&quot;1002&quot;</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Name</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span> &gt;</span>Gary Zhang<span class="tag">&lt;/<span class="name">Name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Email</span> <span class="attr">xmlns</span>=<span class="string">&quot;www.quicklearn.cn&quot;</span> &gt;</span> GaryZhang@cbcye.com<span class="tag">&lt;/<span class="name">Email</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Blog</span>&gt;</span>http://www.quicklearn.cn<span class="tag">&lt;/<span class="name">Blog</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Person</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>查询所有Blog节点值中带有 cn 字符串的Person节点</li>
</ol>
<p>Xpath表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Root//Person[contains(Blog,&#x27;cn&#x27;)]</span><br></pre></td></tr></table></figure>
<p>2.查询所有Blog节点值中带有 cn 字符串并且属性ID值中有01的Person节点</p>
<p>Xpath表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Root//Person[contains(Blog,&#x27;cn&#x27;) and contains(@ID,&#x27;01&#x27;)]</span><br></pre></td></tr></table></figure>
<h1 id="学习笔记"><a href="#学习笔记" class="headerlink" title="学习笔记"></a>学习笔记</h1><p>1.依靠自己的属性，文本定位</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//td[text()=<span class="string">&#x27;Data Import&#x27;</span>]</span><br><span class="line"></span><br><span class="line">//div[contains(@<span class="keyword">class</span>,<span class="string">&#x27;cux-rightArrowIcon-on&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">//a[text()=<span class="string">&#x27;马上注册&#x27;</span>]</span><br><span class="line"></span><br><span class="line">//<span class="built_in">input</span>[@<span class="built_in">type</span>=<span class="string">&#x27;radio&#x27;</span> <span class="keyword">and</span> @value=<span class="string">&#x27;1&#x27;</span>]     多条件</span><br><span class="line"></span><br><span class="line">//span[@name=<span class="string">&#x27;bruce&#x27;</span>][text()=<span class="string">&#x27;bruce1&#x27;</span>][<span class="number">1</span>]   多条件</span><br><span class="line"></span><br><span class="line"> //span[@<span class="built_in">id</span>=<span class="string">&#x27;bruce1&#x27;</span> <span class="keyword">or</span> text()=<span class="string">&#x27;bruce2&#x27;</span>]  找出多个</span><br><span class="line"></span><br><span class="line"> //span[text()=<span class="string">&#x27;bruce1&#x27;</span> <span class="keyword">and</span> text()=<span class="string">&#x27;bruce2&#x27;</span>]  找出多个</span><br></pre></td></tr></table></figure>
<p>2.依靠父节点定位</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//div[@class=&#x27;x-grid-col-name x-grid-cell-inner&#x27;]/div</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;dynamicGridTestInstanceformclearuxformdiv&#x27;]/div</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;test&#x27;]/input</span><br></pre></td></tr></table></figure>
<p>3.依靠子节点定位</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//div[div[@id=&#x27;navigation&#x27;]]</span><br><span class="line"></span><br><span class="line">//div[div[@name=&#x27;listType&#x27;]]</span><br><span class="line"></span><br><span class="line">//div[p[@name=&#x27;testname&#x27;]]</span><br></pre></td></tr></table></figure>
<p>4.混合型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[div[@name=&#x27;listType&#x27;]]//img</span><br><span class="line"></span><br><span class="line">//td[a//font[contains(text(),&#x27;seleleium2从零开始 视屏&#x27;)]]//input[@type=&#x27;checkbox&#x27;]</span><br></pre></td></tr></table></figure>
<p>5.进阶部分</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//input[@id=&#x27;123&#x27;]/following-sibling::input   找下一个兄弟节点</span><br><span class="line"></span><br><span class="line">//input[@id=&#x27;123&#x27;]/preceding-sibling::span    上一个兄弟节点</span><br><span class="line"></span><br><span class="line">//input[starts-with(@id,&#x27;123&#x27;)]               以什么开头</span><br><span class="line"></span><br><span class="line">//span[not(contains(text(),&#x27;xpath&#x27;)）]        不包含xpath字段的span</span><br></pre></td></tr></table></figure>
<p>6.索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//div/input[2]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()=3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()&gt;3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[position()&lt;3]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[last()]</span><br><span class="line"></span><br><span class="line">//div[@id=&#x27;position&#x27;]/span[last()-1]</span><br></pre></td></tr></table></figure>
<p>7.substring 截取判断</p>
<div data-for="result" id="swfEveryCookieWrap"></div>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//*[substring(@id,4,5)=&#x27;Every&#x27;]/@id  截取该属性 定位3,取长度5的字符 </span><br><span class="line"></span><br><span class="line">//*[substring(@id,4)=&#x27;EveryCookieWrap&#x27;]  截取该属性从定位3 到最后的字符 </span><br><span class="line"></span><br><span class="line">//*[substring-before(@id,&#x27;C&#x27;)=&#x27;swfEvery&#x27;]/@id   属性 &#x27;C&#x27;之前的字符匹配</span><br><span class="line"></span><br><span class="line">//*[substring-after(@id,&#x27;C&#x27;)=&#x27;ookieWrap&#x27;]/@id   属性&#x27;C之后的字符匹配</span><br></pre></td></tr></table></figure>
<p>8.通配符*</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//span[@*=&#x27;bruce&#x27;]</span><br><span class="line"></span><br><span class="line">//*[@name=&#x27;bruce&#x27;]</span><br></pre></td></tr></table></figure>
<p>9.轴</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[span[text()=&#x27;+++current node&#x27;]]/parent::div    找父节点</span><br><span class="line"></span><br><span class="line">//div[span[text()=&#x27;+++current node&#x27;]]/ancestor::div    找祖先节点</span><br></pre></td></tr></table></figure>
<p>10.孙子节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//div[span[text()=&#x27;current note&#x27;]]/descendant::div/span[text()=&#x27;123&#x27;]</span><br><span class="line"></span><br><span class="line">//div[span[text()=&#x27;current note&#x27;]]//div/span[text()=&#x27;123&#x27;]          两个表达的意思一样</span><br></pre></td></tr></table></figure>
<h3 id="xpath提取多个标签下的text"><a href="#xpath提取多个标签下的text" class="headerlink" title="xpath提取多个标签下的text"></a>xpath提取多个标签下的text</h3><p>在写爬虫的时候，经常会使用xpath进行数据的提取，对于如下的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test1&quot;&gt;大家好！&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>使用xpath提取是非常方便的。假设网页的源代码在selector中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test1&quot;]/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>就可以把“大家好！”提取到data变量中去。</p>
<p>然而如果遇到下面这段代码呢？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test2&quot;&gt;美女，&lt;font color=red&gt;你的微信是多少？&lt;/font&gt;&lt;div&gt;</span><br></pre></td></tr></table></figure>
<p>如果使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test2&quot;]/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>只能提取到“美女，”；</p>
<p>如果使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test2&quot;]/font/text()&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>又只能提取到“你的微信是多少？”</p>
<p><strong>可是我本意是想把“美女，你的微信是多少？”这一整个句子提取出来。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div id=&quot;test3&quot;&gt;我左青龙，&lt;span id=&quot;tiger&quot;&gt;右白虎，&lt;ul&gt;上朱雀，&lt;li&gt;下玄武。&lt;/li&gt;&lt;/ul&gt;老牛在当中，&lt;/span&gt;龙头在胸口。&lt;div&gt;</span><br></pre></td></tr></table></figure>
<p>而且内部的标签还不固定，如果我有一百段这样类似的html代码，又如何使用xpath表达式，以最快最方便的方式提取出来？</p>
<p><strong>使用xpath的string(.)</strong></p>
<p>以第三段代码为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = selector.xpath(&#x27;//div[@id=&quot;test3&quot;]&#x27;)</span><br><span class="line">info = data.xpath(&#x27;string(.)&#x27;).extract()[0]</span><br></pre></td></tr></table></figure>
<p>这样，就可以把“我左青龙，右白虎，上朱雀，下玄武。老牛在当中，龙头在胸口”整个句子提取出来，赋值给info变量。</p>
<h1 id="非结构化数据之lxml库"><a href="#非结构化数据之lxml库" class="headerlink" title="非结构化数据之lxml库"></a>非结构化数据之lxml库</h1><p>lxml 是一种使用 Python 编写的库,可以迅速、灵活地处理 XML ，支持 XPath (XML Path Language)</p>
<p>lxml python 官方文档</p>
<p><a target="_blank" rel="noopener" href="http://lxml.de/index.html">http://lxml.de/index.html</a></p>
<h4 id="学习目的-1"><a href="#学习目的-1" class="headerlink" title="学习目的"></a>学习目的</h4><p>利用上节课学习的XPath语法，来快速的定位 <strong>特定元素以及节点信息</strong>，目的是 提取出 HTML、XML 目标数据</p>
<h4 id="如何安装"><a href="#如何安装" class="headerlink" title="如何安装"></a>如何安装</h4><ul>
<li>Ubuntu :</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxml2-dev libxslt1-dev python-dev</span><br><span class="line">sudo apt-get install zlib1g-dev</span><br><span class="line">sudo apt-get install libevent-dev</span><br><span class="line">sudo pip install lxml</span><br></pre></td></tr></table></figure>
<p>利用 pip 安装即可</p>
<ul>
<li><p>Windows:</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/g1apassz/article/details/46574963">http://blog.csdn.net/g1apassz/article/details/46574963</a></p>
<p><a target="_blank" rel="noopener" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml">http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</a></p>
</li>
</ul>
<h4 id="初步使用"><a href="#初步使用" class="headerlink" title="初步使用"></a>初步使用</h4><p>首先我们利用lxml来解析 HTML 代码，先来一个小例子来感受一下它的基本用法。</p>
<p>使用 lxml 的 etree 库，然后利用 etree.HTML 初始化，然后我们将其打印出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">  &lt;ul&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">       &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;</span></span><br><span class="line"><span class="string">   &lt;/ul&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#Parses an HTML document from a string</span></span><br><span class="line">html = etree.HTML(text)   </span><br><span class="line"><span class="comment">#Serialize an element to an encoded string representation of its XML tree</span></span><br><span class="line">result = etree.tostring(html)</span><br><span class="line"><span class="built_in">print</span> result</span><br></pre></td></tr></table></figure>
<p>所以输出结果是这样的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;&lt;body&gt;&lt;div&gt;</span><br><span class="line">  &lt;ul&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;&lt;a href=<span class="string">&quot;link1.html&quot;</span>&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;&lt;a href=<span class="string">&quot;link2.html&quot;</span>&gt;second item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-inactive&quot;</span>&gt;&lt;a href=<span class="string">&quot;link3.html&quot;</span>&gt;&lt;span <span class="keyword">class</span>=<span class="string">&quot;bold&quot;</span>&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;&lt;a href=<span class="string">&quot;link4.html&quot;</span>&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">       &lt;li <span class="keyword">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;&lt;a href=<span class="string">&quot;link5.html&quot;</span>&gt;fifth item&lt;/a&gt;</span><br><span class="line">   &lt;/li&gt;&lt;/ul&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<p>不仅补全了 li 标签，还添加了 body，html 标签。</p>
<h3 id="XPath实例测试"><a href="#XPath实例测试" class="headerlink" title="XPath实例测试"></a>XPath实例测试</h3><ul>
<li>（1）获取所有的 <code>&lt;li&gt;</code> 标签</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(html)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> result</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(result)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(result)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(result[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;lxml.etree._ElementTree&#x27;</span>&gt;</span><br><span class="line">[&lt;Element li at <span class="number">0x1014e0e18</span>&gt;, &lt;Element li at <span class="number">0x1014e0ef0</span>&gt;, &lt;Element li at <span class="number">0x1014e0f38</span>&gt;, &lt;Element li at <span class="number">0x1014e0f80</span>&gt;, &lt;Element li at <span class="number">0x1014e0fc8</span>&gt;]</span><br><span class="line"><span class="number">5</span></span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;lxml.etree._Element&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p>可见，每个元素都是 Element 类型;是一个个的标签元素，类似现在的实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;Element li at 0x1014e0e18&gt; Element类型代表的就是</span><br><span class="line">&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>［注意］</p>
<p>Element类型是一种灵活的容器对象，用于在内存中存储结构化数据。</p>
<p>每个element对象都具有以下属性：</p>
</li>
</ul>
<p>　　1. tag：string对象，标签，用于标识该元素表示哪种数据（即元素类型）。</p>
<p>　　2. attrib：dictionary对象，表示附有的属性。</p>
<p>　　3. text：string对象，表示element的内容。</p>
<p>　　4. tail：string对象，表示element闭合之后的尾迹。</p>
<ul>
<li><p>实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;tag attrib1=1&gt;text&lt;/tag&gt;tail</span><br><span class="line">1     2        3         4</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result[0].tag</span><br><span class="line">result[0].text</span><br><span class="line">result[0].tail</span><br><span class="line">result[0].attrib</span><br></pre></td></tr></table></figure>
</li>
<li><p>（2）获取 <code>&lt;li&gt;</code> 标签的所有 class</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/@class&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;item-0&#x27;, &#x27;item-1&#x27;, &#x27;item-inactive&#x27;, &#x27;item-1&#x27;, &#x27;item-0&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（3）获取 <code>&lt;li&gt;</code> 标签下属性 href 为 link1.html 的 <code>&lt;a&gt;</code> 标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(<span class="string">&#x27;//li/a[@href=&quot;link1.html&quot;]&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element a at 0x10ffaae18&gt;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（4）获取 <code>&lt;li&gt;</code> 标签下的所有 <code>&lt;span&gt;</code> 标签</p>
<p>注意这么写是不对的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/span&#x27;)</span><br></pre></td></tr></table></figure>
<p>因为 / 是用来获取子元素的，而 <code>&lt;span&gt;</code> 并不是 <code>&lt;li&gt;</code> 的子元素，所以，要用双斜杠</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li//span&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element span at 0x10d698e18&gt;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（5）获取 <code>&lt;li&gt;</code> 标签下的所有 class，不包括 <code>&lt;li&gt;</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li/a//@class&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;blod&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（6）获取最后一个 <code>&lt;li&gt;</code> 的<code>&lt;a&gt;</code> 的 href</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.xpath(&#x27;//li[last()]/a/@href&#x27;)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;link5.html&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>（7）获取 class 为 bold 的标签名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = html.xpath(&#x27;//*[@class=&quot;bold&quot;]&#x27;)</span><br><span class="line">print result[0].tag</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">span</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="开始练习"><a href="#开始练习" class="headerlink" title="开始练习"></a>开始练习</h3><p>通过以上实例的练习，相信大家对 XPath 的基本用法有了基本的了解</p>
<h4 id="实战项目"><a href="#实战项目" class="headerlink" title="实战项目"></a>实战项目</h4><p>以腾讯招聘网站为例</p>
<p><a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&amp;start=10">http://hr.tencent.com/position.php?&amp;start=10</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">&#x27;http://hr.tencent.com/position.php?&amp;start=10#a&#x27;</span>)</span><br><span class="line">response =urllib2.urlopen(request)</span><br><span class="line">resHtml = response.read()</span><br><span class="line">output =<span class="built_in">open</span>(<span class="string">&#x27;tencent.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">html = etree.HTML(resHtml)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//tr[@class=&quot;odd&quot;] | //tr[@class=&quot;even&quot;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">    item=&#123;&#125;</span><br><span class="line"></span><br><span class="line">    name = site.xpath(<span class="string">&#x27;./td[1]/a&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    detailLink = site.xpath(<span class="string">&#x27;./td[1]/a&#x27;</span>)[<span class="number">0</span>].attrib[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    catalog = site.xpath(<span class="string">&#x27;./td[2]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    recruitNumber = site.xpath(<span class="string">&#x27;./td[3]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    workLocation = site.xpath(<span class="string">&#x27;./td[4]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    publishTime = site.xpath(<span class="string">&#x27;./td[5]&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="built_in">type</span>(name)</span><br><span class="line">    <span class="built_in">print</span> name,detailLink,catalog,recruitNumber,workLocation,publishTime</span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>]=name</span><br><span class="line">    item[<span class="string">&#x27;detailLink&#x27;</span>]=detailLink</span><br><span class="line">    item[<span class="string">&#x27;catalog&#x27;</span>]=catalog</span><br><span class="line">    item[<span class="string">&#x27;recruitNumber&#x27;</span>]=recruitNumber</span><br><span class="line">    item[<span class="string">&#x27;publishTime&#x27;</span>]=publishTime</span><br><span class="line"></span><br><span class="line">    line = json.dumps(item,ensure_ascii=<span class="literal">False</span>) + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> line</span><br><span class="line">    output.write(line.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>
<h1 id="CSS-Selector"><a href="#CSS-Selector" class="headerlink" title="CSS Selector"></a>CSS Selector</h1><p>CSS(即层叠样式表Cascading Stylesheet),Selector来定位（locate）页面上的元素（Elements）。Selenium官网的Document里极力推荐使用CSS locator，而不是XPath来定位元素，原因是CSS locator比XPath locator速度快.</p>
<h3 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a>Beautiful Soup</h3><ul>
<li>支持从HTML或XML文件中提取数据的Python库</li>
<li>支持Python标准库中的HTML解析器</li>
<li>还支持一些第三方的解析器lxml, 使用的是 Xpath 语法，推荐安装。</li>
</ul>
<p>Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了</p>
<ul>
<li><p>Beautiful Soup4 安装</p>
<p>官方文档链接:</p>
<p><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></p>
<p>可以利用 pip来安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装解析器(上节课已经安装过)</p>
<p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器,其中一个是 lxml .根据操作系统不同,可以选择下列方法来安装lxml:</p>
<p>另一个可供选择的解析器是纯Python实现的 html5lib , html5lib的解析方式与浏览器相同,可以选择下列方法来安装html5lib:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install html5lib</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>下表列出了主要的解析器：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python标准库</td>
<td>BeautifulSoup(markup, “html.parser”)</td>
<td>Python的内置标准库;执行速度适中;文档容错能力强</td>
<td>Python 2.7.3 or 3.2.2前 的版本中文档容错能力差</td>
</tr>
<tr>
<td>lxml HTML 解析器</td>
<td>BeautifulSoup(markup, “lxml”)</td>
<td>速度快;文档容错能力强 ;</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>lxml XML 解析器</td>
<td>BeautifulSoup(markup, [“lxml-xml”]) BeautifulSoup(markup, “xml”)</td>
<td>速度快;唯一支持XML的解析器</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>html5lib</td>
<td>BeautifulSoup(markup, “html5lib”)</td>
<td>最好的容错性;以浏览器的方式解析文档;生成HTML5格式的文档</td>
<td>速度慢;不依赖外部扩展</td>
</tr>
</tbody>
</table>
</div>
<p>推荐使用lxml作为解析器,因为效率更高. 在Python2.7.3之前的版本和Python3中3.2.2之前的版本,必须安装lxml或html5lib, 因为那些Python版本的标准库中内置的HTML解析方法不够稳定.</p>
<ul>
<li>快速开始</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(html_doc,<span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>下面我们来打印一下 soup 对象的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print soup</span><br></pre></td></tr></table></figure>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-bs4_01.png" alt="img"></p>
<p>格式化输出soup 对象</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02-bs4_02.png" alt="img"></p>
<h3 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h3><p>在写 CSS 时：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">标签名不加任何修饰</span><br><span class="line"></span><br><span class="line">类名前加点</span><br><span class="line"></span><br><span class="line">id名前加 #</span><br></pre></td></tr></table></figure>
<p>利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list</p>
<ul>
<li><p>通过标签名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;title&#x27;</span>) </span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过类名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;.sister&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过 id 名查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;#link1&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>直接子标签查找</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&quot;head &gt; title&quot;</span>)</span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>组合查找</p>
<p>组合查找即标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，</p>
<p><strong>属性和标签不属于同一节点 二者需要用空格分开</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;p #link1&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>属性查找</p>
<p>查找时还可以加入属性元素，属性需要用中括号括起来</p>
<p><strong>注意属性和标签属于同一节点，所以中间不能加空格</strong>，否则会无法匹配到</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a[class=&quot;sister&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a[href=&quot;http://example.com/elsie&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
<p>同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;p a[href=&quot;http://example.com/elsie&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment">#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure>
<p>以上的 select 方法返回的结果都是列表形式，可以遍历形式输出</p>
<p>用 <strong>get_text()</strong> 方法来获取它的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;title&#x27;</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> soup.select(<span class="string">&#x27;title&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span> title.get_text()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><p>Tag 是什么？通俗点讲就是 HTML 中的一个个标签，例如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</span><br><span class="line">print type(soup.select(&#x27;a&#x27;)[0])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bs4.element.Tag</span><br></pre></td></tr></table></figure>
<p>对于 Tag，它有两个重要的属性，是 name 和 attrs，下面我们分别来感受一下</p>
<ol>
<li><p>name</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.name</span><br><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].name</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[document]</span><br><span class="line"><span class="string">&#x27;a&#x27;</span></span><br></pre></td></tr></table></figure>
<p>soup 对象本身比较特殊，它的 name 即为 [document]，对于其他内部标签，输出的值便为标签本身的名称。</p>
</li>
<li><p>attrs</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].attrs</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://example.com/elsie&#x27;</span>, <span class="string">&#x27;class&#x27;</span>: [<span class="string">&#x27;sister&#x27;</span>], <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;link1&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，我们把 soup.select(‘a’)[0] 标签的所有属性打印输出了出来，得到的类型是一个字典。</p>
<p>如果我们想要单独获取某个属性，可以这样，例如我们获取它的 class 叫什么</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> soup.select(<span class="string">&#x27;a&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;class&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;sister&#x27;]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="实战案例"><a href="#实战案例" class="headerlink" title="实战案例"></a>实战案例</h3><p>我们还是以 腾讯招聘网站</p>
<p><a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&amp;start=10#a">http://hr.tencent.com/position.php?&amp;start=10#a</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">&#x27;http://hr.tencent.com/position.php?&amp;start=10#a&#x27;</span>)</span><br><span class="line">response =urllib2.urlopen(request)</span><br><span class="line">resHtml = response.read()</span><br><span class="line">output =<span class="built_in">open</span>(<span class="string">&#x27;tencent.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">html = BeautifulSoup(resHtml,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">result = html.select(<span class="string">&#x27;tr[class=&quot;even&quot;]&#x27;</span>)</span><br><span class="line">result2 = html.select(<span class="string">&#x27;tr[class=&quot;odd&quot;]&#x27;</span>)</span><br><span class="line">result+=result2</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">    item=&#123;&#125;</span><br><span class="line"></span><br><span class="line">    name = site.select(<span class="string">&#x27;td a&#x27;</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">    detailLink = site.select(<span class="string">&#x27;td a&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    catalog = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].get_text()</span><br><span class="line">    recruitNumber = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">2</span>].get_text()</span><br><span class="line">    workLocation = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].get_text()</span><br><span class="line">    publishTime = site.select(<span class="string">&#x27;td&#x27;</span>)[<span class="number">4</span>].get_text()</span><br><span class="line"></span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>]=name</span><br><span class="line">    item[<span class="string">&#x27;detailLink&#x27;</span>]=detailLink</span><br><span class="line">    item[<span class="string">&#x27;catalog&#x27;</span>]=catalog</span><br><span class="line">    item[<span class="string">&#x27;recruitNumber&#x27;</span>]=recruitNumber</span><br><span class="line">    item[<span class="string">&#x27;publishTime&#x27;</span>]=publishTime</span><br><span class="line"></span><br><span class="line">    line = json.dumps(item,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span> line</span><br><span class="line"></span><br><span class="line">    output.write(line.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><p><strong>掌握了XPath、CSS选择器，为什么还要学习正则？</strong></p>
<p>正则表达式，用标准正则解析，一般会把HTML当做普通文本，用指定格式匹配当相关文本，适合小片段文本，或者某一串字符(比如电话号码、邮箱账户)，或者HTML包含javascript的代码，无法用CSS选择器或者XPath</p>
<p><a target="_blank" rel="noopener" href="http://tool.oschina.net/regex/">在线正则表达式测试网站</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.python.org/2/library/re.html#regular-expression-objects">官方文档</a></p>
<p><strong>了解正则表达式</strong></p>
<p>正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个”规则字符串”，这个”规则字符串”用来表达对字符串的一种过滤逻辑。</p>
<h3 id="正则表达式常见概念"><a href="#正则表达式常见概念" class="headerlink" title="正则表达式常见概念"></a>正则表达式常见概念</h3><ul>
<li><p>边界匹配</p>
<p>^ — 与字符串开始的地方匹配，不匹配任何字符；</p>
<p>$ — 与字符串结束的地方匹配，不匹配任何字符；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str = &quot;cat abdcatdetf ios&quot;</span><br><span class="line">^cat : 验证该行以c开头紧接着是a，然后是t</span><br><span class="line">ios$ : 验证该行以t结尾倒数第二个字符为a倒数第三个字符为c</span><br><span class="line">^cat$: 以c开头接着是a-&gt;t然后是行结束：只有cat三个字母的数据行</span><br><span class="line">^$   : 开头之后马上结束：空白行，不包括任何字符</span><br><span class="line">^    : 行的开头，可以匹配任何行，因为每个行都有行开头</span><br></pre></td></tr></table></figure>
<p>\b — 匹配一个单词边界，也就是单词和空格之间的位置，不匹配任何字符；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;er\b&quot;可以匹配&quot;never&quot;中的&quot;er&quot;，但不能匹配&quot;verb&quot;中的&quot;er&quot;。</span><br></pre></td></tr></table></figure>
<p>\B — \b取非，即匹配一个非单词边界；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;er\B&quot;能匹配&quot;verb&quot;中的&quot;er&quot;，但不能匹配&quot;never&quot;中的&quot;er&quot;。</span><br></pre></td></tr></table></figure>
</li>
<li><p>数量词的贪婪模式与非贪婪模式</p>
<p>正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">正则表达式&quot;ab*&quot;如果用于查找&quot;abbbc&quot;，将找到&quot;abbb&quot;。而如果使用非贪婪的数量词&quot;ab*?&quot;，将找到&quot;a&quot;。</span><br></pre></td></tr></table></figure>
</li>
<li><p>反斜杠问题</p>
<p>与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。</p>
<p>假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。</p>
<p>Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\“表示。</p>
</li>
</ul>
<p>  同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">a=re.search(<span class="string">r&quot;\\&quot;</span>,<span class="string">&quot;ab123bb\c&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> a.group()</span><br><span class="line">\</span><br><span class="line">a=re.search(<span class="string">r&quot;\d&quot;</span>,<span class="string">&quot;ab123bb\c&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> a.group()</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="Python-Re模块"><a href="#Python-Re模块" class="headerlink" title="Python Re模块"></a>Python Re模块</h3><p>Python 自带了re模块，它提供了对正则表达式的支持。</p>
<h3 id="match函数"><a href="#match函数" class="headerlink" title="match函数"></a>match函数</h3><p>re.match 尝试从字符串的<strong>起始位置</strong>匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。</p>
<p>下面是此函数的语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=0)</span><br></pre></td></tr></table></figure>
<p>这里的参数的说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>pattern</td>
<td>这是正则表达式来进行匹配。</td>
</tr>
<tr>
<td>string</td>
<td>这是字符串，这将被搜索匹配的模式，在字符串的开头。</td>
</tr>
<tr>
<td>flags</td>
<td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td>
</tr>
</tbody>
</table>
</div>
<p>匹配成功re.match方法返回一个匹配的对象，否则返回None。</p>
<p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>匹配对象的方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>group(num=0)</td>
<td>此方法返回整个匹配（或指定分组num）</td>
</tr>
<tr>
<td>groups()</td>
<td>此方法返回所有元组匹配的子组（空，如果没有）</td>
</tr>
</tbody>
</table>
</div>
<h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span></span><br><span class="line"></span><br><span class="line">matchObj = re.match( <span class="string">r&#x27;(.*) are (.*?) .*&#x27;</span>, line, re.M|re.I)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> matchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group() : &quot;</span>, matchObj.group()</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group(1) : &quot;</span>, matchObj.group(<span class="number">1</span>)</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;matchObj.group(2) : &quot;</span>, matchObj.group(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;No match!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，它产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matchObj.group() :  Cats are smarter than dogs</span><br><span class="line">matchObj.group(1) :  Cats</span><br><span class="line">matchObj.group(2) :  smarter</span><br></pre></td></tr></table></figure>
<h4 id="正则表达式修饰符-选项标志"><a href="#正则表达式修饰符-选项标志" class="headerlink" title="正则表达式修饰符 - 选项标志"></a>正则表达式修饰符 - 选项标志</h4><p>正则表达式字面可以包含一个可选的修饰符来控制匹配的各个方面。修饰符被指定为一个可选的标志。可以使用异或提供多个修饰符（|），如先前所示，并且可以由这些中的一个来表示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>修饰符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.I(re.IGNORECASE)</td>
<td>使匹配对大小写不敏感</td>
</tr>
<tr>
<td>re.M(MULTILINE)</td>
<td>多行匹配，影响 ^ 和 $</td>
</tr>
<tr>
<td>re.S(DOTALL)</td>
<td>使 . 匹配包括换行在内的所有字符</td>
</tr>
<tr>
<td>re.X(VERBOSE)</td>
<td>正则表达式可以是多行，忽略空白字符，并可以加入注释</td>
</tr>
</tbody>
</table>
</div>
<h3 id="findall-函数"><a href="#findall-函数" class="headerlink" title="findall()函数"></a>findall()函数</h3><p>re.findall(pattern, string, flags=0)</p>
<p>返回字符串中所有模式的非重叠的匹配，作为字符串列表。该字符串扫描左到右，并匹配返回的顺序发现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">默认：</span><br><span class="line">        pattren = &quot;\w+&quot;</span><br><span class="line">        target = &quot;hello world\nWORLD HELLO&quot;</span><br><span class="line">        re.findall(pattren,target)</span><br><span class="line">        [&#x27;hello&#x27;, &#x27;world&#x27;, &#x27;WORLD&#x27;, &#x27;HELLO&#x27;]</span><br><span class="line"></span><br><span class="line">re.I:   </span><br><span class="line">        re.findall(&quot;world&quot;, target,re.I)</span><br><span class="line">        [&#x27;world&#x27;, &#x27;WORLD&#x27;]</span><br><span class="line"></span><br><span class="line">re.S:   </span><br><span class="line">        re.findall(&quot;world.WORLD&quot;, target,re.S)</span><br><span class="line">        [&quot;world\nworld&quot;]</span><br><span class="line">        re.findall(&quot;hello.*WORLD&quot;, target,re.S)</span><br><span class="line">        [&#x27;hello world\nWORLD&#x27;]</span><br><span class="line"></span><br><span class="line">re.M:</span><br><span class="line">        re.findall(&quot;^WORLD&quot;,target,re.M)</span><br><span class="line">        [&quot;WORLD&quot;]</span><br><span class="line"></span><br><span class="line">re.X:</span><br><span class="line">        reStr = &#x27;&#x27;&#x27;\d&#123;3&#125;  #区号</span><br><span class="line">                -\d&#123;8&#125;&#x27;&#x27;&#x27; #号码</span><br><span class="line">        re.findall(reStr,&quot;010-12345678&quot;,re.X) </span><br><span class="line">        [&quot;010-12345678&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="search函数"><a href="#search函数" class="headerlink" title="search函数"></a>search函数</h3><p>re.search 扫描整个字符串并返回第一个成功的匹配。</p>
<p>下面是此函数语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=0)</span><br></pre></td></tr></table></figure>
<p>这里的参数说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>pattern</td>
<td>这是正则表达式来进行匹配。</td>
</tr>
<tr>
<td>string</td>
<td>这是字符串，这将被搜索到的字符串中的任何位置匹配的模式。</td>
</tr>
<tr>
<td>flags</td>
<td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td>
</tr>
</tbody>
</table>
</div>
<p>匹配成功re.search方法返回一个匹配的对象，否则返回None。</p>
<p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>匹配对象的方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>group(num=0)</td>
<td>此方法返回整个匹配（或指定分组num）</td>
</tr>
<tr>
<td>groups()</td>
<td>此方法返回所有元组匹配的子组（空，如果没有）</td>
</tr>
</tbody>
</table>
</div>
<h4 id="例子：-1"><a href="#例子：-1" class="headerlink" title="例子："></a>例子：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span>;</span><br><span class="line"></span><br><span class="line">searchObj = re.search( <span class="string">r&#x27;(.*) are (.*?) .*&#x27;</span>, line, re.M|re.I)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> searchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group() : &quot;</span>, searchObj.group()</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group(1) : &quot;</span>, searchObj.group(<span class="number">1</span>)</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;searchObj.group(2) : &quot;</span>, searchObj.group(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;Nothing found!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，它产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matchObj.group() :  Cats are smarter than dogs</span><br><span class="line">matchObj.group(1) :  Cats</span><br><span class="line">matchObj.group(2) :  smarter</span><br></pre></td></tr></table></figure>
<h4 id="re-match与re-search的区别"><a href="#re-match与re-search的区别" class="headerlink" title="re.match与re.search的区别"></a>re.match与re.search的区别</h4><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p>
<h4 id="例子：-2"><a href="#例子：-2" class="headerlink" title="例子："></a>例子：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">&quot;Cats are smarter than dogs&quot;</span>;</span><br><span class="line"></span><br><span class="line">matchObj = re.match( <span class="string">r&#x27;dogs&#x27;</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> matchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;match --&gt; matchObj.group() : &quot;</span>, matchObj.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;No match!!&quot;</span></span><br><span class="line"></span><br><span class="line">searchObj = re.search( <span class="string">r&#x27;dogs&#x27;</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> searchObj:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;search --&gt; searchObj.group() : &quot;</span>, searchObj.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="built_in">print</span> <span class="string">&quot;Nothing found!!&quot;</span></span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">No match!!</span><br><span class="line">search --&gt; matchObj.group() :  dogs</span><br></pre></td></tr></table></figure>
<h3 id="搜索和替换"><a href="#搜索和替换" class="headerlink" title="搜索和替换"></a>搜索和替换</h3><p>Python 的re模块提供了re.sub用于替换字符串中的匹配项。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, max=0)</span><br></pre></td></tr></table></figure>
<p>返回的字符串是在字符串中用 RE 最左边不重复的匹配来替换。如果模式没有发现，字符将被没有改变地返回。 可选参数 count 是模式匹配后替换的最大次数；count 必须是非负整数。缺省值是 0 表示替换所有的匹配。 实例：</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p>下面是一个爬虫做翻页面例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://hr.tencent.com/position.php?&amp;start=10&quot;</span></span><br><span class="line">page = re.search(<span class="string">&#x27;start=(\d+)&#x27;</span>,url).group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">nexturl = re.sub(<span class="string">r&#x27;start=(\d+)&#x27;</span>, <span class="string">&#x27;start=&#x27;</span>+<span class="built_in">str</span>(<span class="built_in">int</span>(page)+<span class="number">10</span>), url)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Next Url : &quot;</span>, nexturl</span><br></pre></td></tr></table></figure>
<p>当执行上面的代码，产生以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Next Url :  http://hr.tencent.com/position.php?&amp;start=20</span><br></pre></td></tr></table></figure>
<h1 id="页面解析之结构化数据"><a href="#页面解析之结构化数据" class="headerlink" title="页面解析之结构化数据"></a>页面解析之结构化数据</h1><p>结构化的数据是最好处理，一般都是类似JSON格式的字符串，直接解析JSON数据，提取JSON的关键字段即可。</p>
<h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式；适用于进行数据交互的场景，比如网站前台与后台之间的数据交互</p>
<p>Python 2.7中自带了JSON模块，直接import json就可以使用了。</p>
<p>Json模块提供了四个功能：dumps、dump、loads、load,用于字符串 和 python数据类型间进行转换</p>
<p><a target="_blank" rel="noopener" href="http://docs.python.org/library/json.html">Python操作json的标准api库参考</a></p>
<p><a target="_blank" rel="noopener" href="http://tool.oschina.net/codeformat/json">在线JSON格式化代码</a></p>
<h3 id="1-json-loads"><a href="#1-json-loads" class="headerlink" title="1. json.loads()"></a>1. json.loads()</h3><p>实现：json字符串 转化 python的类型，返回一个python的类型</p>
<p>从json到python的类型转化对照如下：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/json2.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">a=<span class="string">&quot;[1,2,3,4]&quot;</span></span><br><span class="line">b=<span class="string">&#x27;&#123;&quot;k1&quot;:1,&quot;k2&quot;:2&#125;&#x27;</span><span class="comment">#当字符串为字典时&#123;&#125;外面必须是&#x27;&#x27;单引号&#123;&#125;里面必须是&quot;&quot;双引号</span></span><br><span class="line"><span class="built_in">print</span> json.loads(a) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.loads(b) </span><br><span class="line">&#123;<span class="string">&#x27;k2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;k1&#x27;</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(<span class="string">r&#x27;http://api.douban.com/v2/book/isbn/9787218087351&#x27;</span>)</span><br><span class="line"></span><br><span class="line">hjson = json.loads(response.read())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> hjson.keys()</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;rating&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;images&#x27;</span>][<span class="string">&#x27;large&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> hjson[<span class="string">&#x27;summary&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h3 id="2-json-dumps"><a href="#2-json-dumps" class="headerlink" title="2. json.dumps()"></a>2. json.dumps()</h3><p>实现python类型转化为json字符串，返回一个str对象</p>
<p>从python原始类型向json类型的转化对照如下：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/json.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">b =&#123;<span class="string">&quot;k1&quot;</span>:<span class="number">1</span>,<span class="string">&quot;k2&quot;</span>:<span class="number">2</span>&#125;</span><br><span class="line">c = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">json.dumps(a)</span><br><span class="line"><span class="string">&#x27;[1, 2, 3, 4]&#x27;</span></span><br><span class="line"></span><br><span class="line">json.dumps(b)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;k2&quot;: 2, &quot;k1&quot;: 1&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">json.dumps(c)</span><br><span class="line"><span class="string">&#x27;[1, 2, 3, 4]&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="json-dumps-中的ensure-ascii-参数引起的中文编码问题"><a href="#json-dumps-中的ensure-ascii-参数引起的中文编码问题" class="headerlink" title="json.dumps 中的ensure_ascii 参数引起的中文编码问题"></a>json.dumps 中的ensure_ascii 参数引起的中文编码问题</h4><p>如果Python Dict字典含有中文，json.dumps 序列化时对中文默认使用的ascii编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">b = &#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;中国&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">json.dumps(b)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;name&quot;: &quot;\\u4e2d\\u56fd&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.dumps(b)</span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;\u4e2d\u56fd&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(b))</span><br><span class="line">&#123;<span class="string">&#x27;confidence&#x27;</span>: <span class="number">1.0</span>, <span class="string">&#x27;encoding&#x27;</span>: <span class="string">&#x27;ascii&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>‘中国’ 中的ascii 字符码，而不是真正的中文。</p>
<p>想输出真正的中文需要指定<strong>ensure_ascii=False</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">json.dumps(b,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#123;&quot;name&quot;: &quot;\xe6\x88\x91&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> json.dumps(b,ensure_ascii=<span class="literal">False</span>) </span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;我&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(b,ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">&#123;<span class="string">&#x27;confidence&#x27;</span>: <span class="number">0.7525</span>, <span class="string">&#x27;encoding&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-json-dump"><a href="#3-json-dump" class="headerlink" title="3. json.dump()"></a>3. json.dump()</h3><p>把Python类型 以 字符串的形式 写到文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">json.dump(a,<span class="built_in">open</span>(<span class="string">&quot;digital.json&quot;</span>,<span class="string">&quot;w&quot;</span>))</span><br><span class="line">b = &#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;我&quot;</span>&#125;</span><br><span class="line">json.dump(b,<span class="built_in">open</span>(<span class="string">&quot;name.json&quot;</span>,<span class="string">&quot;w&quot;</span>),ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">json.dump(b,<span class="built_in">open</span>(<span class="string">&quot;name2.json&quot;</span>,<span class="string">&quot;w&quot;</span>),ensure_ascii=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-json-load"><a href="#4-json-load" class="headerlink" title="4. json.load()"></a>4. json.load()</h3><p>读取 文件中json形式的字符串元素 转化成python类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">number = json.load(<span class="built_in">open</span>(<span class="string">&quot;digital.json&quot;</span>))</span><br><span class="line"><span class="built_in">print</span> number</span><br><span class="line">b = json.load(<span class="built_in">open</span>(<span class="string">&quot;name.json&quot;</span>))</span><br><span class="line"><span class="built_in">print</span> b</span><br><span class="line">b.keys()</span><br><span class="line"><span class="built_in">print</span> b[<span class="string">&#x27;name&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h4 id="实战项目-1"><a href="#实战项目-1" class="headerlink" title="实战项目"></a>实战项目</h4><p>获取 lagou 城市表信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"></span><br><span class="line">url =<span class="string">&#x27;http://www.lagou.com/lbs/getAllCitySearchLabels.json?&#x27;</span></span><br><span class="line">request =urllib2.Request(url)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="built_in">print</span> response.code</span><br><span class="line">resHtml = response.read()</span><br><span class="line">jsonobj = json.loads(resHtml)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(jsonobj)</span><br><span class="line"><span class="built_in">print</span> jsonobj</span><br><span class="line"></span><br><span class="line">citylist =[]</span><br><span class="line"></span><br><span class="line">allcitys = jsonobj[<span class="string">&#x27;content&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;allCitySearchLabels&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> allcitys.keys()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> allcitys:</span><br><span class="line">    <span class="built_in">print</span> <span class="built_in">type</span>(allcitys[key])</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> allcitys[key]:</span><br><span class="line">        name =item[<span class="string">&#x27;name&#x27;</span>].encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span> name,<span class="built_in">type</span>(name)</span><br><span class="line">        citylist.append(name)</span><br><span class="line"></span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;city.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">content = json.dumps(citylist,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> content</span><br><span class="line"></span><br><span class="line">fp.write(content)</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="https://piaosanlang.gitbooks.io/spiders/content/photos/02_json.png" alt="img"></p>
<h3 id="JSONPath"><a href="#JSONPath" class="headerlink" title="JSONPath"></a>JSONPath</h3><p>JSON 信息抽取类库，从JSON文档中抽取指定信息的工具</p>
<h4 id="JSONPath与Xpath区别"><a href="#JSONPath与Xpath区别" class="headerlink" title="JSONPath与Xpath区别"></a>JSONPath与Xpath区别</h4><p>JsonPath 对于 JSON 来说，相当于 XPATH 对于XML。</p>
<p>下载地址：</p>
<p><a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/jsonpath/">https://pypi.python.org/pypi/jsonpath/</a></p>
<p>安装方法：</p>
<p>下载jsonpath，解压之后执行’python setup.py install’</p>
<p><a target="_blank" rel="noopener" href="http://goessner.net/articles/JsonPath/">参考文档</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>XPath</strong></th>
<th><strong>JSONPath</strong></th>
<th><strong>Result</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/store/book/author</code></td>
<td><code>$.store.book[*].author</code></td>
<td>the authors of all books in the store</td>
</tr>
<tr>
<td><code>//author</code></td>
<td><code>$..author</code></td>
<td>all authors</td>
</tr>
<tr>
<td><code>/store/*</code></td>
<td><code>$.store.*</code></td>
<td>all things in store, which are some books and a red bicycle.</td>
</tr>
<tr>
<td><code>/store//price</code></td>
<td><code>$.store..price</code></td>
<td>the price of everything in the store.</td>
</tr>
<tr>
<td><code>//book[3]</code></td>
<td><code>$..book[2]</code></td>
<td>the third book</td>
</tr>
<tr>
<td><code>//book[last()]</code></td>
<td><code>$..book[(@.length-1)]</code> <code>$..book[-1:]</code></td>
<td>the last book in order.</td>
</tr>
<tr>
<td><code>//book[position()&lt;3]</code></td>
<td><code>$..book[0,1]</code> <code>$..book[:2]</code></td>
<td>the first two books</td>
</tr>
<tr>
<td><code>//book[isbn]</code></td>
<td><code>$..book[?(@.isbn)]</code></td>
<td>filter all books with isbn number</td>
</tr>
<tr>
<td><code>//book[price&lt;10]</code></td>
<td><code>$..book[?(@.price&lt;10)]</code></td>
<td>filter all books cheapier than 10</td>
</tr>
<tr>
<td><code>//*</code></td>
<td><code>$..*</code></td>
<td>all Elements in XML document. All members of JSON structure.</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h4><p>还是以 <a target="_blank" rel="noopener" href="http://www.lagou.com/lbs/getAllCitySearchLabels.json">http://www.lagou.com/lbs/getAllCitySearchLabels.json</a> 为例，获取所有城市</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line">url =<span class="string">&#x27;http://www.lagou.com/lbs/getAllCitySearchLabels.json&#x27;</span></span><br><span class="line">request =urllib2.Request(url)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="built_in">print</span> response.code</span><br><span class="line">resHtml = response.read()</span><br><span class="line"></span><br><span class="line"><span class="comment">##detect charset</span></span><br><span class="line"><span class="built_in">print</span> chardet.detect(resHtml)</span><br><span class="line"></span><br><span class="line">jsonobj = json.loads(resHtml)</span><br><span class="line">citylist = jsonpath.jsonpath(jsonobj,<span class="string">&#x27;$..name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> citylist</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(citylist)</span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;city.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">content = json.dumps(citylist,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> content</span><br><span class="line"></span><br><span class="line">fp.write(content.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<h3 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h3><p>xmltodict模块让使用XML感觉跟操作JSON一样</p>
<p>Python操作XML的第三方库参考：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/martinblech/xmltodict">https://github.com/martinblech/xmltodict</a></p>
<p>模块安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">pip install xmltodict</span><br><span class="line"><span class="keyword">import</span> xmltodict</span><br><span class="line"></span><br><span class="line">bookdict = xmltodict.parse(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        &lt;bookstore&gt;</span></span><br><span class="line"><span class="string">            &lt;book&gt;</span></span><br><span class="line"><span class="string">                  &lt;title lang=&quot;eng&quot;&gt;Harry Potter&lt;/title&gt;</span></span><br><span class="line"><span class="string">                  &lt;price&gt;29.99&lt;/price&gt;</span></span><br><span class="line"><span class="string">            &lt;/book&gt;</span></span><br><span class="line"><span class="string">            &lt;book&gt;</span></span><br><span class="line"><span class="string">                  &lt;title lang=&quot;eng&quot;&gt;Learning XML&lt;/title&gt;</span></span><br><span class="line"><span class="string">                  &lt;price&gt;39.95&lt;/price&gt;</span></span><br><span class="line"><span class="string">            &lt;/book&gt;</span></span><br><span class="line"><span class="string">    &lt;/bookstore&gt;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> bookdict.keys()</span><br><span class="line">[<span class="string">u&#x27;bookstore&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> json.dumps(bookdict,indent=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;bookstore&quot;: &#123;</span><br><span class="line">        &quot;book&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;title&quot;: &#123;</span><br><span class="line">                    &quot;@lang&quot;: &quot;eng&quot;, </span><br><span class="line">                    &quot;#text&quot;: &quot;Harry Potter&quot;</span><br><span class="line">                &#125;, </span><br><span class="line">                &quot;price&quot;: &quot;29.99&quot;</span><br><span class="line">            &#125;, </span><br><span class="line">            &#123;</span><br><span class="line">                &quot;title&quot;: &#123;</span><br><span class="line">                    &quot;@lang&quot;: &quot;eng&quot;, </span><br><span class="line">                    &quot;#text&quot;: &quot;Learning XML&quot;</span><br><span class="line">                &#125;, </span><br><span class="line">                &quot;price&quot;: &quot;39.95&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="数据提取总结"><a href="#数据提取总结" class="headerlink" title="数据提取总结"></a>数据提取总结</h3><ul>
<li><p>HTML、XML</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">XPath</span><br><span class="line">CSS选择器</span><br><span class="line">正则表达式</span><br></pre></td></tr></table></figure>
</li>
<li><p>JSON</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JSONPath</span><br><span class="line">转化成Python类型进行操作（json类）</span><br></pre></td></tr></table></figure>
</li>
<li><p>XML</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">转化成Python类型（xmltodict）</span><br><span class="line">XPath</span><br><span class="line">CSS选择器</span><br><span class="line">正则表达式</span><br></pre></td></tr></table></figure>
</li>
<li><p>其他（js、文本、电话号码、邮箱地址）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">正则表达式</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/9%E7%88%AC%E8%99%ABpyppeteer%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-29 21:47:51" itemprop="dateCreated datePublished" datetime="2022-10-29T21:47:51+08:00">2022-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-28 16:30:11" itemprop="dateModified" datetime="2022-10-28T16:30:11+08:00">2022-10-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>使用 Pyppeteer 针对之前的 Selenium 案例做一次改写，来体会一下二者的不同之处，同时也加强一下对 Pyppeteer 的理解和掌握情况。</p>
<p>还是 Selenium 的那个案例，地址为：<a target="_blank" rel="noopener" href="https://dynamic2.scrape.cuiqingcai.com/">https://dynamic2.scrape.cuiqingcai.com/</a></p>
<p>爬取目标和那一节也是一样的：</p>
<ul>
<li>遍历每一页列表页，然后获取每部电影详情页的 URL。</li>
<li>爬取每部电影的详情页，然后提取其名称、评分、类别、封面、简介等信息。</li>
<li>爬取到的数据存为 JSON 文件。</li>
</ul>
<p>要求和之前也是一样的，只不过我们这里的实现就全用 Pyppeteer 来做了。</p>
<ul>
<li>安装好 Python （最低为 Python 3.6）版本，并能成功运行 Python 程序。</li>
<li>安装好 Pyppeteer 并能成功运行示例。</li>
</ul>
<p>其他的浏览器、驱动配置就不需要了，这也是相比 Selenium 更加方便的地方。</p>
<p>页面分析在这里就不多介绍了，还是列表页 + 详情页的结构，具体可以参考 Selenium 那一课时的内容。</p>
<h2 id="爬取列表页"><a href="#爬取列表页" class="headerlink" title="爬取列表页"></a>爬取列表页</h2><p>首先我们先做一些准备工作，定义一些基础的配置，包括日志定义、变量等等并引入一些必要的包，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic2.scrape.cuiqingcai.com/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIMEOUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line">WINDOW_WIDTH, WINDOW_HEIGHT = <span class="number">1366</span>, <span class="number">768</span></span><br><span class="line">HEADLESS = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>这里大多数的配置和之前是一样的，不过这里我们额外定义了窗口的宽高信息，这里定义为 1366 x 768，你也可以随意指定适合自己屏幕的宽高信息。另外这里定义了一个变量 HEADLESS，用来指定是否启用 Pyppeteer 的无头模式，如果为 False，那么启动 Pyppeteer 的时候就会弹出一个 Chromium 浏览器窗口。</p>
<p>接着我们再定义一个初始化 Pyppeteer 的方法，包括启动 Pyppeteer，新建一个页面选项卡，设置窗口大小等操作，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line">browser, tab = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">   <span class="keyword">global</span> browser, tab</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=HEADLESS,</span><br><span class="line">                          args=[<span class="string">&#x27;--disable-infobars&#x27;</span>,</span><br><span class="line">                                <span class="string">f&#x27;--window-size=<span class="subst">&#123;WINDOW_WIDTH&#125;</span>,<span class="subst">&#123;WINDOW_HEIGHT&#125;</span>&#x27;</span>])</span><br><span class="line">   tab = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> tab.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: WINDOW_WIDTH, <span class="string">&#x27;height&#x27;</span>: WINDOW_HEIGHT&#125;)</span><br></pre></td></tr></table></figure>
<p>在这里我们先声明了一个 browser 对象，代表 Pyppeteer 所用的浏览器对象，tab 代表新建的页面选项卡，这里把两项设置为全局变量，方便其他的方法调用。</p>
<p>另外定义了一个 init 方法，调用了 Pyppeteer 的 launch 方法，传入了 headless 为 HEADLESS，将其设置为非无头模式，另外还通过 args 指定了隐藏提示条并设定了窗口的宽高。</p>
<p>接下来我们像之前一样，定义一个通用的爬取方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer.errors <span class="keyword">import</span> TimeoutError</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_page</span>(<span class="params">url, selector</span>):</span><br><span class="line">   logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">await</span> tab.goto(url)</span><br><span class="line">       <span class="keyword">await</span> tab.waitForSelector(selector, options=&#123;</span><br><span class="line">           <span class="string">&#x27;timeout&#x27;</span>: TIMEOUT * <span class="number">1000</span></span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">except</span> TimeoutError:</span><br><span class="line">       logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 scrape_page 方法，它接收两个参数，一个是 url，代表要爬取的链接，使用 goto 方法调用即可；另外一个是 selector，即要等待渲染出的节点对应的 CSS 选择器，这里我们使用 waitForSelector 方法并传入了 selector，并通过 options 指定了最长等待时间。</p>
<p>这样的话在运行时页面会首先访问这个 URL，然后等待某个符合 selector 的节点加载出来，最长等待 10 秒，如果 10 秒内加载出来了，那就接着往下执行，否则抛出异常，捕获 TimeoutError 并输出错误日志。</p>
<p>接下来，我们就实现一下爬取列表页的方法，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">   url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;.item .name&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们定义了 scrape_index 方法来爬取页面，其接受一个参数 page，代表要爬取的页码，这里我们首先通过 INDEX_URL 构造了列表页的 URL，然后调用 scrape_page 方法传入了 url 和要等待加载的选择器。</p>
<p>好，接下来我们可以再定义一个解析列表页的方法，提取出每部电影的详情页 URL，定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_index</span>():</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.item .name&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里我们调用了 querySelectorAllEval 方法，它接收两个参数，第一个参数是 selector，代表要选择的节点对应的 CSS 选择器；第二个参数是 pageFunction，代表的是要执行的 JavaScript 方法，这里需要传入的是一段 JavaScript 字符串，整个方法的作用是选择 selector 对应的节点，然后对这些节点通过 pageFunction 定义的逻辑抽取出对应的结果并返回。</p>
<p>所以这里第一个参数 selector 就传入电影名称对应的节点，其实是超链接 a 节点。由于提取结果有多个，所以这里 JavaScript 对应的 pageFunction 输入参数就是 nodes，输出结果是调用了 map 方法得到每个 node，然后调用 node 的 href 属性即可。这样返回结果就是当前列表页的所有电影的详情页 URL 组成的列表了。</p>
<p>好，接下来我们来串联调用一下看看，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           logging.info(<span class="string">&#x27;detail_urls %s&#x27;</span>, detail_urls)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<h2 id="爬取详情页"><a href="#爬取详情页" class="headerlink" title="爬取详情页"></a>爬取详情页</h2><p>拿到详情页的 URL 之后，下一步就是爬取每一个详情页然后提取信息了，首先我们定义一个爬取详情页的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">   <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;h2&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>如果顺利运行，那么当前 Pyppeteer 就已经成功加载出详情页了，下一步就是提取里面的信息了。</p>
<p>接下来我们再定义一个提取详情信息的方法，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_detail</span>():</span><br><span class="line">   url = tab.url</span><br><span class="line">   name = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;h2&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   categories = <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.categories button span&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;</span>)</span><br><span class="line">   cover = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.cover&#x27;</span>, <span class="string">&#x27;node =&gt; node.src&#x27;</span>)</span><br><span class="line">   score = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.score&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   drama = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.drama p&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   <span class="keyword">return</span> &#123;</span><br><span class="line">       <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">       <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">       <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">       <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">       <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">       <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>这里我们定义了一个 parse_detail 方法，提取了 URL、名称、类别、封面、分数、简介等内容，提取方式如下：</p>
<ul>
<li>URL：直接调用 tab 对象的 url 属性即可获取当前页面的 URL。</li>
<li>名称：由于名称只有一个节点，所以这里我们调用了 querySelectorEval 方法来提取，而不是querySelectorAllEval，第一个参数传入 h2，提取到了名称对应的节点，然后第二个参数传入提取的 pageFunction，调用了 node 的 innerText 属性提取了文本值，即电影名称。</li>
<li>类别：类别有多个，所以我们这里调用了 querySelectorAllEval 方法来提取，其对应的 CSS 选择器为 .categories button span，可以选中多个类别节点。接下来还是像之前提取详情页 URL 一样，pageFunction 使用 nodes 参数，然后调用 map 方法提取 node 的 innerText 就得到所有类别结果了。</li>
<li>封面：同样地，可以使用 CSS 选择器 .cover 直接获取封面对应的节点，但是由于其封面的 URL 对应的是 src 这个属性，所以这里提取的是 src 属性。</li>
<li>分数：分数对应的 CSS 选择器为 .score ，类似的原理，提取 node 的 innerText 即可。</li>
<li>简介：同样可以使用 CSS 选择器 .drama p 直接获取简介对应的节点，然后调用 innerText 属性提取文本即可。</li>
</ul>
<p>最后我们将提取结果汇总成一个字典然后返回即可。</p>
<p>接下来 main 方法里面，我们增加 scrape_detail 和 parse_detail 方法的调用，main 方法改写如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">               <span class="keyword">await</span> scrape_detail(detail_url)</span><br><span class="line">               detail_data = <span class="keyword">await</span> parse_detail()</span><br><span class="line">               logging.info(<span class="string">&#x27;data %s&#x27;</span>, detail_data)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br></pre></td></tr></table></figure>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>最后，我们再像之前一样添加一个数据存储的方法，为了方便，这里还是保存为 JSON 文本文件，实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">   name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">   data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">   json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>在运行过程中，由于 Pyppeteer 本身实现的原因，可能连续运行 20 秒之后控制台就会出现如下错误：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyppeteer.errors.NetworkError: Protocol Error (Runtime.evaluate): Session closed. Most likely the page has been closed.</span><br></pre></td></tr></table></figure>
<h2 id="无头模式"><a href="#无头模式" class="headerlink" title="无头模式"></a>无头模式</h2><p>最后如果代码能稳定运行了，我们可以将其改为无头模式，将 HEADLESS 修改为 True 即可，这样在运行的时候就不会弹出浏览器窗口了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/ComplexNetWork/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/ComplexNetWork/" class="post-title-link" itemprop="url">Attack Robustness and Centrality of Complex Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-21 15:43:22" itemprop="dateCreated datePublished" datetime="2022-10-21T15:43:22+08:00">2022-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-24 19:01:44" itemprop="dateModified" datetime="2022-10-24T19:01:44+08:00">2022-10-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>Iyer, Swami &amp; Killingback, Timothy &amp; Sundaram, Bala &amp; Wang, Zhen. (2013). Attack Robustness and Centrality of Complex Networks. PloS one. 8. e59613. 10.1371/journal.pone.0059613. </p>
</blockquote>
<p>组件失败时系统的稳定性——依赖于底层网络的稳定性——顶点移除时网络结构的改变</p>
<ul>
<li>betweenness centrality.</li>
<li>基于度分布、聚集系数、组合系数去衡量复杂网络的鲁棒性</li>
</ul>
<p>研究基于度、中间度、接近度和特征向量中心性的<code>去除方案</code>对各种模型网络的影响，包括幂律和指数分布、不同聚类系数和不同分类程度的模型网络</p>
<h2 id="网络渗流和稳定性"><a href="#网络渗流和稳定性" class="headerlink" title="网络渗流和稳定性"></a>网络渗流和稳定性</h2><p>渗透：取一个网络并去除其顶点的某些部分（以及连接到顶点的边）的过程。</p>
<p>对于疫苗接种或者节点失效来说，虽然它物理上还存在，但从功能视图上看一些节点被移除了。</p>
<p><strong>若渗流后的最大组件（相对于原始网络规模）在规模上变得太小，系统不可正常工作。</strong></p>
<p>系统稳定性衡量函数为移除节点的函数：</p>
<p><img src="/categories/Notes/ComplexNetWork/1666345435871.png" alt="1666345435871"></p>
<p>中心性参数(centrality)<strong>度数</strong>，可以用来衡量节点的<strong>重要性程度</strong>——。</p>
<p>R-index<a href="Schneider C, Moreira A, Andrade Jr J, Havlin S, Herrmann H (2011">[13]</a> Mitigation of malicious attacks on networks. Proceedings of the National Academy of Sciences 108: 3838–3841.)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Few-Shot08/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Few-Shot08/" class="post-title-link" itemprop="url">A CLOSER LOOK AT FEW-SHOT CLASSIFICATION</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-15 20:43:22" itemprop="dateCreated datePublished" datetime="2022-10-15T20:43:22+08:00">2022-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-16 15:46:58" itemprop="dateModified" datetime="2022-10-16T15:46:58+08:00">2022-10-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="本文工作"><a href="#本文工作" class="headerlink" title="本文工作"></a>本文工作</h2><h2 id="研究点"><a href="#研究点" class="headerlink" title="研究点"></a>研究点</h2><h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><h2 id="论文结论的支持证据"><a href="#论文结论的支持证据" class="headerlink" title="论文结论的支持证据"></a>论文结论的支持证据</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/Notes/%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BB%A3%E7%A0%81%E7%9B%B8%E4%BC%BC%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/Notes/%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BB%A3%E7%A0%81%E7%9B%B8%E4%BC%BC%E6%80%A7/" class="post-title-link" itemprop="url">二进制代码相似性研究综述</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-10-11 21:00:26 / Modified: 15:23:44" itemprop="dateCreated datePublished" datetime="2022-10-11T21:00:26+08:00">2022-10-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>A Survey of Binary Code Similarity</strong>(<a target="_blank" rel="noopener" href="https://doi.org/10.1145/3446371">https://doi.org/10.1145/3446371</a>)</p>
<p>Irfan Ul Haq and Juan Caballero. 2021. A Survey of Binary Code Similarity. <em>ACM Comput. Surv.</em> 54, 3, Article 51 (April 2021), 38 pages. </p>
<p>补丁，漏洞，恶意代码检测，这些技术其实是相通的。<br>70种恶意代码相似性比较方法：应用领域，方法特点，实施办法，评估基准。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Few-Shot02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Few-Shot02/" class="post-title-link" itemprop="url">小样本学习方法概述2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-05 20:43:22" itemprop="dateCreated datePublished" datetime="2022-10-05T20:43:22+08:00">2022-10-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-02 17:28:51" itemprop="dateModified" datetime="2022-10-02T17:28:51+08:00">2022-10-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="元学习模型"><a href="#元学习模型" class="headerlink" title="元学习模型"></a>元学习模型</h2><p>借助训练时的元知识</p>
<p><a href="Santoro, A.; Bartunov, S.; Botvinick, M.; Wierstra, D.; Lillicrap, T. Meta-learning with memory-augmented  neural networks. In Proceedings of the 33rd International Conference on International Conference on Machine Learning, New York, NY, USA, 19–24 June 2016; Volume 48, pp. 1842–1850.">A. Santoro,神经图灵机变种</a></p>
<p><a href>O.Vinyals,Matching Network</a> </p>
<p><a href>G. Koch et al.,孪生网络</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Few-Shot07/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Few-Shot07/" class="post-title-link" itemprop="url">MANNWARE: A Malware Classification Approach with a Few Samples Using a Memory Augmented Neural Network</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-03 20:43:22" itemprop="dateCreated datePublished" datetime="2022-10-03T20:43:22+08:00">2022-10-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-14 14:04:40" itemprop="dateModified" datetime="2022-10-14T14:04:40+08:00">2022-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/338662042_MANNWARE_A_Malware_Classification_Approach_with_a_Few_Samples_Using_a_Memory_Augmented_Neural_Network">下载链接</a>  MANNWARE：用记忆增强网络的小样本恶意软件分类方法,2020，小样本学习做恶意代码分类开山作</p>
<p>Tran, Kien &amp; Sato, Hiroshi &amp; Kubo, Masao. (2020). MANNWARE: A Malware Classification Approach with a Few Samples Using a Memory Augmented Neural Network. Information. 11. 51. 10.3390/info11010051. </p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>修改了内存存取能力memory access capabilities的神经图灵机<a href>NTM</a>  +NLP(word2vec, n-gram)</p>
<p><img src="/categories/ML/Few-Shot07/1664785741276.png" alt="1664785741276"></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/categories/ML/Few-Shot07/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Few-Shot06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Few-Shot06/" class="post-title-link" itemprop="url">A Few-Shot Meta-Learning based Siamese Neural Network using Entropy Features for Ransomware Classification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-10-02 20:43:22 / Modified: 13:28:27" itemprop="dateCreated datePublished" datetime="2022-10-02T20:43:22+08:00">2022-10-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.00668">下载链接</a>,一种使用熵特征进行勒索软件分类的基于小样本元学习的孪生网络，2022年</p>
<p>Jinting Zhu, Julian Jang-Jaccard, Amardeep Singh, Ian Welch, Harith AI-Sahaf, Seyit Camtepe,<br>A few-shot meta-learning based siamese neural network using entropy features for ransomware classification,Computers &amp; Security,Volume 117,2022,102691,ISSN 0167-4048,</p>
<blockquote>
<p><a href="..\Few-Shot04">相关论文</a>Task-Aware Meta Learning-based Siamese Neural Network for Classifying Control Flow Obfuscated Malware</p>
</blockquote>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/categories/ML/Few-Shot06/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueinyou.com/categories/ML/Few-Shot05/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://blueinyou.com/photos/avatar.jpg">
      <meta itemprop="name" content="Paul C">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paul C's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/categories/ML/Few-Shot05/" class="post-title-link" itemprop="url">ConvProtoNet: Deep Prototype Induction towards Better Class Representation for Few-Shot Malware Classification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-27 15:43:22" itemprop="dateCreated datePublished" datetime="2022-09-27T15:43:22+08:00">2022-09-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-21 16:41:41" itemprop="dateModified" datetime="2022-10-21T16:41:41+08:00">2022-10-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p><a target="_blank" rel="noopener" href="https://mdpi-res.com/d_attachment/applsci/applsci-10-02847/article_deploy/applsci-10-02847-v2.pdf#version=1587905118&amp;usg=AOvVaw0hMY5VHNyAO9Ikmo2Ghf-M">下载链接</a>，卷积原型网络：针对小样本恶意软件分类的更好的类表示的深度原型归纳,2020年</p>
</blockquote>
<p>Zhijie, Tang &amp; Wang, Peng &amp; Wang, Junfeng. (2020). ConvProtoNet: Deep Prototype Induction towards Better Class Representation for Few-Shot Malware Classification. Applied Sciences. 10. 2847. 10.3390/app10082847. </p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>ConvProtoNet：基于度量(metric-based)的模型，使用了非参数的方法，<strong>在嵌入层做了深层的原型归纳</strong>，使得表达效果好，分布能匹配，避免了梯度消失，在分析时忽略无用特征。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/categories/ML/Few-Shot05/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Paul C"
      src="https://blueinyou.com/photos/avatar.jpg">
  <p class="site-author-name" itemprop="name">Paul C</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">99</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/memoryofsnow" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;memoryofsnow" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2215489940@qq.com" title="E-Mail → mailto:2215489940@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/jiyi_guoshu" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;jiyi_guoshu" rel="noopener" target="_blank"><i class="fab fa-csdn fa-fw"></i>CSDN</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Paul C</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
