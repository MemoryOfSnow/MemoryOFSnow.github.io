---
title: 梯度下降法、[拟]牛顿法
date: 2022-03-30 16:14:53
categories: 机器学习 #
tags: [统计学习]
---
## GD

Gradient Decent/Steepest Decent，求解无约束最优化问题。

<img src="SL-05/image-20220330173751248.png" alt="image-20220330173751248" style="zoom:33%;" />

负梯度方向是使函数值下降最快的方向。

![image-20220330181452563](SL-05/image-20220330181452563.png)

否则，不断地找f(x)的极小值点x，办法是让x=x-df(x)* λ，最关键的是找到合适的λ。

举例如下：

![image-20220330181942932](SL-05/image-20220330181942932.png)

梯度下降法收敛速度不一定快，而牛顿法和拟牛顿法，收敛速度更快。

## Newton Method

求解无约束最优化问题的迭代算法，每一步需要求解目标函数的海森矩阵的逆矩阵。

基本思想:在现有极小值估计值的附近对f(x)做泰勒展开，进而找到**极小值的下一个估计**值。

![image-20220330182720475](SL-05/image-20220330182720475.png)



## quasi-Newton Method

通过正定矩阵近似海森矩阵(的逆矩阵)。